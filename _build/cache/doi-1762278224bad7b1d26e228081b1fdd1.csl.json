[{"author":[{"given":"Hongyu","family":"Wang"},{"given":"Shuming","family":"Ma"},{"given":"Ruiping","family":"Wang"},{"given":"Furu","family":"Wei"}],"DOI":"10.48550/ARXIV.2407.10969","type":"document","id":"https://doi.org/10.48550/arxiv.2407.10969","citation-key":"https://doi.org/10.48550/arxiv.2407.10969","issued":{"date-parts":[[2024]]},"keyword":"Computation and Language (cs.CL),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences","publisher":"arXiv","title":"Q-Sparse: All Large Language Models can be Fully Sparsely-Activated","URL":"https://arxiv.org/abs/2407.10969","_graph":[{"type":"@biblatex/text","data":"@misc{https://doi.org/10.48550/arxiv.2407.10969,\n  doi = {10.48550/ARXIV.2407.10969},\n  url = {https://arxiv.org/abs/2407.10969},\n  author = {Wang, Hongyu and Ma, Shuming and Wang, Ruiping and Wei, Furu},\n  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {Q-Sparse: All Large Language Models can be Fully Sparsely-Activated},\n  publisher = {arXiv},\n  year = {2024},\n  copyright = {arXiv.org perpetual, non-exclusive license}\n}\n"},{"type":"@biblatex/entries+list"},{"type":"@csl/list+object"}]}]