<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>The Interactive Transformer - ML Notes</title><meta property="og:title" content="The Interactive Transformer - ML Notes"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg"/><meta property="og:image" content="/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg"/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/build/_assets/app-H3NBUYVS.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="/myst-theme.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">ML Notes</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3iop:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="ML Notes" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">ML Notes</a><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Projects" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200 active" href="/projects">Projects</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rbd8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:Rbd8p:" class="pl-3 pr-[2px] collapsible-content"><a title="CognitionTO Community" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/projects/cognition-to">CognitionTO Community</a><a title="The Interactive Transformer" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/projects/the-interactive-transformer/interactive-transformer">The Interactive Transformer</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Glossary" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/glossary">Glossary</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rfd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rfd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Papers" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/paper-notes">Papers</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rjd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rjd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Experiments" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/experiments">Experiments</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rnd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rnd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/joshcarp/ml-notes" title="GitHub Repository: joshcarp/ml-notes" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="inline-block mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block"><title>Jupyter Notebook</title><path d="M20.2 1.7c0 .8-.5 1.4-1.3 1.5-.8 0-1.4-.5-1.5-1.3 0-.8.5-1.4 1.3-1.5.8-.1 1.5.5 1.5 1.3zM12 17.9c-3.7 0-7-1.3-8.7-3.3 1.8 4.8 7.1 7.3 11.9 5.5 2.5-.9 4.5-2.9 5.5-5.5-1.7 2-4.9 3.3-8.7 3.3zM12 5.1c3.7 0 7 1.3 8.7 3.3-1.8-4.8-7.1-7.3-11.9-5.5-2.5.9-4.5 2.9-5.5 5.5 1.7-2 5-3.3 8.7-3.3zM6.9 21.8c.1 1-.7 1.8-1.7 1.9-1 .1-1.8-.7-1.9-1.7 0-1 .7-1.8 1.7-1.9 1-.1 1.8.7 1.9 1.7zM3.7 4.6c-.6 0-1-.4-1-1s.4-1 1-1 1 .4 1 1c0 .5-.4 1-1 1z"></path></svg></div><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">The Interactive Transformer</h1><p class="mt-2 mb-0 lead text-zinc-600 dark:text-zinc-400">by Joshua Carpeggiani</p></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div class="sticky top-[60px] flex justify-end w-full z-20 pointer-events-none"><div class="flex p-1 m-1 space-x-1 border rounded-full shadow pointer-events-auto border-stone-300 bg-white/80 dark:bg-stone-900/80 backdrop-blur"><div class="rounded"><button class="flex text-center rounded-full cursor-pointer text-stone-800 dark:text-white hover:opacity-100 opacity-60" aria-label="start compute environment"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="inline-block w-6 h-6 align-top"><title>enable compute</title><path stroke-linecap="round" stroke-linejoin="round" d="M5.636 5.636a9 9 0 1 0 12.728 0M12 3v9"></path></svg></button></div></div></div><div id="skip-to-article"></div><div id="kWoommLMry" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="introduction" class="relative group"><span class="heading-text">Introduction</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#introduction" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Welcome. This is an implementation of a transformer in pure go with no third party libraries. This way, everything from tensor operations to tokenization are all done inside this notebook.</p><p>Because the goal of this project is illustrative, there are no optimisations. Everything runs on a single goroutine and doesn’t have any parallelism. This makes it easy to follow and good as a reference guide.</p><p>This page is also heavily referenced. The goal is to have everything have a reference to its original paper or reference implementation.</p><aside class="my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden rounded border-l-4 border-blue-500"><div class="m-0 font-medium py-1 flex min-w-0 text-lg text-blue-600 bg-blue-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="inline-block pl-2 mr-2 self-center flex-none text-blue-600"><path stroke-linecap="round" stroke-linejoin="round" d="m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z"></path></svg><div class="text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Note</div></div><div class="px-4 py-1"><p>This notebook is a version of my repo <a target="_blank" href="https:/github.com/joshcarp/llm.go" rel="noreferrer">github<wbr/>.com<wbr/>/joshcarp<wbr/>/llm<wbr/>.go</a> which in itself is a fork of <a target="_blank" href="https://github.com/karpathy/llm.c" rel="noreferrer">github<wbr/>.com<wbr/>/karpathy<wbr/>/llm<wbr/>.c</a>.</p></div></aside><figure id="l8WymNFk1D" class="fig-figure"><div style="text-align:center" class="leading-[0]"><div class="relative inline-block" style="padding-bottom:60%;width:min(max(100%, 500px), 100%)"><iframe width="100%" height="100%" src="https://www.youtube.com/embed/wjZofJX0v4M?si=ropP1oHLOiynXLNH" allowfullscreen="" allow="autoplay" style="width:100%;height:100%;position:absolute;top:0;left:0;border:none"></iframe></div></div><figcaption class="group"><p>GPT introduction</p></figcaption></figure></div><div id="QVpP91ZWaO" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="references" class="relative group"><span class="heading-text">References</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Usually this goes at the bottom, but seeing this entire thing is a reference, it’ll go at the top instead.</p><ul><li><a href="https://en.wikipedia.org/wiki/IEEE_754" class="italic" target="_blank" rel="noreferrer" data-state="closed">IEEE-754</a> - This is binary floating point. The specification gives good details about what types of errors that can accumulate which would impact training and interence, as well as possible optimisations that can be used, like fused-multiply-add (FMA), which can reduce intermediate errors. CPUs usually use FP32, GPUs FP16.</li><li><a target="_blank" href="https://netlib.org/blas/" rel="noreferrer">BLAS</a> - Speed up matrix multiplication on CPUs.</li><li><a target="_blank" href="https://arxiv.org/abs/1607.06450" rel="noreferrer"><strong>Layer Normalization</strong></a> - Layernorm was introduced in this paper.</li><li><a target="_blank" href="https://arxiv.org/pdf/1512.03385" rel="noreferrer"><strong>Deep Residual Learning for Image Recognition</strong></a> - The introduction of residuals allowed for deeper networks. Before this paper the depth of a neural network was limited because it would diverge enough and back propagation was really, really difficult to do because of vanishing gradients. Residuals essentially have a “short circuit” past a block which limits how much the neural networks can influence.</li><li><a target="_blank" href="https://arxiv.org/abs/1606.08415v5" rel="noreferrer"><strong>Gaussian Error Linear Units (GELUs)</strong></a> - Activation function that leaves positive values unchanged but maps negative numbers to near zero. Other architectures use different activation functions. For example, OpenElm uses SwiGLU.</li><li><a target="_blank" href="https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf" rel="noreferrer"><strong>Learning representations by back-propagating errors</strong></a> - Back-propagation was introduced here, couldn’t find the original paper. This was done by Hinton and co and was what lead to the AI era of the 80s.</li><li><a target="_blank" href="https://arxiv.org/abs/1412.6980" rel="noreferrer"><strong>Adam: A Method for Stochastic Optimization</strong></a> - Introduced the Adam optimiser.</li><li><a target="_blank" href="https://arxiv.org/abs/1711.05101" rel="noreferrer"><strong>DECOUPLED WEIGHT DECAY REGULARIZATION</strong></a> - Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.</li><li><a target="_blank" href="https://arxiv.org/abs/1412.6980" rel="noreferrer"><strong>Adam: A Method for Stochastic Optimization</strong></a> - Introduced the Adam optimiser.</li><li><a target="_blank" href="https://arxiv.org/abs/1711.05101" rel="noreferrer"><strong>DECOUPLED WEIGHT DECAY REGULARIZATION</strong></a> - Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.</li><li><a target="_blank" href="https://arxiv.org/pdf/1911.02150" rel="noreferrer"><strong>Fast Transformer Decoding: One Write-Head is All
You Need</strong></a> - People always point to the original Attention is all you need paper or the GPT paper that introduced the <em>decoder only</em> model, but this one was the first one that actually used it in practice.</li><li><a target="_blank" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="noreferrer"><strong>Language Models are Unsupervised Multitask Learners</strong></a> - This is the GPT-2 paper</li><li><a target="_blank" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="noreferrer"><strong>Improving Language Understanding by Generative Pre-Training</strong></a> -** This paper introduced the “GPT” which was a breakthrough at the time. It introduced the idea of using next token prediction as a way to do self-supervised learning, which meant that we can put all of the internet into it and with a simple loss function over the vocabulary adjust the weights via backpropagation.</li><li><a target="_blank" href="https://arxiv.org/abs/1706.03762v7" rel="noreferrer"><strong>Attention Is All You Need</strong></a> - The OG introduced the idea of self-attention and the encoder/decoder architecture for language translation tasks (the encoder later got dropped because it was only used for translation). Another breakthrough from this paper was the training; “The Transformer allows for significantly more parallelisation and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.” - This fact here was what let it: overtake RNNs (which weren’t parallelisable), and lead NVIDIA to be worth more than 2.7 Trillion token credits.</li></ul></div><div id="h0D85lJAzI" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="table-of-contents" class="relative group"><span class="heading-text">Table of contents</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#table-of-contents" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ul><li><span data-state="closed"><a href="#background" class="hover-link">Background</a></span><ul><li><a target="_blank" href="#data-types-math" rel="noreferrer">Data types and math operations</a></li><li><span data-state="closed"><a href="#tensors" class="hover-link">Tensors</a></span></li><li><a target="_blank" href="#math" rel="noreferrer">Math</a></li><li><span data-state="closed"><a href="#matrix-multiplication" class="hover-link">Matrix Multiplication</a></span></li></ul></li><li><span data-state="closed"><a href="#gpt" class="hover-link">GPT</a></span></li></ul></div><div id="uQEMaHWI9q" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="background" class="relative group"><span class="heading-text">Background</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#background" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Before we can dive into the transformer, we need to cover the basics:</p><ul><li>Datatypes</li><li>Matricies + Tensors</li><li>Matrix multiplication</li></ul></div><div id="G4ELFueuMB" class="relative group/block article-grid subgrid-gap col-screen"><p><a target="_blank" href="" rel="noreferrer"></a></p><h2 id="datatypes-and-math" class="relative group"><span class="heading-text">Datatypes and Math</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#datatypes-and-math" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Because we’re GPU poor, and because it makes the implementation easier, we use float32 for all parameters and calculations.</p><p>CPUs can either do calculations in 32 or 64 bits, but the go standard library is opinionated and only supports 64 bit math operations. This wraps all the math functions we need. Whilst all modern architectures have instructions for both float32 and float64 operations, float32 is still faster because it uses 1/2 the bits, so the throughput can be 2x the float64 (citation needed). This is an obvious optimisation for this implementation.</p><p>Because graphics applications aren’t needed to be precise, GPUs often use IEEE 754 half precision which is 16 bits, the training loss from switching from 32 -&gt; 16 bits is negligible. (citation needed)</p><h4 id="papers" class="relative group"><span class="heading-text">Papers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#papers" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><a href="https://en.wikipedia.org/wiki/IEEE_754" class="italic" target="_blank" rel="noreferrer" data-state="closed">IEEE-754</a> - I’ve linked the Wikipedia because you need to pay for the standard.</li></ul></div><div id="I3WmYzXhfL" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">import &quot;math&quot;

func Abs(x float32) float32 {
	if x &gt; 0 {
		return x
	}
	return -x
}

func Cosh(x float32) float32 {
	return float32(math.Cosh(float64(x)))
}

func Exp(x float32) float32 {
	return float32(math.Exp(float64(x)))
}

func Inf(sign int) float32 {
	return float32(math.Inf(sign))
}

func Log(x float32) float32 {
	return float32(math.Log(float64(x)))
}

func IsNaN(f float32) bool {
	return math.IsNaN(float64(f))
}

func Pow(x, y float32) float32 {
	return float32(math.Pow(float64(x), float64(y)))
}

func Sqrt(x float32) float32 {
	return float32(math.Sqrt(float64(x)))
}

func Tanh(x float32) float32 {
	return float32(math.Tanh(float64(x)))
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="V5c9ch2KY316dXWoA8-i1" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="urv8H1BGAZ" class="relative group/block article-grid subgrid-gap col-screen"><p><a target="_blank" href="" rel="noreferrer"></a></p><h2 id="tensors" class="relative group"><span class="heading-text">Tensors</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#tensors" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>What is a tensor?
A tensor is a multi-dimensional array. A regular slice is one-dimensional, holding elements in a sequence. A tensor can have multiple dimensions, like a 2D array (grid) or even a 3D array (cube).</p><p>Tensor libraries like pytorch or tensorflow exist in python. The most widely used tensor library for local inference is <a target="_blank" href="https://ggml.ai/" rel="noreferrer">https://ggml.ai/</a> which powers <a target="_blank" href="https://github.com/ggerganov/llama.cpp" rel="noreferrer">llama.cpp</a>.</p><figure id="zNT6onbkP5" class="fig-figure"><div style="text-align:center" class="leading-[0]"><div class="relative inline-block" style="padding-bottom:60%;width:min(max(100%, 500px), 100%)"><iframe width="100%" height="100%" src="https://www.youtube.com/embed/DfK83xEtJ_k" allowfullscreen="" allow="autoplay" style="width:100%;height:100%;position:absolute;top:0;left:0;border:none"></iframe></div></div><figcaption class="group"><p>What is a tensor</p></figcaption></figure></div><div id="nmJRxVtbcj" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">
type tensor struct {
	data []float32
	dims []int
    stride []int
}

func (t tensor) Data() []float32 {
	return t.data
}

func newTensor(data []float32, dims ...int) (tensor, int) {
	s := 1
	for _, d := range dims {
		s *= d
	}
	if s &gt; len(data) {
		panic(&quot;dimensions larger than supplied data&quot;)
	}
	ss := min(s, len(data))
	return tensor{
		data: data[:ss],
		dims: dims,
	}, ss
}

func (t tensor) size() int {
	size := 1
	for _, dim := range t.dims {
		size *= dim
	}
	return size
}

func (t tensor) index(idx ...int) tensor {
	// 1. Error Handling (Partially Adjusted)
	if len(idx) &gt; len(t.dims) {
		panic(&quot;Too many indices for tensor dimensions&quot;)
	}
	for i, dim := range idx {
		if dim &lt; 0 || dim &gt;= t.dims[i] {
			panic(&quot;Index out of bounds&quot;)
		}
	}
	// 2. Calculate Linear Index (Partially Adjusted)
	linearIndex := idx[0]
	stride := t.size()
	for i := 1; i &lt; len(idx); i++ {
		stride /= t.dims[i]
		linearIndex += idx[i] * stride
	}
	// 3. Adjust Dimensions and Return Sub-Tensor
	newDims := t.dims[len(idx):]                  // Keep remaining dimensions
	end := linearIndex + t.subTensorSize(newDims) // Size based on remaining dimensions

	return tensor{
		data: t.data[linearIndex:end],
		dims: newDims,
	}
}

// Helper function to calculate the size of a sub-tensor
func (t tensor) subTensorSize(idx []int) int {
	subTensorSize := 1
	for _, dim := range t.dims[len(idx):] {
		subTensorSize *= dim
	}
	return subTensorSize
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="O621W3B8-kUCA44u7CYhX" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="vppYIbJA5s" class="relative group/block article-grid subgrid-gap col-screen"><p><a target="_blank" href="" rel="noreferrer"></a></p><h2 id="matrix-multiplication" class="relative group"><span class="heading-text">Matrix Multiplication</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#matrix-multiplication" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>matmulForward performs matrix multiplication and adds bias.
Parameters:</p><ul><li>out: output matrix</li><li>inp: input matrix</li><li>weight: weight matrix</li><li>bias: bias vector</li><li>B: batch size</li><li>T: sequence length (number of time steps)</li><li>C: input dimension (number of features)</li><li>OC: number of output channels</li></ul><p>Most of the time spent in inference is in this function. Because we’re only doing this on a CPU this implemenation is very, very slow, and this is where different implementations would use a GPU/CUDA/Metal implementation to do parallel computation.</p><p>On CPU, many architectures have an optimisation called Basic Linear Algebra Subprograms <a target="_blank" href="https://netlib.org/blas/" rel="noreferrer">BLAS</a>. This allows for tiling (breaking matricies into smaller pieces and processing) or Single Instruction Multiple Data (SIMD).</p><figure id="D8uuRZ1LNc" class="fig-figure"><div style="text-align:center" class="leading-[0]"><div class="relative inline-block" style="padding-bottom:60%;width:min(max(100%, 500px), 100%)"><iframe width="100%" height="100%" src="https://www.youtube.com/embed?v=XkY2DOUCWMU" allowfullscreen="" allow="autoplay" style="width:100%;height:100%;position:absolute;top:0;left:0;border:none"></iframe></div></div><figcaption class="group"><p>Matrix multiplication</p></figcaption></figure></div><div id="YKeCcu5ZOW" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func matmulForward(out, inp, weight, bias []float32, B, T, C, OC int) {
	// Iterate over each batch
	var wg sync.WaitGroup
	for b := 0; b &lt; B; b++ {
		// Iterate over each time step in the sequence
		for t := 0; t &lt; T; t++ {
			wg.Add(1)
			go func(b, t int) {
				defer wg.Done()
				// Calculate the index in the output slice
				inp_bt := inp[b*T*C+t*C:]
				out_bt := out[b*T*OC+t*OC:]
				for o := 0; o &lt; OC; o++ {
					var val float32
					if bias != nil {
						val = bias[o]
					}
					// Calculate the index in the weight slice
					wrow := weight[o*C:]
					// Perform the dot product between the input and weight row
					for i := 0; i &lt; C; i++ {
						val += inp_bt[i] * wrow[i]
					}
					// Store the output value in the output slice
					out_bt[o] = val
				}
			}(b, t)
		}
	}
	wg.Wait()
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="oSebqDkoe8CesyXTere07" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="FuCvnOGQoc" class="relative group/block article-grid subgrid-gap col-screen"><p><a target="_blank" href="" rel="noreferrer"></a></p><h2 id="gpt" class="relative group"><span class="heading-text">GPT</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#gpt" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><img id="j2yES4Le4A" style="margin:0 auto" src="/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg" alt="decoder" data-canonical-url="decoder-only.svg"/></div><div id="cBXn9fJNS4" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="table-of-contents-1" class="relative group"><span class="heading-text">Table of contents</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#table-of-contents-1" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="parameters-vs-activations" class="relative group"><span class="heading-text">Parameters vs Activations</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#parameters-vs-activations" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li><p><span data-state="closed"><a href="#parameters" class="hover-link">Parameters</a></span> - The bulk of what makes up “the model”. Most of the bytes you download comes from this part.</p></li><li><p><span data-state="closed"><a href="#activations" class="hover-link">Activations</a></span> - Output of mathematical operations between the input and the parameters.</p></li></ul><h3 id="forward-pass" class="relative group"><span class="heading-text">Forward pass</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#forward-pass" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>A forward pass is the “inference” stage - this section is what’s occuring when you talk with ChatGPT.</p><h4 id="preparing" class="relative group"><span class="heading-text">Preparing</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#preparing" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>This section transforms text into a vector representation that can be processed by a neural network.</p><ul><li><span data-state="closed"><a href="#tokenizer" class="hover-link">Tokenizer</a></span> - Converts text to numeric ids that can be processed.</li><li><a target="_blank" href="#data" rel="noreferrer">Data Loading</a> - This section describes how data is loaded, including batching, tokenization, and offsetting.</li><li><span data-state="closed"><a href="#embedding" class="hover-link">Embedding</a></span> - Converts these ids into n dimensional vector space</li></ul><h4 id="n-layers" class="relative group"><span class="heading-text">N-Layers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#n-layers" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>This section is repeated for every layer. GPT-2 has 12 layers.</p><ul><li><a target="_blank" href="#masked-multi-head-attention" rel="noreferrer">Masked Multi-Head Attention</a> - Allows all tokens in the context window to impact other tokens in the context window</li><li><a target="_blank" href="#add-norm" rel="noreferrer">Add and Norm</a> - Adds residual stream and normalises outputs</li><li><a target="_blank" href="#feed-forward" rel="noreferrer">Feed Forward</a> - Feed forward is a standard MLP. Allows for more complex connections to be formed than just the attention mechanism alone.</li></ul><h4 id="final-transformations" class="relative group"><span class="heading-text">Final transformations</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#final-transformations" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>This section takes the higher dimensionality representations of our activations and processes it to give us our final output</p><ul><li><a target="_blank" href="#linear" rel="noreferrer">Linear</a> - Transformation that reduces dimensionality into “logits” which are correlated to how likely each token is (-inf==never, +inf=100% certainty)</li><li><span data-state="closed"><a href="#softmax" class="hover-link">Softmax</a></span> - This takes the logits and creates a probability distribution that adds up to 100%</li><li><span data-state="closed"><a href="#sampling" class="hover-link">Sampling</a></span> - This samples the probability distribution and returns the single token that’s needed to make the next prediction</li></ul><h4 id="a-complete-forward-pass" class="relative group"><span class="heading-text">A complete forward pass</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#a-complete-forward-pass" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>This section puts all of this together.</p><ul><li><span data-state="closed"><a href="#forward" class="hover-link">Forward</a></span></li></ul><h3 id="backwards-pass" class="relative group"><span class="heading-text">Backwards pass</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#backwards-pass" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>This is “training”. Companies spend billions of dollars optimizing to make this as fast as possible.</p><ul><li><span data-state="closed"><a href="#backward-pass" class="hover-link">Backward Pass</a></span> - Calculating the gradients for gradient descent + backprop.</li><li><a target="_blank" href="#optimizer" rel="noreferrer">Optimizer</a> - Determines how fast the model learns</li><li><a target="_blank" href="#training-our-model" rel="noreferrer">Training our model</a> - Let’s train gpt.</li></ul></div><div id="dbG0vKwe2O" class="relative group/block article-grid subgrid-gap col-screen"><p><a target="_blank" href="" rel="noreferrer"></a></p><h2 id="data-loading" class="relative group"><span class="heading-text">Data loading</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#data-loading" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="IHrcOUFTy5" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">import (
	&quot;bytes&quot;
	&quot;encoding/binary&quot;
	&quot;errors&quot;
	&quot;io&quot;
)

const Int32ByteLen = 4

type DataLoader struct {
	filename        string
	batchSize       int
	seqLength       int
	currentPosition int64
	fileSize        int64
	NumBatches      int
	data            []int32
	dataAll         []int32
}

func NewDataLoader(filename string, batchSize, seqLength int) (*DataLoader, error) {
	file, err := os.Open(filename)
	if err != nil {
		return nil, err
	}
	return newDataLoader(file, batchSize, seqLength)
}

func newDataLoader(file io.Reader, batchSize, seqLength int) (*DataLoader, error) {
	data, err := io.ReadAll(file)
	if err != nil {
		return nil, err
	}
	size := len(data)
	if size &lt; (batchSize*seqLength+1)*Int32ByteLen {
		return nil, errors.New(&quot;error: file size is too small for the batch size and sequence length&quot;)
	}
	loader := &amp;DataLoader{
		batchSize:  batchSize,
		seqLength:  seqLength,
		NumBatches: size / (batchSize * seqLength * Int32ByteLen),
		data:       make([]int32, size/Int32ByteLen),
		fileSize:   int64(size / Int32ByteLen),
	}
	if err := binary.Read(bytes.NewReader(data), binary.LittleEndian, loader.data); err != nil {
		return nil, err
	}
	return loader, nil
}

func newDataLoaderFromInts(data []int32, batchSize, seqLength int) (*DataLoader, error) {
	size := len(data)
	if size &lt; (batchSize*seqLength + 1) {
		return nil, errors.New(&quot;error: file size is too small for the batch size and sequence length&quot;)
	}
	loader := &amp;DataLoader{
		batchSize:  batchSize,
		seqLength:  seqLength,
		NumBatches: size / (batchSize * seqLength),
		data:       data,
		fileSize:   int64(size),
	}
	return loader, nil
}

func (loader *DataLoader) Reset() {
	loader.currentPosition = 0
}

func (loader *DataLoader) NextBatch() ([]int32, []int32, error) {
	nextPos := loader.currentPosition + int64(loader.batchSize*loader.seqLength)
	if nextPos+1 &gt; loader.fileSize {
		loader.Reset()
		nextPos = loader.currentPosition + int64(loader.batchSize*loader.seqLength)
	}
	// don&#x27;t  x4 because we&#x27;re indexing int32 not byte
	inputs := loader.data[loader.currentPosition:nextPos]
	targets := loader.data[loader.currentPosition+1 : nextPos+1]
	loader.currentPosition = nextPos
	return inputs, targets, nil
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ESRZpyrAxWkkMNwxz3X1T" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="Vd2yk9Kt3z" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="parameters" class="relative group"><span class="heading-text">Parameters <a target="_blank" href="" rel="noreferrer"></a></span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#parameters" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>A Parameter is a numerical value that determines the strength of the connection between neurons. These connections are similar to synapses in the human brain, and the parameters are like the knobs that adjust the strength of those connections.</p><p>There are two main types of parameters in neural networks:</p><ul><li><p>Weights: These are associated with each connection between neurons. They multiply the signal coming from one neuron before it’s passed on to the next neuron. A higher weight means a stronger connection and a greater influence on the receiving neuron.</p></li><li><p>Biases: These are added to the sum of the weighted inputs at each neuron. They act like a baseline shift, allowing the neuron to activate even if the weighted inputs are weak.</p></li></ul><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="WNNW4Lk13x" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">// ParameterTensors are the parameters of the model
type ParameterTensors struct {
	Memory        []float32
	WordTokEmbed  tensor // (V, C) - Word/Token Embedding weights (Vocabulary size, Embedding dimension)
	WordPosEmbed  tensor // (maxT, C) - Positional Embedding weights (Maximum Sequence length, Embedding dimension)
	LayerNorm1W   tensor // (L, C) - Weights for Layer Normalization 1 (Number of layers, Embedding dimension)
	LayerNorm1B   tensor // (L, C) - Biases for Layer Normalization 1
	QueryKeyValW  tensor // (L, 3*C, C) - Attention QKV weights (Layers, 3 * Embedding dimension, Embedding dimension)
	QueryKeyValB  tensor // (L, 3*C) - Attention QKV biases
	AttProjW      tensor // (L, C, C) - Attention projection weights (Layers, Embedding dimension, Embedding dimension)
	AttProjB      tensor // (L, C) - Attention projection biases
	Layer2NormW   tensor // (L, C) - Weights for Layer Normalization 2
	Layer2NormB   tensor // (L, C) - Biases for Layer Normalization 2
	FeedFwdW      tensor // (L, 4*C, C) - Feed-forward layer weights (Layers, 4 * Embedding Dimension, Embedding Dimension)
	FeedFwdB      tensor // (L, 4*C) - Feed-forward layer biases
	FeedFwdProjW  tensor // (L, C, 4*C) - Feed-forward projection weights
	FeedFwdProjB  tensor // (L, C)- Feed-forward projection biases
	LayerFinNormW tensor // (C) - Final layer normalization weights
	LayerFinNormB tensor // (C) - Final layer normalization biases
}

func newParameterTensors(V, C, maxSeqLen, L int) ParameterTensors {
	var tensor ParameterTensors
	tensor.Init(V, C, maxSeqLen, L)
	return tensor
}

func (tensor *ParameterTensors) Len() int {
	return len(tensor.Memory)
}

// Init initialises the ParameterTensors with specific sizes for each tensor based on the model architecture.
func (tensor *ParameterTensors) Init(V, C, maxSeqLen, L int) {
	tensor.Memory = make([]float32,
		V*C+ // WordTokEmbed
			maxSeqLen*C+ // WordPosEmbed
			L*C+ // LayerNorm1W
			L*C+ // LayerNorm1B
			L*3*C*C+ // QueryKeyValW
			L*3*C+ // QueryKeyValB
			L*C*C+ // AttProjW
			L*C+ // AttProjB
			L*C+ // Layer2NormW
			L*C+ // Layer2NormB
			L*4*C*C+ // FeedFwdW
			L*4*C+ // FeedFwdB
			L*C*4*C+ // FeedFwdProjW
			L*C+ // FeedFwdProjB
			C+ // LayerFinNormW
			C, // LayerFinNormB
	)
	var ptr int
	memPtr := tensor.Memory
	tensor.WordTokEmbed, ptr = newTensor(memPtr, V, C)
	memPtr = memPtr[ptr:]
	tensor.WordPosEmbed, ptr = newTensor(memPtr, maxSeqLen, C)
	memPtr = memPtr[ptr:]
	tensor.LayerNorm1W, ptr = newTensor(memPtr, L, C)
	memPtr = memPtr[ptr:]
	tensor.LayerNorm1B, ptr = newTensor(memPtr, L, C)
	memPtr = memPtr[ptr:]
	tensor.QueryKeyValW, ptr = newTensor(memPtr, L, 3*C, C)
	memPtr = memPtr[ptr:]
	tensor.QueryKeyValB, ptr = newTensor(memPtr, L, 3*C)
	memPtr = memPtr[ptr:]
	tensor.AttProjW, ptr = newTensor(memPtr, L, C, C)
	memPtr = memPtr[ptr:]
	tensor.AttProjB, ptr = newTensor(memPtr, L, C)
	memPtr = memPtr[ptr:]
	tensor.Layer2NormW, ptr = newTensor(memPtr, L, C)
	memPtr = memPtr[ptr:]
	tensor.Layer2NormB, ptr = newTensor(memPtr, L, C)
	memPtr = memPtr[ptr:]
	tensor.FeedFwdW, ptr = newTensor(memPtr, L, 4*C, C)
	memPtr = memPtr[ptr:]
	tensor.FeedFwdB, ptr = newTensor(memPtr, L, 4*C)
	memPtr = memPtr[ptr:]
	tensor.FeedFwdProjW, ptr = newTensor(memPtr, L, C, 4*C)
	memPtr = memPtr[ptr:]
	tensor.FeedFwdProjB, ptr = newTensor(memPtr, L, C)
	memPtr = memPtr[ptr:]
	tensor.LayerFinNormW, ptr = newTensor(memPtr, C)
	memPtr = memPtr[ptr:]
	tensor.LayerFinNormB, ptr = newTensor(memPtr, C)
	memPtr = memPtr[ptr:]
	if len(memPtr) != 0 {
		panic(&quot;something went real bad here&quot;)
	}
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="u6Jm6A9FVoYASzMY5q7T9" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="PINjjnWYTM" class="relative group/block article-grid subgrid-gap col-screen"><p><a target="_blank" href="" rel="noreferrer"></a></p><h2 id="activations" class="relative group"><span class="heading-text">Activations</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#activations" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>An activation is the output of the input, and a mathematical operation. If the weight determines the strength of the function, the activation is the output.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="imI5mQbZUf" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">
// ActivationTensors
type ActivationTensors struct {
	Memory             []float32
	Encoded            tensor // (B, T, C) - Initial encoded input representations (Batch size, Sequence length, Embedding dimension)
	Layer1Act          tensor // (L, B, T, C) - Activations after Layer Normalization 1
	LayerNorm1Mean     tensor // (L, B, T) - Mean values for Layer Normalization 1
	LayerNorm1Rstd     tensor // (L, B, T) - Reciprocal of standard deviation for Layer Normalization 1
	QueryKeyVal        tensor // (L, B, T, 3*C) - Combined Query, Key, Value representations for attention
	AttentionInter     tensor // (L, B, T, C) - Intermediate attention-like result
	PreAttention       tensor // (L, B, NH, T, T) - Pre-attention scores
	Attention          tensor // (L, B, NH, T, T) - Normalized attention weights (Number of layers, Batch size, Number of Attention Heads, Sequence length, Sequence length)
	AttentionProj      tensor // (L, B, T, C) - Projected attention outputs
	Residual2          tensor // (L, B, T, C) - Residual connection after attention
	LayerNorm2Act      tensor // (L, B, T, C) - Activations after Layer Normalization 2
	LayerNorm2Mean     tensor // (L, B, T) - Mean values for Layer Normalization 2
	LayerNorm2Rstd     tensor // (L, B, T) - Reciprocal of standard deviation for Layer Normalization 2
	FeedForward        tensor // (L, B, T, 4*C) - Intermediate Feed-Forward Network activations
	FeedForwardGelu    tensor // (L, B, T, 4*C) - FeedForward activations after applying GELU (non-linearity)
	FeedForwardProj    tensor // (L, B, T, C) - Projected output of the Feed-Forward Network
	Residual3          tensor // (L, B, T, C) - Residual connection after Feed-Forward Network
	LayerNormFinal     tensor // (B, T, C) - Final activations after Layer Normalization
	LayerNormFinalMean tensor // (B, T) - Mean values for final Layer Normalization
	LayerNormFinalStd  tensor // (B, T) - Reciprocal of standard deviation for final Layer Normalization
	Logits             tensor // (B, T, V) - Raw output scores (before softmax)
	Probabilities      tensor // (B, T, V) - Softmax probabilities over the vocabulary
	Losses             tensor // (B, T) - Loss values per token in the batch
}

func (tensor *ActivationTensors) Init(B, C, T, L, NH, V int) {
	tensor.Memory = make([]float32,
		B*T*C+
			L*B*T*C+
			L*B*T+
			L*B*T+
			L*B*T*C*3+
			L*B*T*C+
			L*B*NH*T*T+
			L*B*NH*T*T+
			L*B*T*C+
			L*B*T*C+
			L*B*T*C+
			L*B*T+
			L*B*T+
			L*B*T*C*4+
			L*B*T*C*4+
			L*B*T*C+
			L*B*T*C+
			B*T*C+
			B*T+
			B*T+
			B*T*V+
			B*T*V+
			B*T)
	var ptr int
	memPtr := tensor.Memory
	tensor.Encoded, ptr = newTensor(memPtr, B, T, C)
	memPtr = memPtr[ptr:]
	tensor.Layer1Act, ptr = newTensor(memPtr, L, B, T, C)
	memPtr = memPtr[ptr:]
	tensor.LayerNorm1Mean, ptr = newTensor(memPtr, L, B, T)
	memPtr = memPtr[ptr:]
	tensor.LayerNorm1Rstd, ptr = newTensor(memPtr, L, B, T)
	memPtr = memPtr[ptr:]
	tensor.QueryKeyVal, ptr = newTensor(memPtr, L, B, T, C*3)
	memPtr = memPtr[ptr:]
	tensor.AttentionInter, ptr = newTensor(memPtr, L, B, T, C)
	memPtr = memPtr[ptr:]
	tensor.PreAttention, ptr = newTensor(memPtr, L, B, NH, T, T)
	memPtr = memPtr[ptr:]
	tensor.Attention, ptr = newTensor(memPtr, L, B, NH, T, T)
	memPtr = memPtr[ptr:]
	tensor.AttentionProj, ptr = newTensor(memPtr, L, B, T, C)
	memPtr = memPtr[ptr:]
	tensor.Residual2, ptr = newTensor(memPtr, L, B, T, C)
	memPtr = memPtr[ptr:]
	tensor.LayerNorm2Act, ptr = newTensor(memPtr, L, B, T, C)
	memPtr = memPtr[ptr:]
	tensor.LayerNorm2Mean, ptr = newTensor(memPtr, L, B, T)
	memPtr = memPtr[ptr:]
	tensor.LayerNorm2Rstd, ptr = newTensor(memPtr, L, B, T)
	memPtr = memPtr[ptr:]
	tensor.FeedForward, ptr = newTensor(memPtr, L, B, T, C*4)
	memPtr = memPtr[ptr:]
	tensor.FeedForwardGelu, ptr = newTensor(memPtr, L, B, T, C*4)
	memPtr = memPtr[ptr:]
	tensor.FeedForwardProj, ptr = newTensor(memPtr, L, B, T, C)
	memPtr = memPtr[ptr:]
	tensor.Residual3, ptr = newTensor(memPtr, L, B, T, C)
	memPtr = memPtr[ptr:]
	tensor.LayerNormFinal, ptr = newTensor(memPtr, B, T, C)
	memPtr = memPtr[ptr:]
	tensor.LayerNormFinalMean, ptr = newTensor(memPtr, B, T)
	memPtr = memPtr[ptr:]
	tensor.LayerNormFinalStd, ptr = newTensor(memPtr, B, T)
	memPtr = memPtr[ptr:]
	tensor.Logits, ptr = newTensor(memPtr, B, T, V)
	memPtr = memPtr[ptr:]
	tensor.Probabilities, ptr = newTensor(memPtr, B, T, V)
	memPtr = memPtr[ptr:]
	tensor.Losses, ptr = newTensor(memPtr, B, T)
	memPtr = memPtr[ptr:]
	if len(memPtr) != 0 {
		panic(&quot;something went real bad here&quot;)
	}
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="MIx-DAG_p_LUz9KXKBLsS" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="bevELSVr2m" class="relative group/block article-grid subgrid-gap col-screen"><p><a target="_blank" href="" rel="noreferrer"></a></p><h2 id="tokenizer" class="relative group"><span class="heading-text">Tokenizer</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#tokenizer" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><img id="OrFj2FQrt1" style="margin:0 auto" src="/build/tokenization-eb5de751dbe589c933f44323d83d5ddc.svg" alt="tokenization" data-canonical-url="tokenization.svg"/><p>Tokenization is the fundamental process of transforming text data into a format the model can understand. It involves breaking down sentences into smaller units called tokens.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="wwgnQbRzJ7" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">import (
	&quot;encoding/binary&quot;
	&quot;encoding/json&quot;
	&quot;errors&quot;
	&quot;os&quot;
	&quot;sort&quot;
)

const GPT2_EOT int32 = 50256

type Tokenizer struct {
	vocabSize  uint32
	tokenTable []string         // tokenTable maps token id to string
	tokenMap   map[string]int32 // tokenMap maps token to id
	init       bool
}

func newTokenizer(vocab []string) Tokenizer {
	tokenizer := Tokenizer{
		vocabSize:  uint32(len(vocab)),
		tokenTable: vocab,
		tokenMap:   make(map[string]int32),
		init:       true,
	}
	for i, token := range vocab {
		tokenizer.tokenMap[token] = int32(i)
	}
	return tokenizer
}

func NewTokenizer(filename string) (Tokenizer, error) {
	f, err := os.Open(filename)
	if err != nil {
		return Tokenizer{}, err
	}
	defer f.Close()
	header := make([]uint32, 256)
	if err := binary.Read(f, binary.LittleEndian, header); err != nil {
		return Tokenizer{}, err
	}
	if header[0] != 20240328 || header[1] != 1 {
		return Tokenizer{}, errors.New(&quot;incorrect header for tokenizer&quot;)
	}
	tok := Tokenizer{
		vocabSize:  header[2],
		tokenTable: make([]string, header[2]),
		tokenMap:   make(map[string]int32),
		init:       true,
	}
	var length byte
	for i := range tok.tokenTable {
		if err := binary.Read(f, binary.LittleEndian, &amp;length); err != nil {
			return tok, err
		}
		if length &lt;= 0 {
			return tok, errors.New(&quot;tokenizer failure&quot;)
		}
		tokenBytes := make([]byte, length)
		if err := binary.Read(f, binary.LittleEndian, tokenBytes); err != nil {
			return tok, err
		}
		tok.tokenTable[i] = string(tokenBytes)
		tok.tokenMap[tok.tokenTable[i]] = int32(i)
	}
	return tok, nil
}

type TokenizerJSON struct {
	Version string `json:&quot;version&quot;`
	Model   struct {
		Type          string            `json:&quot;type&quot;`
		Vocab         map[string]int    `json:&quot;vocab&quot;`
		MergesData    []string          `json:&quot;merges,omitempty&quot;`
		SpecialTokens map[string]string `json:&quot;special_tokens&quot;`
	} `json:&quot;model&quot;`
}

func NewTokenizerJson(filename string) (Tokenizer, error) {
	// Read the JSON file
	fileContent, err := os.ReadFile(filename)
	if err != nil {
		return Tokenizer{}, err
	}

	// Unmarshal JSON into our struct
	var tokenizerData TokenizerJSON
	if err := json.Unmarshal(fileContent, &amp;tokenizerData); err != nil {
		return Tokenizer{}, err
	}

	// Create a new Tokenizer instance
	tok := Tokenizer{
		vocabSize:  uint32(len(tokenizerData.Model.Vocab)),
		tokenTable: make([]string, len(tokenizerData.Model.Vocab)),
		tokenMap:   make(map[string]int32),
		init:       true,
	}

	// Create a slice of token-id pairs for sorting
	var tokenIDPairs []struct {
		Token string
		ID    int
	}
	for token, id := range tokenizerData.Model.Vocab {
		// Convert the first two bytes to the &#x27;Ġ&#x27; character if they match 0xC4 0xA0
		if len(token) &gt;= 2 &amp;&amp; token[0] == 0xC4 &amp;&amp; token[1] == 0xA0 {
			token = &quot; &quot; + token[2:]
		}
		tokenIDPairs = append(tokenIDPairs, struct {
			Token string
			ID    int
		}{token, id})
	}

	// Sort the token-id pairs by ID
	sort.Slice(tokenIDPairs, func(i, j int) bool {
		return tokenIDPairs[i].ID &lt; tokenIDPairs[j].ID
	})

	// Populate tokenTable and tokenMap
	for i, pair := range tokenIDPairs {
		tok.tokenTable[i] = pair.Token
		tok.tokenMap[pair.Token] = int32(i)
	}

	return tok, nil
}

func (t Tokenizer) Decode(tokens []int32) (string, error) {
	s := &quot;&quot;
	for _, token := range tokens {
		if token &gt;= int32(len(t.tokenTable)) {
			return &quot;&quot;, errors.New(&quot;not valid token&quot;)
		}
		if token != GPT2_EOT {
			s += t.tokenTable[token]
		}
	}
	return s, nil
}

func (t Tokenizer) Encode(text string) ([]int32, error) {
	tokens := []int32{}
	for len(text) &gt; 0 {
		longestMatch := &quot;&quot;
		longestMatchToken := int32(GPT2_EOT)
		for i := len(text); i &gt; 0; i-- {
			subStr := text[:i]
			if token, exists := t.tokenMap[subStr]; exists {
				longestMatch = subStr
				longestMatchToken = token
				break
			}
		}
		if longestMatch == &quot;&quot; {
			// If no match found, treat the first character as an unknown token
			tokens = append(tokens, GPT2_EOT)
			text = text[1:]
		} else {
			tokens = append(tokens, longestMatchToken)
			text = text[len(longestMatch):]
		}
	}
	return tokens, nil
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="xVKCLRsdGCditfB7D7Sbf" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="Xbtnxq9ivz" class="relative group/block article-grid subgrid-gap col-screen"><h3 id="tokenize-some-text" class="relative group"><span class="heading-text">Tokenize some text</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#tokenize-some-text" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="SF2Sl3g9LR" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">%%
tokenizer, err := NewTokenizerJson(&quot;/Users/joshcarp/Documents/the-interactive-transformer/tokenizer.json&quot;); if err != nil {
    panic(err)
}
gonbui.RequestInput(&quot;Tokenize some text: &quot;, false)
reader := bufio.NewReader(os.Stdin)
inputText, err := reader.ReadString(&#x27;\n&#x27;)
if err != nil {
    panic(err)
}
if err != nil { panic(err) }
encoded, err := tokenizer.Encode(inputText)
fmt.Println(&quot;encoded: &quot;, encoded)
decoded, err := tokenizer.Decode(encoded)
fmt.Println(&quot;decoded: &quot;, decoded)
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="rIqHsKt0O5LY8g2VmhDt0" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>encoded:  [31373 612 220 50256]
decoded:  hello there 
</span></code></pre></div></div></div><div id="sPx9nm8AGm" class="relative group/block article-grid subgrid-gap col-screen"><p><a target="_blank" href="" rel="noreferrer"></a></p><h3 id="embedding" class="relative group"><span class="heading-text">Embedding</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#embedding" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><img id="Yj1WatSFAl" style="margin:0 auto" src="/build/embedding-6c47d2fc652eac0e4773bd7f9cdc736c.svg" alt="embeddings" data-canonical-url="embedding.svg"/><p>encoderForward iterates through the batch/sequence and combines the word token embeddings
with the word position embeddings. This allows out vector to encode tokens and positions in one vector.</p><figure id="QqyihuMXzb" class="fig-figure"><div style="text-align:center" class="leading-[0]"><div class="relative inline-block" style="padding-bottom:60%;width:min(max(100%, 500px), 100%)"><iframe width="100%" height="100%" src="https://www.youtube.com/embed?v=gQddtTdmG_8" allowfullscreen="" allow="autoplay" style="width:100%;height:100%;position:absolute;top:0;left:0;border:none"></iframe></div></div><figcaption class="group"><p>Word embeddings</p></figcaption></figure><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="yx6FAVSP5R" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func encoderForward(out []float32, inp []int32, wte []float32, wpe []float32, B, T, C int) {
	// Iterate over each batch
	for b := 0; b &lt; B; b++ {
		// Iterate over each time step in the sequence
		for t := 0; t &lt; T; t++ {
			// Calculate the index in the output slice. Each vector is C elements long.
			startOutIndex := b*T*C + t*C
			// Calculate the token ID index in the input
			// inp is the tokenized input, each number in inp char is an index within wte (word token embeddings)
			ix := inp[b*T+t]
			// Calculate the index in the token embeddings slice
			// inp -&gt; id -&gt; wte[id]
			startWteIndex := ix * int32(C)
			// Calculate the index in the position embeddings slice
			// Wpe starts at 0 (when t is zero) which is basically mapping directly to index
			startWpeIndex := t * C
			// Add the vectors from `wte` and `wpe` and store the result in `out`
			// here we combine the vectors in the C dimensions.
			for i := 0; i &lt; C; i++ {
				out[startOutIndex+i] = wte[startWteIndex+int32(i)] + wpe[startWpeIndex+i]
			}
		}
	}
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="LPkMp0cq_3-hDzt7z4pWq" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="wLVeVlkUaq" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">%test
func TestEncoderForwardExplicit(t *testing.T) {
    inp := []int32{1, 0} // [1 -&gt; wte (2, 3), wpe(4, 5)] [0 -&gt; wte (0, 1), wpe(6, 7)]
    wte := []float32{0, 1, 2, 3}
    wpe := []float32{4, 5, 6, 7}
    B := 1 // Batch size
    T := 1 // Sequence Len
    C := 2 // Dimensions
    out := make([]float32, len(inp))
    encoderForward(out, inp, wte, wpe, B, T, C)
    expectedOut := []float32{6, 8}
    assert.Equal(t, expectedOut, out)
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="CoqMMq69KETxqRiuEz_dW" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>=== RUN   TestEncoderForwardExplicit
--- PASS: TestEncoderForwardExplicit (0.00s)
PASS
</span></code></pre></div></div></div><div id="uR5oQC8ss6" class="relative group/block article-grid subgrid-gap col-screen"><p><a target="_blank" href="" rel="noreferrer"></a></p><h2 id="layernorm-forward" class="relative group"><span class="heading-text">Layernorm forward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#layernorm-forward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>layernormForward normalizes the activations in each layer.
It improves convergence in training and reduces sensitivity to initial parameters.
For each vector, the mean and variance are calculated.</p><p>Parameters:</p><ul><li>out: output activations (B,T,C)</li><li>mean: mean values (B,T) for each position (b,t)</li><li>rstd: reciprocal standard deviations (B,T) for each position (b,t)</li><li>inp: input activations (B,T,C)</li><li>weight: learnable weight (C) for scaling</li><li>bias: learnable bias (C) for shifting</li><li>B: batch size</li><li>T: sequence length (number of time steps)</li><li>C: embedding dimension (number of features)</li></ul><h4 id="papers-1" class="relative group"><span class="heading-text">Papers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#papers-1" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><a target="_blank" href="https://arxiv.org/abs/1607.06450" rel="noreferrer"><strong>Layer Normalization</strong></a> - Layernorm was introduced in this paper.</li></ul><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="Q4VRoFTo3F" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func layernormForward(out, mean, rstd, inp, weight, bias []float32, B, T, C int) {
	var eps float32 = 1e-5
	for b := 0; b &lt; B; b++ {
		for t := 0; t &lt; T; t++ {
			x := inp[b*T*C+t*C:]
			// Calculate mean
			var m float32 = 0.0
			for i := 0; i &lt; C; i++ {
				m += x[i]
			}
			m /= float32(C)
			// Calculate variance
			var v float32 = 0.0
			for i := 0; i &lt; C; i++ {
				xshift := x[i] - m
				v += xshift * xshift
			}
			v /= float32(C)
			// Calculate rstd (reciprocal standard deviation)
			s := 1.0 / Sqrt((v)+eps)
			// Normalize, scale, shift, and store output
			outBT := out[b*T*C+t*C:]
			for i := 0; i &lt; C; i++ {
				// subtract mean to center data
				// divide by std to scale variance
				// (val - mean) / std
				n := s * (x[i] - m)
				// Multiply the weight
				o := n*weight[i] + bias[i]
				outBT[i] = o
			}
			// Store mean and rstd for backward pass
			mean[b*T+t] = m
			rstd[b*T+t] = s
		}
	}
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ozfJifEL8FjtBDdPH6q_m" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="ionz2tmG9M" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="attentionforward" class="relative group"><span class="heading-text">AttentionForward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#attentionforward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><img id="V0inJS6GcD" style="margin:0 auto" src="/build/attention-8549d71863b9608e2d90d8942b571ddd.svg" alt="attention" data-canonical-url="attention.svg"/><p>attentionForward performs the attention forward pass.</p><p>attention is the only layer that mixes information across time
every other operation is applied at every (b,t) position independently
(and of course, no layer mixes information across batch)</p><p>Parameters:</p><ul><li>out: output matrix (B,T,C)</li><li>preatt: pre-attention scores (B,NH,T,T)</li><li>att: post-attention scores (B,NH,T,T)</li><li>inp: input matrix (B,T,3C) holding Query, Key, Value vectors</li><li>B: batch size</li><li>T: sequence length (number of time steps)</li><li>C: input dimension (number of features)</li><li>NH: number of attention heads</li></ul><h4 id="papers-2" class="relative group"><span class="heading-text">Papers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#papers-2" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><a target="_blank" href="https://arxiv.org/abs/1706.03762v7" rel="noreferrer"><strong>Attention Is All You Need</strong></a> - The attention mechanism was introduced in the original transformer paper.</li></ul><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="xoAP1IpSbq" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func attentionForward(out, preatt, att, inp []float32, B, T, C, NH int) {
	C3 := C * 3  // This is the dimensions for the key, query and values
	hs := C / NH // head size
	scale := 1.0 / Sqrt(float32(hs))
	// Iterate over batch, sequence length, and number of heads
	var wg sync.WaitGroup
	for b := 0; b &lt; B; b++ {
		// Sequence length
		for t := 0; t &lt; T; t++ {
			for h := 0; h &lt; NH; h++ {
				wg.Add(1)
				go func(b, t, h int) {
					defer wg.Done()
					// Calculate indices for query, pre-attention, and attention arrays
					// query is any particular input asking for information from other inputs
					queryT := inp[b*T*C3+t*C3+h*hs:] // inp[B][T][C3]
					preattBth := preatt[b*NH*T*T+h*T*T+t*T:]
					attBth := att[b*NH*T*T+h*T*T+t*T:]
					// Pass 1: Calculate query dot key and max value
					// The dot product is described in the paper as being better because
					// it can be optimized with matrix multiplication
					var maxval float32 = -10000.0
					// range from 0 to the current inp
					for t2 := 0; t2 &lt;= t; t2++ {
						// Calculate key index for t2
						key_t2 := inp[b*T*C3+t2*C3+h*hs+C:] // +C because it&#x27;s key
						// Compute dot product and update max value
						var val float32
						for i := 0; i &lt; hs; i++ {
							val += queryT[i] * key_t2[i]
						}
						val *= scale
						if val &gt; maxval {
							maxval = val
						}
						// preatt[b][h][t1][t2] == dot product (similarity) between query vector at position t1 and
						// key vector at t2.
						preattBth[t2] = val
					}
					// Pass 2: Calculate the exp and keep track of sum
					// Calculate exponential sum and update preatt and att arrays
					// maps the max value to zero,
					// and everything else negative.
					// when the exp function is called then the range of numbers will be
					// between 0 and e.
					var expsum float32
					for t2 := 0; t2 &lt;= t; t2++ {
						expv := Exp((preattBth[t2]) - maxval)
						// expsum is a sum of all the exp&#x27;d pre_att values
						expsum += expv
						// att_bth[t2] is the exp&#x27;d preatt_bth[t2]
						attBth[t2] = expv
					}
					var expsum_inv float32
					if expsum != 0.0 {
						expsum_inv = 1.0 / expsum
					}
					// Pass 3: Normalize to get softmax
					// from 0 -&gt; t2: att_bth[t2] = exp(preatt[t2]) / sum(exp(preatt[:]))
					// for everything else it&#x27;s zero
					for t2 := 0; t2 &lt; T; t2++ {
						if t2 &lt;= t {
							attBth[t2] *= expsum_inv
						} else {
							// Causal attention mask (optional; used for debugging and comparison)
							attBth[t2] = 0.0
						}
					}

					// Pass 4: Accumulate weighted values into the output of attention
					// out = attention * values
					// The values in this instance are the initial token/position embeddings that have gone through many linear
					// transformations at this point.
					// This is simply applying the learned attention &quot;weights&quot; to the lkqv values.
					// These weights must change a whole bunch after back propagation.
					out_bth := out[b*T*C+t*C+h*hs:]
					for i := 0; i &lt; hs; i++ {
						out_bth[i] = 0.0
					}
					for t2 := 0; t2 &lt;= t; t2++ {
						value_t2 := inp[b*T*C3+t2*C3+h*hs+C*2:] // +C*2 because it&#x27;s value
						att_btht2 := attBth[t2]
						for i := 0; i &lt; hs; i++ {
							out_bth[i] += att_btht2 * value_t2[i]
						}
					}
				}(b, t, h)
			}
		}
	}
	wg.Wait()
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="yP_oaMNOTzaBtK7JWTuH6" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="VJ5QZDe65d" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">%test
func TestAttentionForward(t *testing.T) {
	type args struct {
		inp []float32
		B   int
		T   int
		C   int
		NH  int
	}
	tests := []struct {
		name       string
		args       args
		wantOut    []float32
		wantPreatt []float32
		wantAtt    []float32
	}{
		{
			name: &quot;Small Input Test&quot;,
			args: args{
				inp: []float32{1, 2, 3, 4, 5, 6},
				B:   1,
				T:   1,
				C:   2,
				NH:  1,
			},
			wantOut:    []float32{5, 6},
			wantPreatt: []float32{7.7781744},
			wantAtt:    []float32{1},
		},
		{
			name: &quot;Larger Input Test&quot;,
			args: args{
				inp: []float32{ // (B, T, C3)
					/* B = 1 */
					/* T =  0 */
					/*qry*/ 1, 2, 3, // query compared against (4, 5, 6) but not (13, 14, 15) because it&#x27;s in the future (t=1)
					/*key*/ 4, 5, 6,
					/*val*/ 7, 8, 9,
					/* T =  1 */
					/*qry*/ 10, 11, 12, // will be compared against (4, 5, 6) (t-1) and (13, 14, 15)
					/*key*/ 13, 14, 15,
					/*val*/ 16, 17, 18, // vals are updated to
				},
				B:  1,
				T:  2,
				C:  3,
				NH: 1,
			},
			wantOut: []float32{ // (B, T, C)
				/*      B = 0       */
				/*      T = 0       */
				/* C =  0    1    2 */
				/*  */ 7, 8, 9,
				/* T = 1 */
				/* C =  0    1    2 */
				/*  */ 16, 17, 18,
			},
			wantPreatt: []float32{ // (B, NH, T, T)
				/* B =  0    */
				/* NH = 0    */
				/*T =   1  2 */
				/*T=1*/ 18.475208, 0, // preatt: 18 -&gt; 1, 0 -&gt; 0
				/*T=2*/ 96.417496, 267.89053, // 96 -&gt; 9, 267 -&gt; 1
			},
			wantAtt: []float32{ // (B, NH, T, T)
				/* B = 0     */
				/* NH = 0    */
				/*T =   1  2 */
				/*T=1*/ 1, 0,
				/*T=2*/ 0, 1,
			},
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			out, preatt, att := make([]float32, len(tt.wantOut)), make([]float32, len(tt.wantPreatt)), make([]float32, len(tt.wantAtt))
			attentionForward(out, preatt, att, tt.args.inp, tt.args.B, tt.args.T, tt.args.C, tt.args.NH)
			assert.InDeltaSlice(t, tt.wantOut, out, 1e-4, fmt.Sprintf(&quot;want: %v got: %v&quot;, tt.wantOut, out))
			assert.InDeltaSlice(t, tt.wantPreatt, preatt, 1e-4, fmt.Sprintf(&quot;want: %v got: %v&quot;, tt.wantPreatt, preatt))
			assert.InDeltaSlice(t, tt.wantAtt, att, 1e-4, fmt.Sprintf(&quot;want: %v got: %v&quot;, tt.wantAtt, att))
		})
	}
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="lIYO-g3S6etjMYIVb4NqF" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>=== RUN   TestAttentionForward
=== RUN   TestAttentionForward/Small_Input_Test
=== RUN   TestAttentionForward/Larger_Input_Test
--- PASS: TestAttentionForward (0.00s)
    --- PASS: TestAttentionForward/Small_Input_Test (0.00s)
    --- PASS: TestAttentionForward/Larger_Input_Test (0.00s)
PASS
</span></code></pre></div></div></div><div id="LNlBq0lRJf" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="residual-forward" class="relative group"><span class="heading-text">Residual forward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#residual-forward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><img id="YewX2rSkVF" style="margin:0 auto" src="/build/residual-f4c8ca201cf38843afcbd05e356dbb20.svg" alt="residual" data-canonical-url="residual.svg"/><p>residualForward implements a simple residual connection, a common technique used in deep neural networks to improve training and performance.</p><h4 id="papers-3" class="relative group"><span class="heading-text">Papers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#papers-3" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><a target="_blank" href="https://arxiv.org/pdf/1512.03385" rel="noreferrer"><strong>Deep Residual Learning for Image Recognition</strong></a> - The introduction of residuals allowed for deeper networks. Before this paper the depth of a neural network was limited because it would diverge enough and back propagation was really, really difficult to do because of vanishing gradients. Residuals essentially have a “short circuit” past a block which limits how much the neural networks can influence.</li></ul><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="RSLckvjfJx" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func residualForward(out, inp1, inp2 []float32, N int) {
	for i := 0; i &lt; N; i++ {
		out[i] = inp1[i] + inp2[i]
	}
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="2Amsrj0ilye91KP2pNQsL" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="tsFfHfOw3T" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="geluforward" class="relative group"><span class="heading-text">geluForward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#geluforward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The geluForward function applies the GELU activation to the input values stored in the inp slice and writes the activated values to the out slice.</p><p>geluForward is the Gaussian Error Linear Units activation function.
It leaves positive values mostly unchanged but
maps negative value close to zero.
This introduces “non-linearity” to the neural network and allows for the model to fit to functions that aren’t just linear regressions.</p><h4 id="papers-4" class="relative group"><span class="heading-text">Papers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#papers-4" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><a target="_blank" href="https://arxiv.org/abs/1606.08415v5" rel="noreferrer"><strong>Gaussian Error Linear Units (GELUs)</strong></a> - Activation function that leaves positive values unchanged but maps negative numbers to near zero. Other architectures use different activation functions. For example, OpenElm uses SwiGLU.</li></ul><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="OgjAHN1aeK" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">var GELUSCALEFACTOR = Sqrt(2.0 / math.Pi)
func geluForward(out, inp []float32, n int) {
	for i := 0; i &lt; n; i++ {
		x := inp[i]
		cube := 0.044715 * x * x * x
		out[i] = 0.5 * x * (1.0 + Tanh(GELUSCALEFACTOR*(x+cube)))
	}
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="kCOczTi49L1lyyQOp2cei" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="JxBvEsx5ua" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="softmax" class="relative group"><span class="heading-text">Softmax</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#softmax" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="bEIlcyrZCU" class="relative group/block article-grid subgrid-gap col-screen"><p>softmaxForward calculates the softmax probabilities for a batch of input logits, converting them into a probability distribution over multiple classes. It’s a common operation in neural networks, especially for classification tasks.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="LM9M8M1FwB" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func softmaxForward(probs, logits []float32, B, T, V int) {
	var wg sync.WaitGroup
	for b := 0; b &lt; B; b++ {
		for t := 0; t &lt; T; t++ {
			wg.Add(1)
			go func(b, t int) {
				defer wg.Done()
				baseIndex := b*T*V + t*V
				logitsBT := logits[baseIndex : baseIndex+V]
				probsBT := probs[baseIndex : baseIndex+V]
				// Numerical Stability
				var maxval float32 = -10000.0
				for i := 0; i &lt; V; i++ {
					if logitsBT[i] &gt; maxval {
						maxval = logitsBT[i]
					}
				}
				// Calculate exponentials and sum
				var sum float32
				for i := 0; i &lt; V; i++ {
					probsBT[i] = Exp((logitsBT[i] - maxval))
					sum += probsBT[i] // Using float32 for potential precision gain
				}
				// Normalize
				for i := 0; i &lt; V; i++ {
					probsBT[i] /= sum
				}
			}(b, t)
		}
	}
	wg.Wait()
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="OJhqPi4iBJblLrTuri-AH" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="x7mwEWxaTm" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="crossentropyforward" class="relative group"><span class="heading-text">CrossEntropyForward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#crossentropyforward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The function crossEntropyForward calculates the cross-entropy loss for a batch of predicted probability distributions and their corresponding target labels.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="s6a8EnrY5x" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">// crossEntropyForward
func crossEntropyForward(losses []float32, probs []float32, targets []int32, B, T, V int) {
	// Iterate over each batch
	for b := 0; b &lt; B; b++ {
		// Iterate over each time step in the sequence
		for t := 0; t &lt; T; t++ {
			// Calculate the index in the probability slice
			startIndex := int32(b*T*V + t*V)
			// Get the correct index in the logits for the current batch and time step
			ix := targets[b*T+t]
			// Calculate the cross-entropy loss
			prob := probs[startIndex+ix]
			// Calculate the negative log of the probability for the correct target index
			losses[b*T+t] = -Log((prob))
		}
	}
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="PGrJqko2tW5D-JZ-Kxv9J" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="zCxC1EBwBi" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="putting-it-all-together" class="relative group"><span class="heading-text">Putting it all together</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#putting-it-all-together" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="zecfmgu8Ta" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">type GPT2Config struct {
	MaxSeqLen int `json:&quot;max_seq_len&quot;`
	V         int `json:&quot;vocab_size&quot;`
	L         int `json:&quot;num_layers&quot;`
	NH        int `json:&quot;num_heads&quot;`
	C         int `json:&quot;channels&quot;`
	EOT       int32
}


type GPT2 struct {
	Tokenizer Tokenizer
	Config    GPT2Config // Hyper-parameters of the model
	// Params has the actual weights of the model. Params.Memory is for convenience to be able to set/reset parameters simply
	Params ParameterTensors // Weights of the model
	// Grads contains the delta/gradient that will eventually be applied to the params in the model
	Grads ParameterTensors // Gradients of the weights
	// Fields for AdamW optimizer
	MMemory []float32         // First moment estimates (for AdamW)
	VMemory []float32         // Second moment estimates (for AdamW)
	Acts    ActivationTensors // Activations of the model
	// gradients of the activations
	GradsActs ActivationTensors
	B         int     // Current batch size (B)
	T         int     // Current sequence length (T)
	Inputs    []int32 // Input tokens
	Targets   []int32 // Target tokens
	MeanLoss  float32 // Mean loss after a forward pass
	Rand      *rand.Rand
}


func loadFromReader(f io.Reader) (*GPT2, error) {
	header := make([]int32, 256)
	err := binary.Read(f, binary.LittleEndian, header)
	if err != nil {
		return nil, fmt.Errorf(&quot;error reading model header: %v&quot;, err)
	}
	if header[0] != 20240326 || header[1] != 1 {
		return nil, fmt.Errorf(&quot;bad model file format&quot;)
	}
	model := &amp;GPT2{
		Config: GPT2Config{
			MaxSeqLen: int(header[2]),
			V:         int(header[3]),
			L:         int(header[4]),
			NH:        int(header[5]),
			C:         int(header[6]),
			EOT:       GPT2_EOT,
		},
		Rand: rand.New(rand.NewSource(21)),
	}
	model.Params.Init(model.Config.V, model.Config.C, model.Config.MaxSeqLen, model.Config.L)
	if err := binary.Read(f, binary.LittleEndian, model.Params.Memory); err != nil {
		return nil, fmt.Errorf(&quot;error reading model: %v&quot;, err)
	}
	return model, nil
}
// LoadGPT2Model loads the GPT-2 model from a checkpoint file.
func LoadGPT2Model(checkpointPath, tokenizerFile string) (*GPT2, error) {
	// File Reading
	f, err := os.Open(checkpointPath)
	if err != nil {
		return nil, fmt.Errorf(&quot;Error opening model file: %v&quot;, err)
	}
	defer f.Close()
	// Read Model Header
	model, err := loadFromReader(f)
	if err != nil {
		return nil, err
	}
	if tokenizerFile == &quot;&quot; {
		return model, err
	}
	tok, err := NewTokenizer(tokenizerFile)
	if err != nil {
		return nil, err
	}
	model.Tokenizer = tok
	return model, nil
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="6XhtS7FGfUhMUeyjj0xWX" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="aGpEGLkc2i" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="forward" class="relative group"><span class="heading-text">Forward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#forward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The function Forward implements the forward pass of a GPT-2 language model. It takes a sequence of input tokens and a sequence of target tokens (if available) as input, and it calculates the model’s output probabilities for the next token in the sequence.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="LqxwFIuZW0" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func (model *GPT2) Forward(input, target []int32, B, T int) {
	V, L, NH, C := model.Config.V, model.Config.L, model.Config.NH, model.Config.C
	if model.Acts.Memory == nil {
		model.B, model.T = B, T
		model.Acts.Init(B, C, T, L, NH, V)
		model.Inputs = make([]int32, B*T)
		model.Targets = make([]int32, B*T)
	}
	copy(model.Inputs, input)
	copy(model.Targets, target)
	params, acts := model.Params, model.Acts
	// This encodes the word token embeddings with the positional embeddings
	// so that those vectors have spacial information and aren&#x27;t just purely made up of the
	// token embeddings. The result of this is stored in acts.Encoded.
	// Input is a slice of ids/tokens that correspond to the vectors in WTE and their index is the &quot;position&quot;
	encoderForward(acts.Encoded.data, input, params.WordTokEmbed.data, params.WordPosEmbed.data, B, T, C)
	var residual []float32
	for l := 0; l &lt; L; l++ {
		// residual is a connection between the last layers output, or the initial token/pos embedding (as applied above)
		if l == 0 {
			residual = acts.Encoded.data
		} else {
			residual = acts.Residual3.data[(l-1)*B*T*C:]
		}
		// Parameters
		l_ln1w := params.LayerNorm1W.data[l*C:]
		l_ln1b := params.LayerNorm1B.data[l*C:]
		l_qkvw := params.QueryKeyValW.data[l*3*C*C:]
		l_qkvb := params.QueryKeyValB.data[l*3*C:]
		l_attprojw := params.AttProjW.data[l*C*C:]
		l_attprojb := params.AttProjB.data[l*C:]
		l_ln2w := params.Layer2NormW.data[l*C:]
		l_ln2b := params.Layer2NormB.data[l*C:]
		l_fcw := params.FeedFwdW.data[l*4*C*C:]
		l_fcb := params.FeedFwdB.data[l*4*C:]
		l_fcprojw := params.FeedFwdProjW.data[l*C*4*C:]
		l_fcprojb := params.FeedFwdProjB.data[l*C:]
		// Activations
		l_ln1 := acts.Layer1Act.data[l*B*T*C:]
		l_ln1_mean := acts.LayerNorm1Mean.data[l*B*T:]
		l_ln1_rstd := acts.LayerNorm1Rstd.data[l*B*T:]
		l_qkv := acts.QueryKeyVal.data[l*B*T*3*C:]
		l_atty := acts.AttentionInter.data[l*B*T*C:]
		l_preatt := acts.PreAttention.data[l*B*NH*T*T:]
		l_att := acts.Attention.data[l*B*NH*T*T:]
		l_attproj := acts.AttentionProj.data[l*B*T*C:]
		l_residual2 := acts.Residual2.data[l*B*T*C:]
		l_ln2 := acts.LayerNorm2Act.data[l*B*T*C:]
		l_ln2_mean := acts.LayerNorm2Mean.data[l*B*T:]
		l_ln2_rstd := acts.LayerNorm2Rstd.data[l*B*T:]
		l_fch := acts.FeedForward.data[l*B*T*4*C:]
		l_fch_gelu := acts.FeedForwardGelu.data[l*B*T*4*C:]
		l_fcproj := acts.FeedForwardProj.data[l*B*T*C:]
		l_residual3 := acts.Residual3.data[l*B*T*C:]
		// Here we normalise the layer so that the mean is 0 and the standard deviation is ~1.
		// residual contains the un-edited activations
		layernormForward(l_ln1, l_ln1_mean, l_ln1_rstd, residual /*inp*/, l_ln1w /*weight*/, l_ln1b /*bias*/, B, T, C)
		/*
					l_qkvw = weight = Query Key Val Weights (C * 3C)
					l_ln1 = inp = layer activations
					l_qkvb = bias = Query Key Val Bias
					l_qkv = out = key/query/value matrix
				Here we&#x27;re matrix multiplying  l_ln1(inp)*l_qkvw(weight) + l_qkvb(bias)
				This matrix multiplication essentially gets a layer activation for the model inputs (activations) which are multiplied
				by the model weights.
			This does the input &quot;projection&quot; via linear transformations via the model query/key/value weights into higher dimensionality.
		*/
		matmulForward(l_qkv, l_ln1, l_qkvw, l_qkvb, B, T, C, 3*C)
		/*
			The attention forward pass takes these query/key/value vectors, along with the model attention weights
			The model pre-attention scores, after the forward pass, have the un-normalised attention scores
			att has the attention acores and l_atty has the attention scores + the query/key/value scores
			l_qkv has the projection of the activations into a higher dimension.
			l_preatt: has the projection qkv vectors dot product(similarity), between an input&#x27;s query and another input&#x27;s key.
				This basically goes like this:
				word a: has a query vector &quot;what am i looking for&quot;
				word b: has a query vector &quot;what do i need&quot;
				if they&#x27;re similar, these vectors will be similar, therefore the scores will be high and be stored in l_preatt
			the v in the qkv is the original token/position embeddings which have been through a number of linear transformations at this point.
		*/
		attentionForward(l_atty, l_preatt, l_att, l_qkv, B, T, C, NH)

		/*
			Here we do another matrix multiplication of attention weights and biases
			This projects the l_atty into another dimension. These will probably also get back propagated.
		*/
		matmulForward(l_attproj, l_atty, l_attprojw, l_attprojb, B, T, C, C)
		/*
			The residual forward simply adds the attention projection and the residual layer, which is the
			weights(or activations?) before any of the previous transformations. This allows a stronger signal and
			prevents weight dropout and i think makes back propagation more efficient.
		*/
		residualForward(l_residual2, residual, l_attproj, B*T*C)
		/*
			The weights in this level are the layer 2 activations, which are multiplied with the residual through the above sections
			This is normalised and everything into layernorm2
		*/
		layernormForward(l_ln2, l_ln2_mean, l_ln2_rstd, l_residual2, l_ln2w, l_ln2b, B, T, C)
		/*
			Feedforward is just another layer of a multi layer perceptron to make the &quot;higher level&quot; connections.
		*/
		matmulForward(l_fch, l_ln2, l_fcw, l_fcb, B, T, C, 4*C)
		/*
			This is an acitvation function which maps large values to close to one and smaller values to zero.
		*/
		geluForward(l_fch_gelu, l_fch, B*T*4*C)
		/*
			This now squishes the last layer into a smaller dimension so it can be added to the next layer.
		*/
		matmulForward(l_fcproj, l_fch_gelu, l_fcprojw, l_fcprojb, B, T, 4*C, C)
		/*
			Now we set the next residual layer as the output of this layer. This is the l_fcproj + the current layer residual
		*/
		residualForward(l_residual3, l_residual2, l_fcproj, B*T*C)
	}
	residual = acts.Residual3.data[(L-1)*B*T*C:]

	/*
		Now this is the last thing. We&#x27;re layer norming the final layer activations so that the logits can be calculated

	*/
	layernormForward(acts.LayerNormFinal.data, acts.LayerNormFinalMean.data, acts.LayerNormFinalStd.data, residual, params.LayerFinNormW.data, params.LayerFinNormB.data, B, T, C)
	/*
			Matrix multiplying the Word Token embedding gives us the logits.
		This is calculating a weighted sum. More likely tokens will be blown up and less likely will be zero or negative.
	*/
	matmulForward(acts.Logits.data, acts.LayerNormFinal.data, params.WordTokEmbed.data, nil, B, T, C, V)
	/*
		After all of this we can softmax the logits to get probabilities over the entire vocabulary
	*/
	softmaxForward(acts.Probabilities.data, acts.Logits.data, B, T, V)
	// also forward the cross-entropy loss function if we have the targets
	if len(target) &gt; 0 {
		/*
			This compares the probabilities for each token and compares it to the target to calculate a loss.
		*/
		crossEntropyForward(model.Acts.Losses.data, model.Acts.Probabilities.data, target, B, T, V)
		// for convenience also evaluate the mean loss
		var meanLoss float32
		for i := range model.Acts.Losses.data {
			meanLoss += model.Acts.Losses.data[i]
		}
		meanLoss /= float32(B * T)
		model.MeanLoss = meanLoss

	} else {
		model.MeanLoss = -1.0
	}
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Q7XQ82H3TzREe0XvOXWLE" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="AACDLDjH1I" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="sampling" class="relative group"><span class="heading-text">Sampling</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#sampling" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The probabilities are a float array of:</p><p>index/tokenid:probability</p><p>coin is a random value between 0 and 1.</p><p>We start with a cumulative sum, and when it gets above our target coin, we return.</p><p>This makes it that the most likely token returned is the one that has the most probability, but we still have the possibiility of choosing other ones, proportional to how likley they are.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="fbThEoLaOb" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func sampleMult(probabilities []float32, coin float32) int {
	var cdf float32
	for i, prob := range probabilities {
		cdf += prob
		if coin &lt; cdf {
			return i
		}
	}
	return len(probabilities) - 1
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="t67_kvt2Qm5NjzOwht6jb" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="goFdLq7I42" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func (model *GPT2) Inference(input string) (string, error) {
	B, T, nTokens := 1, 64, 20
	start := time.Now()
	defer func() {
		fmt.Printf(&quot;inference time took: %v\n&quot;, time.Now().Sub(start))
	}()
	tokens, err := model.Tokenizer.Encode(input)
	//prompt_len := len(tokens)
	if err != nil {
		return &quot;&quot;, err
	}
	if len(tokens) &lt; T {
		for i := len(tokens); i &lt;= T; i++ {
			tokens = append(tokens, model.Config.EOT)
		}
	}
	fmt.Printf(&quot;input is %d tokens long\n&quot;, len(tokens))
	model.Forward(tokens, tokens[1:], B, T)
	for t := 1; t &lt; nTokens; t++ {
		// for each t, we re-compute all activations between 0 and t
		// leaving this alone because you want separate code for inference anyway
		// the inference here is just for sanity checking purposes
		model.Forward(tokens, nil, B, t)
		probabilities := model.Acts.Probabilities.data[(t-1)*model.Config.V:]
		coin := model.Rand.Float32()
		nextToken2 := sampleMult(probabilities, coin)
		tokens[t] = rune(nextToken2)
		out, err := model.Tokenizer.Decode([]int32{tokens[t]})
		if err != nil {
			panic(err)
		}
		fmt.Print(out)

	}
	return model.Tokenizer.Decode(tokens)
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="MyJy-YU6H9BtTFXGNOqb2" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="KhDHkh8Qfl" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func newGPT2(MaxSeqLen, V, L, NH, C int, vocab []string) GPT2 {
	model := GPT2{
		Config: GPT2Config{
			MaxSeqLen: MaxSeqLen,
			V:         V,
			L:         L,
			NH:        NH,
			C:         C,
		},
		Params:    newParameterTensors(V, C, MaxSeqLen, L),
		Tokenizer: newTokenizer(vocab),
		Rand:      rand.New(rand.NewSource(21)),
	}
	return model
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="jYhzL8HRICoxseNWzBqdM" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="f1dWwfr4Pd" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="do-some-inference" class="relative group"><span class="heading-text">Do some inference</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#do-some-inference" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="DgiVmNS1zS" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">%%

path := &quot;/Users/joshcarp/Documents/the-interactive-transformer/&quot;
model, err := LoadGPT2Model(path+&quot;/gpt2_124M.bin&quot;, path+&quot;/gpt2_tokenizer.bin&quot;)
if err != nil {
    panic(err)
}
gonbui.RequestInput(&quot;gpt2 text complete: &quot;, false)
reader := bufio.NewReader(os.Stdin)
inputText, err := reader.ReadString(&#x27;\n&#x27;)
if err != nil {
    panic(err)
}
_, err = model.Inference(inputText)
if err != nil {
    panic(err)
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="zCykR9hZtQIS6z4kifGyG" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>input is 65 tokens long
ahlvinyl.org&gt; &lt;link rel=&quot;stylesheet&quot;&gt;&lt;span class=&quot;affiliate iconinference time took: 6.370601958s
</span></code></pre></div></div></div><div id="y0BKMHGB0g" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="backward-pass" class="relative group"><span class="heading-text">Backward Pass</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#backward-pass" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The backwards pass is where the “learning” happens. It is used to update the weights of the model.
If we’re using the model for inference, deploying it as a chatbot, etc, we don’t do a backwards pass.</p><p>The backward pass calculates the difference between the predicted tokens (before the sampling), and calculates a gradient based on the learning algorithm.</p><figure id="i2RFm9Bkjv" class="fig-figure"><div style="text-align:center" class="leading-[0]"><div class="relative inline-block" style="padding-bottom:60%;width:min(max(100%, 500px), 100%)"><iframe width="100%" height="100%" src="https://www.youtube.com/embed?v=Ilg3gGewQ5U" allowfullscreen="" allow="autoplay" style="width:100%;height:100%;position:absolute;top:0;left:0;border:none"></iframe></div></div><figcaption class="group"><p>Backpropagation</p></figcaption></figure><h4 id="papers-5" class="relative group"><span class="heading-text">Papers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#papers-5" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><a target="_blank" href="https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf" rel="noreferrer"><strong>Learning representations by back-propagating errors</strong></a> - Back-propagation was introduced here, couldn’t find the original paper. This was done by Hinton and co and was what lead to the AI era of the 80s.</li></ul><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="CAilUkJTnB" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="crossentropysoftmaxbackward" class="relative group"><span class="heading-text">crossentropySoftmaxBackward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#crossentropysoftmaxbackward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The function computes the gradients of the logits (dlogits) with respect to the loss, given the probabilities (probs) and target labels (targets).
This gradient information is used during backpropagation to update the weights and biases of the network to minimize the cross-entropy loss.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="aU9IeWt1Cy" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">// crossentropySoftmaxBackward calculates the cross entropy
func crossentropySoftmaxBackward(dlogits, dlosses, probs []float32, targets []int32, B, T, V int) {
	for b := 0; b &lt; B; b++ {
		for t := 0; t &lt; T; t++ {
			baseIndex := b*T*V + t*V
			dlogitsBT := dlogits[baseIndex : baseIndex+V]
			probsBT := probs[baseIndex : baseIndex+V]
			dloss := dlosses[b*T+t]
			ix := targets[b*T+t]
			for i := 0; i &lt; V; i++ {
				p := probsBT[i]
				var indicator float32
				if int32(i) == ix {
					indicator = 1.0
				} else {
					indicator = 0.0
				}
				dlogitsBT[i] += (p - indicator) * dloss
			}
		}
	}
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="s0Qyl_CzZao1WdNg6SHoJ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="aB89w08XnW" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="matmulbackward" class="relative group"><span class="heading-text">matmulBackward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#matmulbackward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The function computes the gradients of the inputs (dinp), weights (dweight), and biases (dbias) for a matrix multiplication operation. These gradients are necessary for adjusting the model parameters during training to minimize the error.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="pacSKYOfnf" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func matmulBackward(dinp, dweight, dbias, dout, inp, weight []float32, B, T, C, OC int) {
	var wg sync.WaitGroup
	for b := 0; b &lt; B; b++ {
		for t := 0; t &lt; T; t++ {
			wg.Add(1)
			go func(b, t int) {
				defer wg.Done()
				doutBt := dout[b*T*OC+t*OC:]
				dinpBt := dinp[b*T*C+t*C:]
				for o := 0; o &lt; OC; o++ {
					wrow := weight[o*C:]
					d := doutBt[o]
					for i := 0; i &lt; C; i++ {
						dinpBt[i] += wrow[i] * d
					}
				}
			}(b, t)
		}
	}
	wg.Wait()
	for o := 0; o &lt; OC; o++ {
		wg.Add(1)
		go func(o int) {
			defer wg.Done()
			for b := 0; b &lt; B; b++ {
				for t := 0; t &lt; T; t++ {
					doutBt := dout[b*T*OC+t*OC:]
					inpBt := inp[b*T*C+t*C:]
					dwrow := dweight[o*C:]
					d := doutBt[o]
					if dbias != nil {
						dbias[o] += d
					}
					for i := 0; i &lt; C; i++ {
						dwrow[i] += inpBt[i] * d
					}
				}
			}
		}(o)
	}
	wg.Wait()
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Dj-LeTxqU9VhVeBBCQfXO" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="Q4WvrsW0KR" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="layernormbackward" class="relative group"><span class="heading-text">layernormBackward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#layernormbackward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The function layernormBackward calculates the gradients for the backward pass of a Layer Normalization (LayerNorm) operation in a neural network. Here’s a breakdown of what it does:</p><p>Layer Normalization is a technique used to normalize the activations of a layer across its features, improving the training stability and performance of deep neural networks. It involves normalizing the input to have zero mean and unit variance. This function calculates the gradients needed to update the weights and biases of the LayerNorm operation during backpropagation.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="TrCZJU0oNT" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func layernormBackward(dinp, dweight, dbias, dout, inp, weight, mean, rstd []float32, B, T, C int) {
	for b := 0; b &lt; B; b++ {
		for t := 0; t &lt; T; t++ {
			baseIndex := b*T*C + t*C
			doutBT := dout[baseIndex : baseIndex+C]
			inpBT := inp[baseIndex : baseIndex+C]
			dinpBT := dinp[baseIndex : baseIndex+C]
			meanBT := mean[b*T+t]
			rstdBT := rstd[b*T+t]

			// Reduce operations
			var dnormMean float32 = 0.0
			var dnormNormMean float32 = 0.0
			for i := 0; i &lt; C; i++ {
				normBTI := (inpBT[i] - meanBT) * rstdBT
				dnormI := weight[i] * doutBT[i]
				dnormMean += dnormI
				dnormNormMean += dnormI * normBTI
			}
			dnormMean /= float32(C)
			dnormNormMean /= float32(C)

			// Accumulation loop
			for i := 0; i &lt; C; i++ {
				normBTI := (inpBT[i] - meanBT) * rstdBT
				dnormI := weight[i] * doutBT[i]
				dbias[i] += doutBT[i]
				dweight[i] += normBTI * doutBT[i]

				var dval float32
				dval += dnormI                  // Term 1
				dval -= dnormMean               // Term 2
				dval -= normBTI * dnormNormMean // Term 3
				dval *= rstdBT                  // Final scale
				dinpBT[i] += dval
			}
		}
	}
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="d4z_JWzCf9g1hbhkgyzvK" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="VGXmTIcxaw" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="residualbackward" class="relative group"><span class="heading-text">residualBackward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#residualbackward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The function residualBackward calculates the gradients for the backward pass of a residual connection in a neural network. Here’s a breakdown of what it does:</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="BWbS3SlaN7" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func residualBackward(dinp1, dinp2, dout []float32, N int) {
	for i := 0; i &lt; N; i++ {
		dinp1[i] += dout[i]
		dinp2[i] += dout[i]
	}
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="6-702OlI21q5sQUrrJJEm" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="fhoSpTSmma" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="gelubackward" class="relative group"><span class="heading-text">geluBackward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#gelubackward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Computes the gradient of the Gaussian Error Linear Unit (GELU) activation function for backpropagation in a neural network.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="W17zBcByho" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">// geluBackward computes the backward pass of the GeLU non-linearity
func geluBackward(dinp, inp, dout []float32, n int) {
	for i := 0; i &lt; n; i++ {
		x := inp[i]
		cube := 0.044715 * x * x * x
		tanhArg := GELUSCALEFACTOR * (x + cube)
		tanhOut := Tanh(tanhArg)
		coshfOut := Cosh(tanhArg)
		sechOut := 1.0 / (coshfOut * coshfOut)
		localGrad := 0.5*(1.0+tanhOut) + x*0.5*sechOut*GELUSCALEFACTOR*(1.0+3.0*0.044715*x*x)
		dinp[i] += localGrad * dout[i]
	}
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="aO6VSVXiKSLP6Blf57Red" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="knWoXwrJ0f" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="attentionbackward" class="relative group"><span class="heading-text">attentionBackward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#attentionbackward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The attentionBackward function implements the backward pass for a self-attention mechanism in a neural network. This is a crucial part of training attention-based models, like transformers. It calculates the gradients of the attention weights, queries, keys, and values with respect to the outputs of the attention layer, allowing the model to adjust its parameters to improve performance.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="NdV9bZt4A2" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">// attentionBackward performs the backward pass for an attention mechanism
func attentionBackward(dinp, dpreatt, datt, dout, inp, att []float32, B, T, C, NH int) {
	// C3 is 3 times C, representing the size of Q, K, and V combined
	C3 := C * 3
	// hs is the size of each head
	hs := C / NH
	// scale is the factor used in the forward pass to scale the dot product
	scale := 1.0 / Sqrt(float32(hs))
	// Iterate through batch, time, and heads
	for b := 0; b &lt; B; b++ {
		for t := 0; t &lt; T; t++ {
			for h := 0; h &lt; NH; h++ {
				// Calculate the indices for the arrays in this specific iteration
				attBTH := att[b*NH*T*T+h*T*T+t*T:]
				dattBTH := datt[b*NH*T*T+h*T*T+t*T:]
				dpreattBTH := dpreatt[b*NH*T*T+h*T*T+t*T:]
				dqueryT := dinp[b*T*C3+t*C3+h*hs:]
				queryT := inp[b*T*C3+t*C3+h*hs:]
				// Backward pass 4: value accumulation
				doutBTH := dout[b*T*C+t*C+h*hs:]
				for t2 := 0; t2 &lt;= t; t2++ {
					valueT2 := inp[b*T*C3+t2*C3+h*hs+C*2:]
					dvalueT2 := dinp[b*T*C3+t2*C3+h*hs+C*2:]
					for i := 0; i &lt; hs; i++ {
						// Compute gradients for attention and value accumulation
						dattBTH[t2] += valueT2[i] * doutBTH[i]
						dvalueT2[i] += attBTH[t2] * doutBTH[i]
					}
				}
				// Backward pass 2 &amp; 3: softmax backward
				// Softmax does not require input (preatt) to backward
				for t2 := 0; t2 &lt;= t; t2++ {
					for t3 := 0; t3 &lt;= t; t3++ {
						var indicator float32
						if t2 == t3 {
							indicator = 1.0
						}
						localDerivative := attBTH[t2] * (indicator - attBTH[t3])
						dpreattBTH[t3] += localDerivative * dattBTH[t2]
					}
				}
				// Backward pass 1: query @ key matmul
				for t2 := 0; t2 &lt;= t; t2++ {
					keyT2 := inp[b*T*C3+t2*C3+h*hs+C:]
					dkeyT2 := dinp[b*T*C3+t2*C3+h*hs+C:]
					for i := 0; i &lt; hs; i++ {
						// Compute gradients for query and key
						dqueryT[i] += keyT2[i] * dpreattBTH[t2] * scale
						dkeyT2[i] += queryT[i] * dpreattBTH[t2] * scale
					}
				}
			}
		}
	}
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="MVvBl8fieY1vEnzueY_5z" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="mv3gSWw3mk" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="matmulbackward-1" class="relative group"><span class="heading-text">matmulBackward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#matmulbackward-1" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The function computes the gradients of the inputs (dinp), weights (dweight), and biases (dbias) for a matrix multiplication operation. These gradients are necessary for adjusting the model parameters during training to minimize the error.</p><p>dinp: A slice of floats representing the gradients of the outputs with respect to the inputs of the matrix multiplication. This is often calculated by the subsequent layer in the network.
dweight: A slice of floats representing the gradients of the outputs with respect to the weights. Initially, this slice is filled with zeros.
dbias: A slice of floats representing the gradients of the outputs with respect to the biases. Initially, this slice is filled with zeros.
dout: A slice of floats representing the outputs of the matrix multiplication.
inp: A slice of floats representing the inputs to the matrix multiplication.
weight: A slice of floats representing the weights of the matrix multiplication.
B: The batch size (number of samples).
T: The time steps or sequence length.
C: The number of input features.
OC: The number of output features.</p><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="ETjzOGO0sP" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func matmulBackward(dinp, dweight, dbias, dout, inp, weight []float32, B, T, C, OC int) {
	var wg sync.WaitGroup
	for b := 0; b &lt; B; b++ {
		for t := 0; t &lt; T; t++ {
			wg.Add(1)
			go func(b, t int) {
				defer wg.Done()
				doutBt := dout[b*T*OC+t*OC:]
				dinpBt := dinp[b*T*C+t*C:]
				for o := 0; o &lt; OC; o++ {
					wrow := weight[o*C:]
					d := doutBt[o]
					for i := 0; i &lt; C; i++ {
						dinpBt[i] += wrow[i] * d
					}
				}
			}(b, t)
		}
	}
	wg.Wait()
	for o := 0; o &lt; OC; o++ {
		wg.Add(1)
		go func(o int) {
			defer wg.Done()
			for b := 0; b &lt; B; b++ {
				for t := 0; t &lt; T; t++ {
					doutBt := dout[b*T*OC+t*OC:]
					inpBt := inp[b*T*C+t*C:]
					dwrow := dweight[o*C:]
					d := doutBt[o]
					if dbias != nil {
						dbias[o] += d
					}
					for i := 0; i &lt; C; i++ {
						dwrow[i] += inpBt[i] * d
					}
				}
			}
		}(o)
	}
	wg.Wait()
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="0tygBnoGUTqt5Jl2MTZO7" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="XwILlN6Dyt" class="relative group/block article-grid subgrid-gap col-screen"><h2 id="encoderbackward" class="relative group"><span class="heading-text">encoderBackward</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#encoderbackward" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>encoderBackward calculates gradients during backpropagation
Parameters:</p><ul><li>dwte: gradients with respect to word embeddings (wte)</li><li>dwpe: gradients with respect to positional embeddings (wpe)</li><li>dout: the gradient to apply to dwte and dwpe</li><li>inp: input tokens (ids that refer to indexes within wte)</li><li>B: batch size</li><li>T: sequence length (number of time steps)</li><li>C: embedding dimension (number of features)</li></ul><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="yKS6DbrnoP" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">
func encoderBackward(dwte, dwpe []float32, dout []float32, inp []int32, B, T, C int) {
	// Iterate over the batch and time steps
	for b := 0; b &lt; B; b++ {
		for t := 0; t &lt; T; t++ {
			// Calculate offsets for indexing
			doutBTOffset := b*T*C + t*C
			ix := inp[b*T+t]              // Get the input token id
			dwteIxOffset := ix * int32(C) // Calculate the offset for dwte
			dwpeTOffset := t * C          // Calculate the offset for dwpe

			// Iterate over the embedding dimension and apply computations
			for i := 0; i &lt; C; i++ {
				// Get the gradient value from dout
				d := dout[doutBTOffset+i]
				// Update the gradients for word embeddings (dwte) and positional embeddings (dwpe)
				dwte[dwteIxOffset+int32(i)] += d
				dwpe[dwpeTOffset+i] += d
			}
		}
	}
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="J6oTOP9VuyWF3eSJfc-w8" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="CQ9kYRhfzb" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">
func (model *GPT2) ZeroGradient() {
	for i := range model.GradsActs.Memory {
		model.GradsActs.Memory[i] = 0.0
	}
	for i := range model.Grads.Memory {
		model.Grads.Memory[i] = 0.0
	}
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="sUTFIi6TuzhrBiTfgrv0s" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="jCvkpgxTES" class="relative group/block article-grid subgrid-gap col-screen"><h3 id="optimiser" class="relative group"><span class="heading-text">Optimiser</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#optimiser" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The optimiser implementation keeps track of the weights that are being changed, and how fast they’re being changed.</p><p>Most neural network back propagation algorithms use AdamW, which is a weight-decay ontop of the Adam optimiser.</p><h4 id="papers-6" class="relative group"><span class="heading-text">Papers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#papers-6" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><a target="_blank" href="https://arxiv.org/abs/1412.6980" rel="noreferrer"><strong>Adam: A Method for Stochastic Optimization</strong></a> - Introduced the Adam optimiser.</li><li><a target="_blank" href="https://arxiv.org/abs/1711.05101" rel="noreferrer"><strong>DECOUPLED WEIGHT DECAY REGULARIZATION</strong></a> - Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.</li></ul><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="Hq7rWieAs9" class="relative group/block article-grid subgrid-gap col-screen"><h3 id="optimiser-1" class="relative group"><span class="heading-text">Optimiser</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#optimiser-1" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The optimiser implementation keeps track of the weights that are being changed, and how fast they’re being changed.</p><p>Most neural network back propagation algorithms use AdamW, which is a weight-decay ontop of the Adam optimiser.</p><h4 id="papers-7" class="relative group"><span class="heading-text">Papers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#papers-7" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><a target="_blank" href="https://arxiv.org/abs/1412.6980" rel="noreferrer"><strong>Adam: A Method for Stochastic Optimization</strong></a> - Introduced the Adam optimiser.</li><li><a target="_blank" href="https://arxiv.org/abs/1711.05101" rel="noreferrer"><strong>DECOUPLED WEIGHT DECAY REGULARIZATION</strong></a> - Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.</li></ul><p><span data-state="closed"><a href="#introduction" class="hover-link">back to top</a></span></p></div><div id="HJ3VzzAS4d" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">func (model *GPT2) Update(learningRate, beta1, beta2, eps, weightDecay float32, t int) {
	// Lazy memory allocation
	if model.MMemory == nil {
		model.MMemory = make([]float32, model.Params.Len())
		model.VMemory = make([]float32, model.Params.Len())
	}
	// Parameter updates
	for i := 0; i &lt; model.Params.Len(); i++ {
		parameter := model.Params.Memory[i]
		gradient := model.Grads.Memory[i]
		// Momentum update
		m := beta1*model.MMemory[i] + (1.0-beta1)*gradient
		// RMSprop update
		v := beta2*model.VMemory[i] + (1.0-beta2)*gradient*gradient
		// Bias correction
		mHat := m / (1.0 - Pow(beta1, float32(t)))
		vHat := v / (1.0 - Pow(beta2, float32(t)))
		// Parameter update
		model.MMemory[i] = m
		model.VMemory[i] = v
		model.Params.Memory[i] -= learningRate * (mHat/(Sqrt(vHat)+eps) + weightDecay*parameter)
	}
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ol1IzjZqbr6rF5wtRc9vO" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="STDuxSY9hT" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">
func (model *GPT2) Backward() error {
	//// double check we forwarded previously, with targets
	if model.MeanLoss == -1.0 {
		return errors.New(&quot;error: must forward with targets before backward&quot;)
	}
	// lazily allocate the memory for gradients of the weights and activations, if needed
	// convenience shortcuts
	B, T, V, L, NH, C := model.B, model.T, model.Config.V, model.Config.L, model.Config.NH, model.Config.C
	if len(model.Grads.Memory) == 0 {
		model.Grads.Init(V, C, model.Config.MaxSeqLen, L)
		model.GradsActs.Init(B, C, T, L, NH, V)
		model.ZeroGradient()
	}
	// backward pass
	params, grads, acts, gradsActs := model.Params, model.Grads, model.Acts, model.GradsActs
	// we kick off the chain by filling in dlosses with 1.0f/(B*T), to get the mean loss
	dlossMean := 1.0 / float32(B*T)
	for i := range gradsActs.Losses.data {
		gradsActs.Losses.data[i] = dlossMean
	}
	crossentropySoftmaxBackward(gradsActs.Logits.data, gradsActs.Losses.data, acts.Probabilities.data, model.Targets, B, T, V)
	matmulBackward(gradsActs.LayerNormFinal.data, grads.WordTokEmbed.data, nil, gradsActs.Logits.data, acts.LayerNormFinal.data, params.WordTokEmbed.data, B, T, C, V)
	residual := acts.Residual3.data[(L-1)*B*T*C:]       // last layer&#x27;s residual
	dresidual := gradsActs.Residual3.data[(L-1)*B*T*C:] // write to last layer&#x27;s residual
	layernormBackward(dresidual, grads.LayerFinNormW.data, grads.LayerFinNormB.data, gradsActs.LayerNormFinal.data, residual, params.LayerFinNormW.data, acts.LayerNormFinalMean.data, acts.LayerNormFinalStd.data, B, T, C)
	for l := L - 1; l &gt;= 0; l-- {
		if l == 0 {
			residual = acts.Encoded.data
			dresidual = gradsActs.Encoded.data
		} else {
			residual = acts.Residual3.data[(l-1)*B*T*C:]
			dresidual = gradsActs.Residual3.data[(l-1)*B*T*C:]
		}

		// Assuming you have a &#x27;params&#x27; variable of your ParameterTensors type
		l_ln1w := params.LayerNorm1W.data[l*C:]
		l_qkvw := params.QueryKeyValW.data[l*3*C*C:]
		l_attprojw := params.AttProjW.data[l*C*C:]
		l_ln2w := params.Layer2NormW.data[l*C:]
		l_fcw := params.FeedFwdW.data[l*4*C*C:]
		l_fcprojw := params.FeedFwdProjW.data[l*C*4*C:]
		// Gradients of weights
		dl_ln1w := grads.LayerNorm1W.data[l*C:]
		dl_ln1b := grads.LayerNorm1B.data[l*C:]
		dl_qkvw := grads.QueryKeyValW.data[l*3*C*C:]
		dl_qkvb := grads.QueryKeyValB.data[l*3*C:]
		dl_attprojw := grads.AttProjW.data[l*C*C:]
		dl_attprojb := grads.AttProjB.data[l*C:]
		dl_ln2w := grads.Layer2NormW.data[l*C:]
		dl_ln2b := grads.Layer2NormB.data[l*C:]
		dl_fcw := grads.FeedFwdW.data[l*4*C*C:]
		dl_fcb := grads.FeedFwdB.data[l*4*C:]
		dl_fcprojw := grads.FeedFwdProjW.data[l*C*4*C:]
		dl_fcprojb := grads.FeedFwdProjB.data[l*C:]
		// Activations
		l_ln1 := acts.Layer1Act.data[l*B*T*C:]
		l_ln1_mean := acts.LayerNorm1Mean.data[l*B*T:]
		l_ln1_rstd := acts.LayerNorm1Rstd.data[l*B*T:]
		l_qkv := acts.QueryKeyVal.data[l*B*T*3*C:]
		l_atty := acts.AttentionInter.data[l*B*T*C:]
		l_att := acts.Attention.data[l*B*NH*T*T:]
		l_residual2 := acts.Residual2.data[l*B*T*C:]
		l_ln2 := acts.LayerNorm2Act.data[l*B*T*C:]
		l_ln2_mean := acts.LayerNorm2Mean.data[l*B*T:]
		l_ln2_rstd := acts.LayerNorm2Rstd.data[l*B*T:]
		l_fch := acts.FeedForward.data[l*B*T*4*C:]
		l_fch_gelu := acts.FeedForwardGelu.data[l*B*T*4*C:]

		dl_ln1 := gradsActs.Layer1Act.data[l*B*T*C:]
		dl_qkv := gradsActs.QueryKeyVal.data[l*B*T*3*C:]
		dl_atty := gradsActs.AttentionInter.data[l*B*T*C:]
		dl_preatt := gradsActs.PreAttention.data[l*B*NH*T*T:]
		dl_att := gradsActs.Attention.data[l*B*NH*T*T:]
		dl_attproj := gradsActs.AttentionProj.data[l*B*T*C:]
		dl_residual2 := gradsActs.Residual2.data[l*B*T*C:]
		dl_ln2 := gradsActs.LayerNorm2Act.data[l*B*T*C:]
		dl_fch := gradsActs.FeedForward.data[l*B*T*4*C:]
		dl_fch_gelu := gradsActs.FeedForwardGelu.data[l*B*T*4*C:]
		dl_fcproj := gradsActs.FeedForwardProj.data[l*B*T*C:]
		dl_residual3 := gradsActs.Residual3.data[l*B*T*C:]
		residualBackward(dl_residual2, dl_fcproj, dl_residual3, B*T*C)
		matmulBackward(dl_fch_gelu, dl_fcprojw, dl_fcprojb, dl_fcproj, l_fch_gelu, l_fcprojw, B, T, 4*C, C)
		geluBackward(dl_fch, l_fch, dl_fch_gelu, B*T*4*C)
		matmulBackward(dl_ln2, dl_fcw, dl_fcb, dl_fch, l_ln2, l_fcw, B, T, C, 4*C)
		layernormBackward(dl_residual2, dl_ln2w, dl_ln2b, dl_ln2, l_residual2, l_ln2w, l_ln2_mean, l_ln2_rstd, B, T, C)
		residualBackward(dresidual, dl_attproj, dl_residual2, B*T*C)
		matmulBackward(dl_atty, dl_attprojw, dl_attprojb, dl_attproj, l_atty, l_attprojw, B, T, C, C)
		attentionBackward(dl_qkv, dl_preatt, dl_att, dl_atty, l_qkv, l_att, B, T, C, NH)
		matmulBackward(dl_ln1, dl_qkvw, dl_qkvb, dl_qkv, l_ln1, l_qkvw, B, T, C, 3*C)
		layernormBackward(dresidual, dl_ln1w, dl_ln1b, dl_ln1, residual, l_ln1w, l_ln1_mean, l_ln1_rstd, B, T, C)
	}
	// Here we want to apply our gradients to our encoded data.
	encoderBackward(grads.WordTokEmbed.data, grads.WordPosEmbed.data, gradsActs.Encoded.data, model.Inputs, B, T, C)
	return nil
}
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="sU1zPSnxM87XbxS-UZhZJ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="vCV5w3QIZm" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">
func (model *GPT2) Train(valDataloader, trainDataloader *DataLoader, B, T int) error {
	fmt.Printf(&quot;train dataset num_batches: %d\n&quot;, valDataloader.NumBatches)
	const genMaxLength, valNumBatches = 20, 3
	for step := 0; step &lt;= 3; step++ {
		if step%1 == 0 {
			var valLoss float32
			valDataloader.Reset()
			for i := 0; i &lt; valNumBatches; i++ {
				input, target, err := valDataloader.NextBatch()
				if err != nil {
					return err
				}
				model.Forward(input, target, B, T)
				valLoss += model.MeanLoss
			}
			valLoss /= float32(valNumBatches)
			fmt.Printf(&quot;val loss %f\n&quot;, valLoss)
		}
		// do a training step
		start := time.Now()
		input, targets, err := trainDataloader.NextBatch()
		if err != nil {
			return err
		}
		model.Forward(input, targets, B, T)
		model.ZeroGradient()
		model.Backward()
		model.Update(1e-4, 0.9, 0.999, 1e-8, 0.0, step+1)
		fmt.Printf(&quot;step %d: train loss %f (took %v ms)\n&quot;, step, model.MeanLoss, time.Since(start))
	}
	return nil
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="JtMqIvQ8RNC6sTb52GJpn" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="S1pOe1VwMi" class="relative group/block article-grid subgrid-gap col-screen"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-go" style="white-space:pre">%main
model, err := LoadGPT2Model(&quot;./gpt2_124M.bin&quot;, &quot;./gpt2_tokenizer.bin&quot;)
if err != nil {
    log.Fatal(err)
}
B, T := 4, 64
trainDataloader, err := NewDataLoader(&quot;./TinyStories_train.bin&quot;, B, T)
if err != nil {
    log.Fatal(err)
}
fmt.Printf(&quot;train dataset num_batches: %d\n&quot;, trainDataloader.NumBatches)
valDataloader, err := NewDataLoader(&quot;./TinyStories_val.bin&quot;, B, T)
if err != nil {
    log.Fatal(err)
}
if err := model.Train(valDataloader, trainDataloader, B, T); err != nil {
    log.Fatal(err)
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="enIBa3uM23ZbyF3Km3334" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>2024/08/26 17:53:26 Error opening model file: open ./gpt2_124M.bin: no such file or directory
exit status 1
</span></code></pre></div></div></div><div id="URSXJZ9vbw" class="relative group/block article-grid subgrid-gap col-screen"><picture><source srcSet="/build/qr-code-3e8da2a510f1483b7b7296455a0de318.webp" type="image/webp"/><img id="IGt5dzCz1P" style="margin:0 auto" src="/build/qr-code-3e8da2a510f1483b7b7296455a0de318.png" data-canonical-url="qr-code.png"/></picture></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/projects/cognition-to"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>CognitionTO Community</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/glossary"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>Glossary</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-JLDGA2DL.js"/><link rel="modulepreload" href="/build/_shared/chunk-YAIQ7LUU.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-ZQWAZXET.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-IQBJE7PC.js"/><link rel="modulepreload" href="/build/_shared/chunk-5CFTM6YW.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-HROFNPGU.js"/><link rel="modulepreload" href="/build/_shared/chunk-N544LW6X.js"/><link rel="modulepreload" href="/build/routes/$-WNZNXUO2.js"/><script>window.__remixContext = {"url":"/projects/the-interactive-transformer/interactive-transformer","state":{"loaderData":{"root":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"},{"children":[{"file":"experiments/higher-abstract-reasoning.ipynb"}],"file":"experiments/index.md","title":"Experiments"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"experiments.index","title":"Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"experiments.higher-abstract-reasoning","title":"Transformers and Higher-Order Abstract Reasoning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"},{"children":[{"file":"experiments/higher-abstract-reasoning.ipynb"}],"file":"experiments/index.md","title":"Experiments"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"experiments.index","title":"Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"experiments.higher-abstract-reasoning","title":"Transformers and Higher-Order Abstract Reasoning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"kind":"Notebook","sha256":"0c93629df87df30e2c3d072c74790002464fbbf50c66357992f9577a4d75aef3","slug":"projects.the-interactive-transformer.interactive-transformer","location":"/projects/the-interactive-transformer/interactive-transformer.ipynb","dependencies":[],"frontmatter":{"title":"The Interactive Transformer","subtitle":"by Joshua Carpeggiani","kernelspec":{"name":"gonb","display_name":"Go (gonb)","language":"go"},"github":"https://github.com/joshcarp/ml-notes","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","exports":[{"format":"ipynb","filename":"interactive-transformer.ipynb","url":"/build/interactive-transfor-2ac5609c6afee3c3448f820f9d5753f2.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Introduction","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VGiyqTWQe5"}],"identifier":"introduction","label":"Introduction","html_id":"introduction","implicit":true,"key":"JWQxsXTkZa"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Welcome. This is an implementation of a transformer in pure go with no third party libraries. This way, everything from tensor operations to tokenization are all done inside this notebook.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Reb58gm5AF"}],"key":"iXuaK1z2N9"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Because the goal of this project is illustrative, there are no optimisations. Everything runs on a single goroutine and doesn’t have any parallelism. This makes it easy to follow and good as a reference guide.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"vY5XM9YKfA"}],"key":"Tx9ohtaTGt"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"This page is also heavily referenced. The goal is to have everything have a reference to its original paper or reference implementation.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TJWq38RhYP"}],"key":"UXKfsLAkOA"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"f2kEYDR6u9"}],"key":"Wxg1dFHXuB"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"This notebook is a version of my repo ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"XmdBf0bYbl"},{"type":"link","url":"https:/github.com/joshcarp/llm.go","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"github​.com​/joshcarp​/llm​.go","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"aUrMimrWWP"}],"urlSource":"https:/github.com/joshcarp/llm.go","key":"ww8J8rmntE"},{"type":"text","value":" which in itself is a fork of ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"COavDatLzF"},{"type":"link","url":"https://github.com/karpathy/llm.c","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"github​.com​/karpathy​/llm​.c","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"beyz2uNYv8"}],"urlSource":"https://github.com/karpathy/llm.c","error":true,"key":"DQhj9iaW1X"},{"type":"text","value":".","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"sDV3ij3oAR"}],"key":"kfnZWEPzi7"}],"key":"fdgH58Wjw4"},{"type":"container","kind":"figure","children":[{"type":"iframe","src":"https://www.youtube.com/embed/wjZofJX0v4M?si=ropP1oHLOiynXLNH","width":"100%","key":"ZD8rQVQqK8"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"GPT introduction","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"NbAC3IvDRm"}],"key":"ik0FyuyJgH"}],"key":"G6I5Cm7VU4"}],"enumerator":"1","key":"l8WymNFk1D"}],"key":"kWoommLMry"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"References","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"phVmQuboiB"}],"identifier":"references","label":"References","html_id":"references","implicit":true,"key":"nfZp2cFeD0"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Usually this goes at the bottom, but seeing this entire thing is a reference, it’ll go at the top instead.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"IMrMsG1966"}],"key":"NtY4903ews"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/IEEE_754","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"IEEE-754","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"hiDGMYH23e"}],"urlSource":"https://en.wikipedia.org/wiki/IEEE_754","data":{"page":"IEEE_754","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"LcvQMDp8au"},{"type":"text","value":" - This is binary floating point. The specification gives good details about what types of errors that can accumulate which would impact training and interence, as well as possible optimisations that can be used, like fused-multiply-add (FMA), which can reduce intermediate errors. CPUs usually use FP32, GPUs FP16.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"iU8glY8RZ5"}],"key":"QUTxCVgtIa"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"link","url":"https://netlib.org/blas/","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"BLAS","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"AW7LTmQr2O"}],"urlSource":"https://netlib.org/blas/","key":"Z0ccg42Ivl"},{"type":"text","value":" - Speed up matrix multiplication on CPUs.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"dhH9PfsDhn"}],"key":"T1sYNXz04C"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1607.06450","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Layer Normalization","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TBE4SAGMWE"}],"key":"QExwIO75uB"}],"urlSource":"https://arxiv.org/abs/1607.06450","key":"tBgbkBFAs4"},{"type":"text","value":" - Layernorm was introduced in this paper.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"UJfvwl5Pz2"}],"key":"hnK6Iysci9"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/pdf/1512.03385","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Deep Residual Learning for Image Recognition","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"N87Jr9F2GX"}],"key":"RbkXeXyIMP"}],"urlSource":"https://arxiv.org/pdf/1512.03385","key":"GzACQZBVpH"},{"type":"text","value":" - The introduction of residuals allowed for deeper networks. Before this paper the depth of a neural network was limited because it would diverge enough and back propagation was really, really difficult to do because of vanishing gradients. Residuals essentially have a “short circuit” past a block which limits how much the neural networks can influence.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"puelz0oXWQ"}],"key":"MqucixZPCD"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1606.08415v5","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Gaussian Error Linear Units (GELUs)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"nSd6kzC4nP"}],"key":"doEUOVHObX"}],"urlSource":"https://arxiv.org/abs/1606.08415v5","key":"S0huBHGwRh"},{"type":"text","value":" - Activation function that leaves positive values unchanged but maps negative numbers to near zero. Other architectures use different activation functions. For example, OpenElm uses SwiGLU.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"UALrqLjJlz"}],"key":"qsuq3ZQZmD"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"link","url":"https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Learning representations by back-propagating errors","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"UfPn7UgF8Q"}],"key":"JyCi7pi08c"}],"urlSource":"https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf","key":"TSZAtDnwCd"},{"type":"text","value":" - Back-propagation was introduced here, couldn’t find the original paper. This was done by Hinton and co and was what lead to the AI era of the 80s.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"b1E1bDUpH6"}],"key":"c7br8A60dQ"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1412.6980","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Adam: A Method for Stochastic Optimization","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"gbF9yYsqWc"}],"key":"peMTNyBT5C"}],"urlSource":"https://arxiv.org/abs/1412.6980","key":"diM97uEWgM"},{"type":"text","value":" - Introduced the Adam optimiser.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"hvDa4TE19x"}],"key":"nNVeHap6Fz"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1711.05101","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"strong","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"DECOUPLED WEIGHT DECAY REGULARIZATION","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"lXkSXwrVv9"}],"key":"SBAXxBvMYK"}],"urlSource":"https://arxiv.org/abs/1711.05101","key":"Z5M6jcAtWv"},{"type":"text","value":" - Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"lmcfef2y73"}],"key":"SklNhf8qdw"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1412.6980","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Adam: A Method for Stochastic Optimization","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"S2gFilnMWe"}],"key":"JZKZcjHofZ"}],"urlSource":"https://arxiv.org/abs/1412.6980","key":"WTFlf02sSi"},{"type":"text","value":" - Introduced the Adam optimiser.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"eCb1w5GkO0"}],"key":"SPr9VZ7oIF"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1711.05101","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"strong","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"DECOUPLED WEIGHT DECAY REGULARIZATION","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"ys71odjk6D"}],"key":"qbpOIHhr89"}],"urlSource":"https://arxiv.org/abs/1711.05101","key":"alaivGzuPQ"},{"type":"text","value":" - Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"rtUQMVuE4A"}],"key":"WylnRL3HEf"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/pdf/1911.02150","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Fast Transformer Decoding: One Write-Head is All\nYou Need","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"k4YCgg2UW5"}],"key":"r7Ui4DqIe7"}],"urlSource":"https://arxiv.org/pdf/1911.02150","key":"etfMGTAFuc"},{"type":"text","value":" - People always point to the original Attention is all you need paper or the GPT paper that introduced the ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"GvcvGrnQtj"},{"type":"emphasis","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"decoder only","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"rMDtUubzqK"}],"key":"wLASeRFbuH"},{"type":"text","value":" model, but this one was the first one that actually used it in practice.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"SwiHrxopYd"}],"key":"hBlTiRQkYA"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"link","url":"https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"strong","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Language Models are Unsupervised Multitask Learners","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"S0pDmeRP9c"}],"key":"LQlmPSteWj"}],"urlSource":"https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf","key":"ge5o9TOiEQ"},{"type":"text","value":" - This is the GPT-2 paper","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"sZ5LKb3Szn"}],"key":"pkoW25Hpuf"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"link","url":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"strong","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Improving Language Understanding by Generative Pre-Training","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"BkWNpctKki"}],"key":"nJqZhh926O"}],"urlSource":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","key":"pCRgbDO7bg"},{"type":"text","value":" -** This paper introduced the “GPT” which was a breakthrough at the time. It introduced the idea of using next token prediction as a way to do self-supervised learning, which meant that we can put all of the internet into it and with a simple loss function over the vocabulary adjust the weights via backpropagation.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"AoynpMOEI2"}],"key":"BSGN7Ar3t9"},{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1706.03762v7","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"strong","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Attention Is All You Need","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"o7utd9MW3i"}],"key":"VkcucNkntp"}],"urlSource":"https://arxiv.org/abs/1706.03762v7","key":"LfQibSqejN"},{"type":"text","value":" - The OG introduced the idea of self-attention and the encoder/decoder architecture for language translation tasks (the encoder later got dropped because it was only used for translation). Another breakthrough from this paper was the training; “The Transformer allows for significantly more parallelisation and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.” - This fact here was what let it: overtake RNNs (which weren’t parallelisable), and lead NVIDIA to be worth more than 2.7 Trillion token credits.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"dlh5dasW0y"}],"key":"w4d8iKFl63"}],"key":"yRlvfhE6IA"}],"key":"QVpP91ZWaO"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Table of contents","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CAk3KnUwt1"}],"identifier":"table-of-contents","label":"Table of contents","html_id":"table-of-contents","implicit":true,"key":"ynODvV0Qvt"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Background","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"YiH3s1qmTX"}],"identifier":"background","label":"Background","kind":"heading","template":"{name}","resolved":true,"html_id":"background","key":"iJlM8bQx4o"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"link","url":"#data-types-math","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Data types and math operations","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"idpE30yBoz"}],"urlSource":"#data-types-math","key":"rUoQEEDXtt"}],"key":"MjtqVhzrJY"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Tensors","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Paqt09nmmF"}],"identifier":"tensors","label":"tensors","kind":"heading","template":"{name}","resolved":true,"html_id":"tensors","key":"AkCKolZ2ZZ"}],"key":"N4zCNpbII9"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"link","url":"#math","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Math","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"xhMLNs00EA"}],"urlSource":"#math","key":"MRzz3kj7o7"}],"key":"uCbSYtIi2i"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Matrix Multiplication","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Pzla5tS0rE"}],"identifier":"matrix-multiplication","label":"matrix-multiplication","kind":"heading","template":"{name}","resolved":true,"html_id":"matrix-multiplication","key":"nNmzuLYdXC"}],"key":"Zm0y9Ps7uz"}],"key":"OrhkxiI3QG"}],"key":"tCS4U1fDRs"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"cQq5ku1zkc"}],"identifier":"gpt","label":"gpt","kind":"heading","template":"{name}","resolved":true,"html_id":"gpt","key":"TMqBQcxtFK"}],"key":"eLGuANMaT3"}],"key":"DwqX9clWQO"}],"key":"h0D85lJAzI"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Background","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lbwvrc31WP"}],"identifier":"background","label":"Background","html_id":"background","implicit":true,"key":"Lr5tyc7f7b"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Before we can dive into the transformer, we need to cover the basics:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"SqOHj3KWGM"}],"key":"kQYzWbRbR9"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":4,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Datatypes","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"JPul5hG0a3"}],"key":"KE81szog1z"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Matricies + Tensors","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"q6ct3Gf5QQ"}],"key":"yZKoOt1ehm"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Matrix multiplication","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"xV9dV2o9Ji"}],"key":"HZe4x7XfFO"}],"key":"qp9gym8Sup"}],"key":"uQEMaHWI9q"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"","children":[],"urlSource":"","key":"JTcUmhtVlZ"}],"key":"l4r68oZ4ZF"},{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Datatypes and Math","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Yfp6GPW6Xg"}],"identifier":"datatypes-and-math","label":"Datatypes and Math","html_id":"datatypes-and-math","implicit":true,"key":"RGPwAj4kP1"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Because we’re GPU poor, and because it makes the implementation easier, we use float32 for all parameters and calculations.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"T7cmCXMfUi"}],"key":"kKeFE7ufAE"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"CPUs can either do calculations in 32 or 64 bits, but the go standard library is opinionated and only supports 64 bit math operations. This wraps all the math functions we need. Whilst all modern architectures have instructions for both float32 and float64 operations, float32 is still faster because it uses 1/2 the bits, so the throughput can be 2x the float64 (citation needed). This is an obvious optimisation for this implementation.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"WbN1ZMbWK6"}],"key":"PqBqFJvl1p"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Because graphics applications aren’t needed to be precise, GPUs often use IEEE 754 half precision which is 16 bits, the training loss from switching from 32 -\u003e 16 bits is negligible. (citation needed)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"f6oov8E4iT"}],"key":"Oj4rBYhlXN"},{"type":"heading","depth":4,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Papers","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"uZ54zDX4Ns"}],"identifier":"papers","label":"Papers","html_id":"papers","implicit":true,"key":"w3DqaXsfwP"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/IEEE_754","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"IEEE-754","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"Z7ynVuzD8J"}],"urlSource":"https://en.wikipedia.org/wiki/IEEE_754","data":{"page":"IEEE_754","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"E7xb34tr5I"},{"type":"text","value":" - I’ve linked the Wikipedia because you need to pay for the standard.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"AA8GiIf6Go"}],"key":"hY6HSHSvRO"}],"key":"WNT6M5EoIG"}],"key":"G4ELFueuMB"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"import \"math\"\n\nfunc Abs(x float32) float32 {\n\tif x \u003e 0 {\n\t\treturn x\n\t}\n\treturn -x\n}\n\nfunc Cosh(x float32) float32 {\n\treturn float32(math.Cosh(float64(x)))\n}\n\nfunc Exp(x float32) float32 {\n\treturn float32(math.Exp(float64(x)))\n}\n\nfunc Inf(sign int) float32 {\n\treturn float32(math.Inf(sign))\n}\n\nfunc Log(x float32) float32 {\n\treturn float32(math.Log(float64(x)))\n}\n\nfunc IsNaN(f float32) bool {\n\treturn math.IsNaN(float64(f))\n}\n\nfunc Pow(x, y float32) float32 {\n\treturn float32(math.Pow(float64(x), float64(y)))\n}\n\nfunc Sqrt(x float32) float32 {\n\treturn float32(math.Sqrt(float64(x)))\n}\n\nfunc Tanh(x float32) float32 {\n\treturn float32(math.Tanh(float64(x)))\n}\n","key":"zCEDS4YXQw"},{"type":"output","id":"V5c9ch2KY316dXWoA8-i1","data":[],"key":"qZnD3DeTzd"}],"key":"I3WmYzXhfL"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"","children":[],"urlSource":"","key":"f4uW6aNpZ5"}],"key":"NdFDWp0EJD"},{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Tensors","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"zDQLwCc0US"}],"identifier":"tensors","label":"Tensors","html_id":"tensors","implicit":true,"key":"Gw1uS0BYcU"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"What is a tensor?\nA tensor is a multi-dimensional array. A regular slice is one-dimensional, holding elements in a sequence. A tensor can have multiple dimensions, like a 2D array (grid) or even a 3D array (cube).","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"CQoDeo26Jm"}],"key":"CLZa0wXBpi"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Tensor libraries like pytorch or tensorflow exist in python. The most widely used tensor library for local inference is ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"eDj7LhJkm8"},{"type":"link","url":"https://ggml.ai/","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"https://ggml.ai/","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"sriFJAU4ug"}],"urlSource":"https://ggml.ai/","key":"a06HzEBGDf"},{"type":"text","value":" which powers ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"d9IgVqEbPb"},{"type":"link","url":"https://github.com/ggerganov/llama.cpp","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"llama.cpp","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"ZwibPMqZE8"}],"urlSource":"https://github.com/ggerganov/llama.cpp","error":true,"key":"EIqOIYPAiJ"},{"type":"text","value":".","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"k35uGzRkts"}],"key":"zGzPYdHYs6"},{"type":"container","kind":"figure","children":[{"type":"iframe","src":"https://www.youtube.com/embed/DfK83xEtJ_k","width":"100%","key":"NQxKMswtTg"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"What is a tensor","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"IPGJt4Gkd7"}],"key":"K1Lux9oWFt"}],"key":"PbJc0WTlOV"}],"enumerator":"2","key":"zNT6onbkP5"}],"key":"urv8H1BGAZ"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"\ntype tensor struct {\n\tdata []float32\n\tdims []int\n    stride []int\n}\n\nfunc (t tensor) Data() []float32 {\n\treturn t.data\n}\n\nfunc newTensor(data []float32, dims ...int) (tensor, int) {\n\ts := 1\n\tfor _, d := range dims {\n\t\ts *= d\n\t}\n\tif s \u003e len(data) {\n\t\tpanic(\"dimensions larger than supplied data\")\n\t}\n\tss := min(s, len(data))\n\treturn tensor{\n\t\tdata: data[:ss],\n\t\tdims: dims,\n\t}, ss\n}\n\nfunc (t tensor) size() int {\n\tsize := 1\n\tfor _, dim := range t.dims {\n\t\tsize *= dim\n\t}\n\treturn size\n}\n\nfunc (t tensor) index(idx ...int) tensor {\n\t// 1. Error Handling (Partially Adjusted)\n\tif len(idx) \u003e len(t.dims) {\n\t\tpanic(\"Too many indices for tensor dimensions\")\n\t}\n\tfor i, dim := range idx {\n\t\tif dim \u003c 0 || dim \u003e= t.dims[i] {\n\t\t\tpanic(\"Index out of bounds\")\n\t\t}\n\t}\n\t// 2. Calculate Linear Index (Partially Adjusted)\n\tlinearIndex := idx[0]\n\tstride := t.size()\n\tfor i := 1; i \u003c len(idx); i++ {\n\t\tstride /= t.dims[i]\n\t\tlinearIndex += idx[i] * stride\n\t}\n\t// 3. Adjust Dimensions and Return Sub-Tensor\n\tnewDims := t.dims[len(idx):]                  // Keep remaining dimensions\n\tend := linearIndex + t.subTensorSize(newDims) // Size based on remaining dimensions\n\n\treturn tensor{\n\t\tdata: t.data[linearIndex:end],\n\t\tdims: newDims,\n\t}\n}\n\n// Helper function to calculate the size of a sub-tensor\nfunc (t tensor) subTensorSize(idx []int) int {\n\tsubTensorSize := 1\n\tfor _, dim := range t.dims[len(idx):] {\n\t\tsubTensorSize *= dim\n\t}\n\treturn subTensorSize\n}\n","key":"BIBPwZab8C"},{"type":"output","id":"O621W3B8-kUCA44u7CYhX","data":[],"key":"oTYSUPmBEC"}],"key":"nmJRxVtbcj"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"","children":[],"urlSource":"","key":"etD0jHfwlC"}],"key":"C0WvBSkCJ3"},{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Matrix Multiplication","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"uJ9HyCn6Fu"}],"identifier":"matrix-multiplication","label":"Matrix Multiplication","html_id":"matrix-multiplication","implicit":true,"key":"HPmdtoJdCY"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"matmulForward performs matrix multiplication and adds bias.\nParameters:","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"BLStuzab9J"}],"key":"jpTWIhMNty"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":6,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"out: output matrix","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"tpfiVf3jsg"}],"key":"zHoDodhmS3"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"inp: input matrix","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"hG3RRjtqto"}],"key":"iCOeVqB25T"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"weight: weight matrix","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"KCXgPnvafb"}],"key":"wti9DhO3WO"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"bias: bias vector","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Ug7LnODVdk"}],"key":"wPW1Y8Wcjz"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"B: batch size","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"irW36NbmQp"}],"key":"to8G4QXP0S"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"T: sequence length (number of time steps)","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"A1tTmQOyye"}],"key":"NhiOHj0HdC"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"C: input dimension (number of features)","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"AJtyKNuXd9"}],"key":"btgdSHCltv"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"OC: number of output channels","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"UfWKoQpTf3"}],"key":"cZlrPuZwDz"}],"key":"e4o8c0CqPR"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Most of the time spent in inference is in this function. Because we’re only doing this on a CPU this implemenation is very, very slow, and this is where different implementations would use a GPU/CUDA/Metal implementation to do parallel computation.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"MrRWLYimTu"}],"key":"peavjVsann"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"On CPU, many architectures have an optimisation called Basic Linear Algebra Subprograms ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"jFdyOpwkJB"},{"type":"link","url":"https://netlib.org/blas/","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"BLAS","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"B1iszRQ6re"}],"urlSource":"https://netlib.org/blas/","key":"n3O90jS6JF"},{"type":"text","value":". This allows for tiling (breaking matricies into smaller pieces and processing) or Single Instruction Multiple Data (SIMD).","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"ZdQNGUOBbA"}],"key":"S7MKN4q114"},{"type":"container","kind":"figure","children":[{"type":"iframe","src":"https://www.youtube.com/embed?v=XkY2DOUCWMU","width":"100%","key":"h3EicI32Va"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Matrix multiplication","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"r9Ybs9YYda"}],"key":"ve3agMLh0l"}],"key":"lF6pcTOhHY"}],"enumerator":"3","key":"D8uuRZ1LNc"}],"key":"vppYIbJA5s"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func matmulForward(out, inp, weight, bias []float32, B, T, C, OC int) {\n\t// Iterate over each batch\n\tvar wg sync.WaitGroup\n\tfor b := 0; b \u003c B; b++ {\n\t\t// Iterate over each time step in the sequence\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\twg.Add(1)\n\t\t\tgo func(b, t int) {\n\t\t\t\tdefer wg.Done()\n\t\t\t\t// Calculate the index in the output slice\n\t\t\t\tinp_bt := inp[b*T*C+t*C:]\n\t\t\t\tout_bt := out[b*T*OC+t*OC:]\n\t\t\t\tfor o := 0; o \u003c OC; o++ {\n\t\t\t\t\tvar val float32\n\t\t\t\t\tif bias != nil {\n\t\t\t\t\t\tval = bias[o]\n\t\t\t\t\t}\n\t\t\t\t\t// Calculate the index in the weight slice\n\t\t\t\t\twrow := weight[o*C:]\n\t\t\t\t\t// Perform the dot product between the input and weight row\n\t\t\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\t\t\tval += inp_bt[i] * wrow[i]\n\t\t\t\t\t}\n\t\t\t\t\t// Store the output value in the output slice\n\t\t\t\t\tout_bt[o] = val\n\t\t\t\t}\n\t\t\t}(b, t)\n\t\t}\n\t}\n\twg.Wait()\n}\n","key":"G9SpgW3zaf"},{"type":"output","id":"oSebqDkoe8CesyXTere07","data":[],"key":"BYJ1Imke8s"}],"key":"YKeCcu5ZOW"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"","children":[],"urlSource":"","key":"MReHuA41yf"}],"key":"itARs4jD0k"},{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"GPT","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"W3ST1QUpbF"}],"identifier":"gpt","label":"GPT","html_id":"gpt","implicit":true,"key":"iZuPNtukrA"},{"type":"image","url":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","alt":"decoder","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"j2yES4Le4A","urlSource":"decoder-only.svg"}],"key":"FuCvnOGQoc"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Table of contents","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yRicyNHm5l"}],"identifier":"table-of-contents","label":"Table of contents","html_id":"table-of-contents-1","implicit":true,"key":"xW6WpGyKFd"},{"type":"heading","depth":3,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Parameters vs Activations","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"S9PBV92NFA"}],"identifier":"parameters-vs-activations","label":"Parameters vs Activations","html_id":"parameters-vs-activations","implicit":true,"key":"cvGxWJFWCN"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Parameters","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"k7XaG7OiP0"}],"identifier":"parameters","label":"parameters","kind":"heading","template":"{name}","resolved":true,"html_id":"parameters","key":"BIBvO6ogVv"},{"type":"text","value":" - The bulk of what makes up “the model”. Most of the bytes you download comes from this part.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"lXGQw0yKbl"}],"key":"xnEt5Ykmxw"}],"key":"bE6y0xHS1T"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Activations","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"YoiD0kMCxO"}],"identifier":"activations","label":"activations","kind":"heading","template":"{name}","resolved":true,"html_id":"activations","key":"sU4SdrDaQ5"},{"type":"text","value":" - Output of mathematical operations between the input and the parameters.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"sVGiLh3zo3"}],"key":"bbBFyGsFBu"}],"key":"utpruhmOC7"}],"key":"tlHNqSUlJo"},{"type":"heading","depth":3,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Forward pass","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"P6yc3PsOsO"}],"identifier":"forward-pass","label":"Forward pass","html_id":"forward-pass","implicit":true,"key":"KwdFCv3sBz"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"A forward pass is the “inference” stage - this section is what’s occuring when you talk with ChatGPT.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"sIzQhJOjAy"}],"key":"MyVFtMhN5K"},{"type":"heading","depth":4,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Preparing","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"Mpy4fnlodz"}],"identifier":"preparing","label":"Preparing","html_id":"preparing","implicit":true,"key":"FXyAuWJWzR"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"This section transforms text into a vector representation that can be processed by a neural network.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"H3cf2nWN35"}],"key":"jh82CI9sYG"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":14,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Tokenizer","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"dXqOoYd71s"}],"identifier":"tokenizer","label":"tokenizer","kind":"heading","template":"{name}","resolved":true,"html_id":"tokenizer","key":"YqTxt9YYKF"},{"type":"text","value":" - Converts text to numeric ids that can be processed.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"Z89A1rNuFU"}],"key":"NfB9jPWTUh"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"link","url":"#data","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Data Loading","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"aoahjTJCgO"}],"urlSource":"#data","key":"PEujLHN0XM"},{"type":"text","value":" - This section describes how data is loaded, including batching, tokenization, and offsetting.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"GyTBsjwIab"}],"key":"ExLlYBOX85"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Embedding","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"QFuFhBF8ZF"}],"identifier":"embedding","label":"embedding","kind":"heading","template":"{name}","resolved":true,"html_id":"embedding","key":"YZhSTivTxz"},{"type":"text","value":" - Converts these ids into n dimensional vector space","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"CW2vWdb2ic"}],"key":"vDVUJ4uY6M"}],"key":"E8ULBOl4hW"},{"type":"heading","depth":4,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"N-Layers","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"hFMqUoNiG7"}],"identifier":"n-layers","label":"N-Layers","html_id":"n-layers","implicit":true,"key":"SEzad3BgSC"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"This section is repeated for every layer. GPT-2 has 12 layers.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"Kb2UEB1G02"}],"key":"QO7qs4oMFR"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":20,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"link","url":"#masked-multi-head-attention","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"Masked Multi-Head Attention","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"Oju91X6HCx"}],"urlSource":"#masked-multi-head-attention","key":"zrSwgbWzp1"},{"type":"text","value":" - Allows all tokens in the context window to impact other tokens in the context window","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"SYLg7UA6ND"}],"key":"QBweOOdtT6"},{"type":"listItem","spread":true,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"link","url":"#add-norm","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Add and Norm","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"KnELIDyx6M"}],"urlSource":"#add-norm","key":"lL3A3ALO4k"},{"type":"text","value":" - Adds residual stream and normalises outputs","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"Pi79nANuxj"}],"key":"KjDXpFi4ss"},{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"link","url":"#feed-forward","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Feed Forward","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"hxC1kZhN7P"}],"urlSource":"#feed-forward","key":"cg5OYh8ZLV"},{"type":"text","value":" - Feed forward is a standard MLP. Allows for more complex connections to be formed than just the attention mechanism alone.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"VezXvSPpLD"}],"key":"V278uTGxpJ"}],"key":"yAYGHJ6TAg"},{"type":"heading","depth":4,"position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"Final transformations","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"xo9SNfQXhO"}],"identifier":"final-transformations","label":"Final transformations","html_id":"final-transformations","implicit":true,"key":"s7X288Bcyc"},{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"This section takes the higher dimensionality representations of our activations and processes it to give us our final output","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"pYy3tIfMmU"}],"key":"EbJ82m539R"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":26,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"link","url":"#linear","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"Linear","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"k4q2Y55JX5"}],"urlSource":"#linear","key":"pxptXRXO5g"},{"type":"text","value":" - Transformation that reduces dimensionality into “logits” which are correlated to how likely each token is (-inf==never, +inf=100% certainty)","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"obogvx8kz5"}],"key":"cfDX204BP2"},{"type":"listItem","spread":true,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Softmax","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"qx9fgc2prS"}],"identifier":"softmax","label":"softmax","kind":"heading","template":"{name}","resolved":true,"html_id":"softmax","key":"gr4jQo2ABE"},{"type":"text","value":" - This takes the logits and creates a probability distribution that adds up to 100%","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"EInQy8BPiz"}],"key":"jkECg11raw"},{"type":"listItem","spread":true,"position":{"start":{"line":28,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"Sampling","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"SkmVZIGGsK"}],"identifier":"sampling","label":"sampling","kind":"heading","template":"{name}","resolved":true,"html_id":"sampling","key":"PoBEz21TQn"},{"type":"text","value":" - This samples the probability distribution and returns the single token that’s needed to make the next prediction","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"s1s4R3Kijh"}],"key":"TDiA6fwxxU"}],"key":"ZJqBtbZlRu"},{"type":"heading","depth":4,"position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"A complete forward pass","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"WV5nZVhSvH"}],"identifier":"a-complete-forward-pass","label":"A complete forward pass","html_id":"a-complete-forward-pass","implicit":true,"key":"C2EalbgW1R"},{"type":"paragraph","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"This section puts all of this together.","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"iCVsmUdRmQ"}],"key":"hLkeDlcD57"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":32,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":32,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Forward","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"yTPXjfqnrX"}],"identifier":"forward","label":"forward","kind":"heading","template":"{name}","resolved":true,"html_id":"forward","key":"LFWhIQps2E"}],"key":"TpiZU9NjTV"}],"key":"dlWGFEHIh2"},{"type":"heading","depth":3,"position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Backwards pass","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"kXy9bNnZK7"}],"identifier":"backwards-pass","label":"Backwards pass","html_id":"backwards-pass","implicit":true,"key":"yBEGsgv4Tk"},{"type":"paragraph","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"This is “training”. Companies spend billions of dollars optimizing to make this as fast as possible.","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"LRIeVBcTgs"}],"key":"nsTspi11Z7"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":37,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"Backward Pass","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"mPtHwrXRrF"}],"identifier":"backward-pass","label":"backward-pass","kind":"heading","template":"{name}","resolved":true,"html_id":"backward-pass","key":"SgfVrOGqZi"},{"type":"text","value":" - Calculating the gradients for gradient descent + backprop.","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"Y7Ta4ROqVR"}],"key":"gWG9Jc4Dcs"},{"type":"listItem","spread":true,"position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"link","url":"#optimizer","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Optimizer","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"t1JD0nDStg"}],"urlSource":"#optimizer","key":"Nl8zasuJl5"},{"type":"text","value":" - Determines how fast the model learns","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"GHCTNrKRDH"}],"key":"NuYOtlEor7"},{"type":"listItem","spread":true,"position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"link","url":"#training-our-model","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Training our model","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"klIpy2Wftn"}],"urlSource":"#training-our-model","key":"T0atHY9lGP"},{"type":"text","value":" - Let’s train gpt.","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"KnU9IBlaij"}],"key":"KLkbuzTe9r"}],"key":"EL8OHEA4OT"}],"key":"cBXn9fJNS4"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"","children":[],"urlSource":"","key":"EpvDT6o5zM"}],"key":"S2NvusgXqx"},{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Data loading","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ty4EPpsgsL"}],"identifier":"data-loading","label":"Data loading","html_id":"data-loading","implicit":true,"key":"HqWCJilGhx"}],"key":"dbG0vKwe2O"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"import (\n\t\"bytes\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"io\"\n)\n\nconst Int32ByteLen = 4\n\ntype DataLoader struct {\n\tfilename        string\n\tbatchSize       int\n\tseqLength       int\n\tcurrentPosition int64\n\tfileSize        int64\n\tNumBatches      int\n\tdata            []int32\n\tdataAll         []int32\n}\n\nfunc NewDataLoader(filename string, batchSize, seqLength int) (*DataLoader, error) {\n\tfile, err := os.Open(filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn newDataLoader(file, batchSize, seqLength)\n}\n\nfunc newDataLoader(file io.Reader, batchSize, seqLength int) (*DataLoader, error) {\n\tdata, err := io.ReadAll(file)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsize := len(data)\n\tif size \u003c (batchSize*seqLength+1)*Int32ByteLen {\n\t\treturn nil, errors.New(\"error: file size is too small for the batch size and sequence length\")\n\t}\n\tloader := \u0026DataLoader{\n\t\tbatchSize:  batchSize,\n\t\tseqLength:  seqLength,\n\t\tNumBatches: size / (batchSize * seqLength * Int32ByteLen),\n\t\tdata:       make([]int32, size/Int32ByteLen),\n\t\tfileSize:   int64(size / Int32ByteLen),\n\t}\n\tif err := binary.Read(bytes.NewReader(data), binary.LittleEndian, loader.data); err != nil {\n\t\treturn nil, err\n\t}\n\treturn loader, nil\n}\n\nfunc newDataLoaderFromInts(data []int32, batchSize, seqLength int) (*DataLoader, error) {\n\tsize := len(data)\n\tif size \u003c (batchSize*seqLength + 1) {\n\t\treturn nil, errors.New(\"error: file size is too small for the batch size and sequence length\")\n\t}\n\tloader := \u0026DataLoader{\n\t\tbatchSize:  batchSize,\n\t\tseqLength:  seqLength,\n\t\tNumBatches: size / (batchSize * seqLength),\n\t\tdata:       data,\n\t\tfileSize:   int64(size),\n\t}\n\treturn loader, nil\n}\n\nfunc (loader *DataLoader) Reset() {\n\tloader.currentPosition = 0\n}\n\nfunc (loader *DataLoader) NextBatch() ([]int32, []int32, error) {\n\tnextPos := loader.currentPosition + int64(loader.batchSize*loader.seqLength)\n\tif nextPos+1 \u003e loader.fileSize {\n\t\tloader.Reset()\n\t\tnextPos = loader.currentPosition + int64(loader.batchSize*loader.seqLength)\n\t}\n\t// don't  x4 because we're indexing int32 not byte\n\tinputs := loader.data[loader.currentPosition:nextPos]\n\ttargets := loader.data[loader.currentPosition+1 : nextPos+1]\n\tloader.currentPosition = nextPos\n\treturn inputs, targets, nil\n}\n","key":"dSVQbahmno"},{"type":"output","id":"ESRZpyrAxWkkMNwxz3X1T","data":[],"key":"yENd67mgP4"}],"key":"IHrcOUFTy5"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Parameters ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bi4Eg9AjSd"},{"type":"link","url":"","children":[],"urlSource":"","key":"vhYwMaHOlb"}],"identifier":"parameters","label":"Parameters ","html_id":"parameters","implicit":true,"key":"nrYO1MynMN"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"A Parameter is a numerical value that determines the strength of the connection between neurons. These connections are similar to synapses in the human brain, and the parameters are like the knobs that adjust the strength of those connections.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"oFDqOh13nb"}],"key":"Sw6X7MEkdu"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"There are two main types of parameters in neural networks:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"DAkuXyNYad"}],"key":"eYGh5gS75n"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Weights: These are associated with each connection between neurons. They multiply the signal coming from one neuron before it’s passed on to the next neuron. A higher weight means a stronger connection and a greater influence on the receiving neuron.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"uclypc0c7T"}],"key":"ulD78uEkX1"}],"key":"DfsPP8saxE"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Biases: These are added to the sum of the weighted inputs at each neuron. They act like a baseline shift, allowing the neuron to activate even if the weighted inputs are weak.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"S6zRqXkfQR"}],"key":"zp5zko4rqJ"}],"key":"ijca1te57w"}],"key":"og7IzYGRD1"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ZkmkyxlkNO"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"yyJfTxEJQY"}],"key":"bfthJMoKAZ"}],"key":"Vd2yk9Kt3z"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"// ParameterTensors are the parameters of the model\ntype ParameterTensors struct {\n\tMemory        []float32\n\tWordTokEmbed  tensor // (V, C) - Word/Token Embedding weights (Vocabulary size, Embedding dimension)\n\tWordPosEmbed  tensor // (maxT, C) - Positional Embedding weights (Maximum Sequence length, Embedding dimension)\n\tLayerNorm1W   tensor // (L, C) - Weights for Layer Normalization 1 (Number of layers, Embedding dimension)\n\tLayerNorm1B   tensor // (L, C) - Biases for Layer Normalization 1\n\tQueryKeyValW  tensor // (L, 3*C, C) - Attention QKV weights (Layers, 3 * Embedding dimension, Embedding dimension)\n\tQueryKeyValB  tensor // (L, 3*C) - Attention QKV biases\n\tAttProjW      tensor // (L, C, C) - Attention projection weights (Layers, Embedding dimension, Embedding dimension)\n\tAttProjB      tensor // (L, C) - Attention projection biases\n\tLayer2NormW   tensor // (L, C) - Weights for Layer Normalization 2\n\tLayer2NormB   tensor // (L, C) - Biases for Layer Normalization 2\n\tFeedFwdW      tensor // (L, 4*C, C) - Feed-forward layer weights (Layers, 4 * Embedding Dimension, Embedding Dimension)\n\tFeedFwdB      tensor // (L, 4*C) - Feed-forward layer biases\n\tFeedFwdProjW  tensor // (L, C, 4*C) - Feed-forward projection weights\n\tFeedFwdProjB  tensor // (L, C)- Feed-forward projection biases\n\tLayerFinNormW tensor // (C) - Final layer normalization weights\n\tLayerFinNormB tensor // (C) - Final layer normalization biases\n}\n\nfunc newParameterTensors(V, C, maxSeqLen, L int) ParameterTensors {\n\tvar tensor ParameterTensors\n\ttensor.Init(V, C, maxSeqLen, L)\n\treturn tensor\n}\n\nfunc (tensor *ParameterTensors) Len() int {\n\treturn len(tensor.Memory)\n}\n\n// Init initialises the ParameterTensors with specific sizes for each tensor based on the model architecture.\nfunc (tensor *ParameterTensors) Init(V, C, maxSeqLen, L int) {\n\ttensor.Memory = make([]float32,\n\t\tV*C+ // WordTokEmbed\n\t\t\tmaxSeqLen*C+ // WordPosEmbed\n\t\t\tL*C+ // LayerNorm1W\n\t\t\tL*C+ // LayerNorm1B\n\t\t\tL*3*C*C+ // QueryKeyValW\n\t\t\tL*3*C+ // QueryKeyValB\n\t\t\tL*C*C+ // AttProjW\n\t\t\tL*C+ // AttProjB\n\t\t\tL*C+ // Layer2NormW\n\t\t\tL*C+ // Layer2NormB\n\t\t\tL*4*C*C+ // FeedFwdW\n\t\t\tL*4*C+ // FeedFwdB\n\t\t\tL*C*4*C+ // FeedFwdProjW\n\t\t\tL*C+ // FeedFwdProjB\n\t\t\tC+ // LayerFinNormW\n\t\t\tC, // LayerFinNormB\n\t)\n\tvar ptr int\n\tmemPtr := tensor.Memory\n\ttensor.WordTokEmbed, ptr = newTensor(memPtr, V, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.WordPosEmbed, ptr = newTensor(memPtr, maxSeqLen, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNorm1W, ptr = newTensor(memPtr, L, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNorm1B, ptr = newTensor(memPtr, L, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.QueryKeyValW, ptr = newTensor(memPtr, L, 3*C, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.QueryKeyValB, ptr = newTensor(memPtr, L, 3*C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.AttProjW, ptr = newTensor(memPtr, L, C, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.AttProjB, ptr = newTensor(memPtr, L, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.Layer2NormW, ptr = newTensor(memPtr, L, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.Layer2NormB, ptr = newTensor(memPtr, L, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.FeedFwdW, ptr = newTensor(memPtr, L, 4*C, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.FeedFwdB, ptr = newTensor(memPtr, L, 4*C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.FeedFwdProjW, ptr = newTensor(memPtr, L, C, 4*C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.FeedFwdProjB, ptr = newTensor(memPtr, L, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerFinNormW, ptr = newTensor(memPtr, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerFinNormB, ptr = newTensor(memPtr, C)\n\tmemPtr = memPtr[ptr:]\n\tif len(memPtr) != 0 {\n\t\tpanic(\"something went real bad here\")\n\t}\n}\n","key":"m3ZCpp0Vy2"},{"type":"output","id":"u6Jm6A9FVoYASzMY5q7T9","data":[],"key":"OBSnUZISW0"}],"key":"WNNW4Lk13x"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"","children":[],"urlSource":"","key":"z4XUdI3XDJ"}],"key":"yp31LTSkmq"},{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Activations","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"jEgRYijWtS"}],"identifier":"activations","label":"Activations","html_id":"activations","implicit":true,"key":"JYnVpbmaG9"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"An activation is the output of the input, and a mathematical operation. If the weight determines the strength of the function, the activation is the output.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"epgPKFMdb2"}],"key":"Ghr28oOiIu"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ji9ifdpY8W"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"a5UTmPGkop"}],"key":"ackeBmtwHs"}],"key":"PINjjnWYTM"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"\n// ActivationTensors\ntype ActivationTensors struct {\n\tMemory             []float32\n\tEncoded            tensor // (B, T, C) - Initial encoded input representations (Batch size, Sequence length, Embedding dimension)\n\tLayer1Act          tensor // (L, B, T, C) - Activations after Layer Normalization 1\n\tLayerNorm1Mean     tensor // (L, B, T) - Mean values for Layer Normalization 1\n\tLayerNorm1Rstd     tensor // (L, B, T) - Reciprocal of standard deviation for Layer Normalization 1\n\tQueryKeyVal        tensor // (L, B, T, 3*C) - Combined Query, Key, Value representations for attention\n\tAttentionInter     tensor // (L, B, T, C) - Intermediate attention-like result\n\tPreAttention       tensor // (L, B, NH, T, T) - Pre-attention scores\n\tAttention          tensor // (L, B, NH, T, T) - Normalized attention weights (Number of layers, Batch size, Number of Attention Heads, Sequence length, Sequence length)\n\tAttentionProj      tensor // (L, B, T, C) - Projected attention outputs\n\tResidual2          tensor // (L, B, T, C) - Residual connection after attention\n\tLayerNorm2Act      tensor // (L, B, T, C) - Activations after Layer Normalization 2\n\tLayerNorm2Mean     tensor // (L, B, T) - Mean values for Layer Normalization 2\n\tLayerNorm2Rstd     tensor // (L, B, T) - Reciprocal of standard deviation for Layer Normalization 2\n\tFeedForward        tensor // (L, B, T, 4*C) - Intermediate Feed-Forward Network activations\n\tFeedForwardGelu    tensor // (L, B, T, 4*C) - FeedForward activations after applying GELU (non-linearity)\n\tFeedForwardProj    tensor // (L, B, T, C) - Projected output of the Feed-Forward Network\n\tResidual3          tensor // (L, B, T, C) - Residual connection after Feed-Forward Network\n\tLayerNormFinal     tensor // (B, T, C) - Final activations after Layer Normalization\n\tLayerNormFinalMean tensor // (B, T) - Mean values for final Layer Normalization\n\tLayerNormFinalStd  tensor // (B, T) - Reciprocal of standard deviation for final Layer Normalization\n\tLogits             tensor // (B, T, V) - Raw output scores (before softmax)\n\tProbabilities      tensor // (B, T, V) - Softmax probabilities over the vocabulary\n\tLosses             tensor // (B, T) - Loss values per token in the batch\n}\n\nfunc (tensor *ActivationTensors) Init(B, C, T, L, NH, V int) {\n\ttensor.Memory = make([]float32,\n\t\tB*T*C+\n\t\t\tL*B*T*C+\n\t\t\tL*B*T+\n\t\t\tL*B*T+\n\t\t\tL*B*T*C*3+\n\t\t\tL*B*T*C+\n\t\t\tL*B*NH*T*T+\n\t\t\tL*B*NH*T*T+\n\t\t\tL*B*T*C+\n\t\t\tL*B*T*C+\n\t\t\tL*B*T*C+\n\t\t\tL*B*T+\n\t\t\tL*B*T+\n\t\t\tL*B*T*C*4+\n\t\t\tL*B*T*C*4+\n\t\t\tL*B*T*C+\n\t\t\tL*B*T*C+\n\t\t\tB*T*C+\n\t\t\tB*T+\n\t\t\tB*T+\n\t\t\tB*T*V+\n\t\t\tB*T*V+\n\t\t\tB*T)\n\tvar ptr int\n\tmemPtr := tensor.Memory\n\ttensor.Encoded, ptr = newTensor(memPtr, B, T, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.Layer1Act, ptr = newTensor(memPtr, L, B, T, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNorm1Mean, ptr = newTensor(memPtr, L, B, T)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNorm1Rstd, ptr = newTensor(memPtr, L, B, T)\n\tmemPtr = memPtr[ptr:]\n\ttensor.QueryKeyVal, ptr = newTensor(memPtr, L, B, T, C*3)\n\tmemPtr = memPtr[ptr:]\n\ttensor.AttentionInter, ptr = newTensor(memPtr, L, B, T, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.PreAttention, ptr = newTensor(memPtr, L, B, NH, T, T)\n\tmemPtr = memPtr[ptr:]\n\ttensor.Attention, ptr = newTensor(memPtr, L, B, NH, T, T)\n\tmemPtr = memPtr[ptr:]\n\ttensor.AttentionProj, ptr = newTensor(memPtr, L, B, T, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.Residual2, ptr = newTensor(memPtr, L, B, T, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNorm2Act, ptr = newTensor(memPtr, L, B, T, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNorm2Mean, ptr = newTensor(memPtr, L, B, T)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNorm2Rstd, ptr = newTensor(memPtr, L, B, T)\n\tmemPtr = memPtr[ptr:]\n\ttensor.FeedForward, ptr = newTensor(memPtr, L, B, T, C*4)\n\tmemPtr = memPtr[ptr:]\n\ttensor.FeedForwardGelu, ptr = newTensor(memPtr, L, B, T, C*4)\n\tmemPtr = memPtr[ptr:]\n\ttensor.FeedForwardProj, ptr = newTensor(memPtr, L, B, T, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.Residual3, ptr = newTensor(memPtr, L, B, T, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNormFinal, ptr = newTensor(memPtr, B, T, C)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNormFinalMean, ptr = newTensor(memPtr, B, T)\n\tmemPtr = memPtr[ptr:]\n\ttensor.LayerNormFinalStd, ptr = newTensor(memPtr, B, T)\n\tmemPtr = memPtr[ptr:]\n\ttensor.Logits, ptr = newTensor(memPtr, B, T, V)\n\tmemPtr = memPtr[ptr:]\n\ttensor.Probabilities, ptr = newTensor(memPtr, B, T, V)\n\tmemPtr = memPtr[ptr:]\n\ttensor.Losses, ptr = newTensor(memPtr, B, T)\n\tmemPtr = memPtr[ptr:]\n\tif len(memPtr) != 0 {\n\t\tpanic(\"something went real bad here\")\n\t}\n}","key":"aUU0E9WeeZ"},{"type":"output","id":"MIx-DAG_p_LUz9KXKBLsS","data":[],"key":"QnjwfeP1LN"}],"key":"imI5mQbZUf"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"","children":[],"urlSource":"","key":"ixgB3zC9wr"}],"key":"gMR0TRB9Uu"},{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Tokenizer","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"qE9E8ikf36"}],"identifier":"tokenizer","label":"Tokenizer","html_id":"tokenizer","implicit":true,"key":"dbTxXGQxzm"},{"type":"image","url":"/build/tokenization-eb5de751dbe589c933f44323d83d5ddc.svg","alt":"tokenization","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"OrFj2FQrt1","urlSource":"tokenization.svg"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Tokenization is the fundamental process of transforming text data into a format the model can understand. It involves breaking down sentences into smaller units called tokens.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"SX7ao9ned7"}],"key":"LQs4dFkCKh"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"ECkLD7czzV"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"H55VwHVuJG"}],"key":"hHHxdLd6up"}],"key":"bevELSVr2m"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"import (\n\t\"encoding/binary\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"os\"\n\t\"sort\"\n)\n\nconst GPT2_EOT int32 = 50256\n\ntype Tokenizer struct {\n\tvocabSize  uint32\n\ttokenTable []string         // tokenTable maps token id to string\n\ttokenMap   map[string]int32 // tokenMap maps token to id\n\tinit       bool\n}\n\nfunc newTokenizer(vocab []string) Tokenizer {\n\ttokenizer := Tokenizer{\n\t\tvocabSize:  uint32(len(vocab)),\n\t\ttokenTable: vocab,\n\t\ttokenMap:   make(map[string]int32),\n\t\tinit:       true,\n\t}\n\tfor i, token := range vocab {\n\t\ttokenizer.tokenMap[token] = int32(i)\n\t}\n\treturn tokenizer\n}\n\nfunc NewTokenizer(filename string) (Tokenizer, error) {\n\tf, err := os.Open(filename)\n\tif err != nil {\n\t\treturn Tokenizer{}, err\n\t}\n\tdefer f.Close()\n\theader := make([]uint32, 256)\n\tif err := binary.Read(f, binary.LittleEndian, header); err != nil {\n\t\treturn Tokenizer{}, err\n\t}\n\tif header[0] != 20240328 || header[1] != 1 {\n\t\treturn Tokenizer{}, errors.New(\"incorrect header for tokenizer\")\n\t}\n\ttok := Tokenizer{\n\t\tvocabSize:  header[2],\n\t\ttokenTable: make([]string, header[2]),\n\t\ttokenMap:   make(map[string]int32),\n\t\tinit:       true,\n\t}\n\tvar length byte\n\tfor i := range tok.tokenTable {\n\t\tif err := binary.Read(f, binary.LittleEndian, \u0026length); err != nil {\n\t\t\treturn tok, err\n\t\t}\n\t\tif length \u003c= 0 {\n\t\t\treturn tok, errors.New(\"tokenizer failure\")\n\t\t}\n\t\ttokenBytes := make([]byte, length)\n\t\tif err := binary.Read(f, binary.LittleEndian, tokenBytes); err != nil {\n\t\t\treturn tok, err\n\t\t}\n\t\ttok.tokenTable[i] = string(tokenBytes)\n\t\ttok.tokenMap[tok.tokenTable[i]] = int32(i)\n\t}\n\treturn tok, nil\n}\n\ntype TokenizerJSON struct {\n\tVersion string `json:\"version\"`\n\tModel   struct {\n\t\tType          string            `json:\"type\"`\n\t\tVocab         map[string]int    `json:\"vocab\"`\n\t\tMergesData    []string          `json:\"merges,omitempty\"`\n\t\tSpecialTokens map[string]string `json:\"special_tokens\"`\n\t} `json:\"model\"`\n}\n\nfunc NewTokenizerJson(filename string) (Tokenizer, error) {\n\t// Read the JSON file\n\tfileContent, err := os.ReadFile(filename)\n\tif err != nil {\n\t\treturn Tokenizer{}, err\n\t}\n\n\t// Unmarshal JSON into our struct\n\tvar tokenizerData TokenizerJSON\n\tif err := json.Unmarshal(fileContent, \u0026tokenizerData); err != nil {\n\t\treturn Tokenizer{}, err\n\t}\n\n\t// Create a new Tokenizer instance\n\ttok := Tokenizer{\n\t\tvocabSize:  uint32(len(tokenizerData.Model.Vocab)),\n\t\ttokenTable: make([]string, len(tokenizerData.Model.Vocab)),\n\t\ttokenMap:   make(map[string]int32),\n\t\tinit:       true,\n\t}\n\n\t// Create a slice of token-id pairs for sorting\n\tvar tokenIDPairs []struct {\n\t\tToken string\n\t\tID    int\n\t}\n\tfor token, id := range tokenizerData.Model.Vocab {\n\t\t// Convert the first two bytes to the 'Ġ' character if they match 0xC4 0xA0\n\t\tif len(token) \u003e= 2 \u0026\u0026 token[0] == 0xC4 \u0026\u0026 token[1] == 0xA0 {\n\t\t\ttoken = \" \" + token[2:]\n\t\t}\n\t\ttokenIDPairs = append(tokenIDPairs, struct {\n\t\t\tToken string\n\t\t\tID    int\n\t\t}{token, id})\n\t}\n\n\t// Sort the token-id pairs by ID\n\tsort.Slice(tokenIDPairs, func(i, j int) bool {\n\t\treturn tokenIDPairs[i].ID \u003c tokenIDPairs[j].ID\n\t})\n\n\t// Populate tokenTable and tokenMap\n\tfor i, pair := range tokenIDPairs {\n\t\ttok.tokenTable[i] = pair.Token\n\t\ttok.tokenMap[pair.Token] = int32(i)\n\t}\n\n\treturn tok, nil\n}\n\nfunc (t Tokenizer) Decode(tokens []int32) (string, error) {\n\ts := \"\"\n\tfor _, token := range tokens {\n\t\tif token \u003e= int32(len(t.tokenTable)) {\n\t\t\treturn \"\", errors.New(\"not valid token\")\n\t\t}\n\t\tif token != GPT2_EOT {\n\t\t\ts += t.tokenTable[token]\n\t\t}\n\t}\n\treturn s, nil\n}\n\nfunc (t Tokenizer) Encode(text string) ([]int32, error) {\n\ttokens := []int32{}\n\tfor len(text) \u003e 0 {\n\t\tlongestMatch := \"\"\n\t\tlongestMatchToken := int32(GPT2_EOT)\n\t\tfor i := len(text); i \u003e 0; i-- {\n\t\t\tsubStr := text[:i]\n\t\t\tif token, exists := t.tokenMap[subStr]; exists {\n\t\t\t\tlongestMatch = subStr\n\t\t\t\tlongestMatchToken = token\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif longestMatch == \"\" {\n\t\t\t// If no match found, treat the first character as an unknown token\n\t\t\ttokens = append(tokens, GPT2_EOT)\n\t\t\ttext = text[1:]\n\t\t} else {\n\t\t\ttokens = append(tokens, longestMatchToken)\n\t\t\ttext = text[len(longestMatch):]\n\t\t}\n\t}\n\treturn tokens, nil\n}\n","key":"ydMIilRx5U"},{"type":"output","id":"xVKCLRsdGCditfB7D7Sbf","data":[],"key":"h3lqo0CvnG"}],"key":"wwgnQbRzJ7"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Tokenize some text","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"phwHP5UVuH"}],"identifier":"tokenize-some-text","label":"Tokenize some text","html_id":"tokenize-some-text","implicit":true,"key":"acHBvXjN27"}],"key":"Xbtnxq9ivz"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"%%\ntokenizer, err := NewTokenizerJson(\"/Users/joshcarp/Documents/the-interactive-transformer/tokenizer.json\"); if err != nil {\n    panic(err)\n}\ngonbui.RequestInput(\"Tokenize some text: \", false)\nreader := bufio.NewReader(os.Stdin)\ninputText, err := reader.ReadString('\\n')\nif err != nil {\n    panic(err)\n}\nif err != nil { panic(err) }\nencoded, err := tokenizer.Encode(inputText)\nfmt.Println(\"encoded: \", encoded)\ndecoded, err := tokenizer.Decode(encoded)\nfmt.Println(\"decoded: \", decoded)\n","key":"UYxDSjyFjq"},{"type":"output","id":"rIqHsKt0O5LY8g2VmhDt0","data":[{"name":"stdout","output_type":"stream","text":"encoded:  [31373 612 220 50256]\ndecoded:  hello there \n"}],"key":"fAGKIC0Vxo"}],"key":"SF2Sl3g9LR"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"","children":[],"urlSource":"","key":"UZdN4o9HAc"}],"key":"ZspJ7oxXRp"},{"type":"heading","depth":3,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Embedding","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"oxyrfW3h3J"}],"identifier":"embedding","label":"Embedding","html_id":"embedding","implicit":true,"key":"ccme9QCrhE"},{"type":"image","url":"/build/embedding-6c47d2fc652eac0e4773bd7f9cdc736c.svg","alt":"embeddings","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Yj1WatSFAl","urlSource":"embedding.svg"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"encoderForward iterates through the batch/sequence and combines the word token embeddings\nwith the word position embeddings. This allows out vector to encode tokens and positions in one vector.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"v5TaHoBxT1"}],"key":"RV6wd36Mie"},{"type":"container","kind":"figure","children":[{"type":"iframe","src":"https://www.youtube.com/embed?v=gQddtTdmG_8","width":"100%","key":"h7L3Y4Idwp"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Word embeddings","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"GJOwroWEmV"}],"key":"uYnprw1JRw"}],"key":"fiA6flxSNA"}],"enumerator":"4","key":"QqyihuMXzb"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"qV3rHJYECJ"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"oRfQLv0aFe"}],"key":"gDCN65hLpw"}],"key":"sPx9nm8AGm"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func encoderForward(out []float32, inp []int32, wte []float32, wpe []float32, B, T, C int) {\n\t// Iterate over each batch\n\tfor b := 0; b \u003c B; b++ {\n\t\t// Iterate over each time step in the sequence\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\t// Calculate the index in the output slice. Each vector is C elements long.\n\t\t\tstartOutIndex := b*T*C + t*C\n\t\t\t// Calculate the token ID index in the input\n\t\t\t// inp is the tokenized input, each number in inp char is an index within wte (word token embeddings)\n\t\t\tix := inp[b*T+t]\n\t\t\t// Calculate the index in the token embeddings slice\n\t\t\t// inp -\u003e id -\u003e wte[id]\n\t\t\tstartWteIndex := ix * int32(C)\n\t\t\t// Calculate the index in the position embeddings slice\n\t\t\t// Wpe starts at 0 (when t is zero) which is basically mapping directly to index\n\t\t\tstartWpeIndex := t * C\n\t\t\t// Add the vectors from `wte` and `wpe` and store the result in `out`\n\t\t\t// here we combine the vectors in the C dimensions.\n\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\tout[startOutIndex+i] = wte[startWteIndex+int32(i)] + wpe[startWpeIndex+i]\n\t\t\t}\n\t\t}\n\t}\n}","key":"T8PTZwLbs8"},{"type":"output","id":"LPkMp0cq_3-hDzt7z4pWq","data":[],"key":"V0cOom74TE"}],"key":"yx6FAVSP5R"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"%test\nfunc TestEncoderForwardExplicit(t *testing.T) {\n    inp := []int32{1, 0} // [1 -\u003e wte (2, 3), wpe(4, 5)] [0 -\u003e wte (0, 1), wpe(6, 7)]\n    wte := []float32{0, 1, 2, 3}\n    wpe := []float32{4, 5, 6, 7}\n    B := 1 // Batch size\n    T := 1 // Sequence Len\n    C := 2 // Dimensions\n    out := make([]float32, len(inp))\n    encoderForward(out, inp, wte, wpe, B, T, C)\n    expectedOut := []float32{6, 8}\n    assert.Equal(t, expectedOut, out)\n}","key":"msve3HRaOn"},{"type":"output","id":"CoqMMq69KETxqRiuEz_dW","data":[{"name":"stdout","output_type":"stream","text":"=== RUN   TestEncoderForwardExplicit\n--- PASS: TestEncoderForwardExplicit (0.00s)\nPASS\n"}],"key":"puv9ygVx0o"}],"key":"wLVeVlkUaq"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"link","url":"","children":[],"urlSource":"","key":"xci0RMmPLR"}],"key":"xMdO404QK7"},{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Layernorm forward","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"pFJciRVPS2"}],"identifier":"layernorm-forward","label":"Layernorm forward","html_id":"layernorm-forward","implicit":true,"key":"vriRvaP8H3"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"layernormForward normalizes the activations in each layer.\nIt improves convergence in training and reduces sensitivity to initial parameters.\nFor each vector, the mean and variance are calculated.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"opH4t26Yya"}],"key":"xUSplH1rCi"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Parameters:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"SgeoHVh2ZI"}],"key":"gZvOVo2uVp"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":10,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"out: output activations (B,T,C)","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"x46J1X150s"}],"key":"ir8SBbFH1y"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"mean: mean values (B,T) for each position (b,t)","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"n3Y24VI8fa"}],"key":"h2XnNxKyoH"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"rstd: reciprocal standard deviations (B,T) for each position (b,t)","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"Fmc4HhXM6f"}],"key":"PvFd2CcqIH"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"inp: input activations (B,T,C)","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Sl0qowQYXv"}],"key":"zKvNN4IPVp"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"weight: learnable weight (C) for scaling","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"psnUSpHpNI"}],"key":"TpSoamM06b"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"bias: learnable bias (C) for shifting","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"S71H4VbH3R"}],"key":"ybkpk9j7bB"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"B: batch size","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"BCu8pztzam"}],"key":"uScU2NEEkg"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"T: sequence length (number of time steps)","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"WqwBEAQGvV"}],"key":"F65VvpeTsj"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"C: embedding dimension (number of features)","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"Jo8yZmewRr"}],"key":"KKWwupXXoU"}],"key":"sR40n6g1HM"},{"type":"heading","depth":4,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Papers","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"LiN9wZoAUW"}],"identifier":"papers","label":"Papers","html_id":"papers-1","implicit":true,"key":"iOnjQBpr3x"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":22,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1607.06450","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"strong","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Layer Normalization","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"YEFLwaa85x"}],"key":"RYBVxyf4tZ"}],"urlSource":"https://arxiv.org/abs/1607.06450","key":"aaTeB9cQac"},{"type":"text","value":" - Layernorm was introduced in this paper.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"KRGTnKI6JQ"}],"key":"BzwylHe8EA"}],"key":"mwIZk59e9t"},{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"fAe4IGvoPS"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"eT1tfKRjnO"}],"key":"qQiB3ZhuXd"}],"key":"uR5oQC8ss6"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func layernormForward(out, mean, rstd, inp, weight, bias []float32, B, T, C int) {\n\tvar eps float32 = 1e-5\n\tfor b := 0; b \u003c B; b++ {\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\tx := inp[b*T*C+t*C:]\n\t\t\t// Calculate mean\n\t\t\tvar m float32 = 0.0\n\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\tm += x[i]\n\t\t\t}\n\t\t\tm /= float32(C)\n\t\t\t// Calculate variance\n\t\t\tvar v float32 = 0.0\n\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\txshift := x[i] - m\n\t\t\t\tv += xshift * xshift\n\t\t\t}\n\t\t\tv /= float32(C)\n\t\t\t// Calculate rstd (reciprocal standard deviation)\n\t\t\ts := 1.0 / Sqrt((v)+eps)\n\t\t\t// Normalize, scale, shift, and store output\n\t\t\toutBT := out[b*T*C+t*C:]\n\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\t// subtract mean to center data\n\t\t\t\t// divide by std to scale variance\n\t\t\t\t// (val - mean) / std\n\t\t\t\tn := s * (x[i] - m)\n\t\t\t\t// Multiply the weight\n\t\t\t\to := n*weight[i] + bias[i]\n\t\t\t\toutBT[i] = o\n\t\t\t}\n\t\t\t// Store mean and rstd for backward pass\n\t\t\tmean[b*T+t] = m\n\t\t\trstd[b*T+t] = s\n\t\t}\n\t}\n}","key":"wwRZSeTlEu"},{"type":"output","id":"ozfJifEL8FjtBDdPH6q_m","data":[],"key":"WRncL4fVW8"}],"key":"Q4VRoFTo3F"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"AttentionForward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XunxHAGn7j"}],"identifier":"attentionforward","label":"AttentionForward","html_id":"attentionforward","implicit":true,"key":"ksnCRhYEDb"},{"type":"image","url":"/build/attention-8549d71863b9608e2d90d8942b571ddd.svg","alt":"attention","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"V0inJS6GcD","urlSource":"attention.svg"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"attentionForward performs the attention forward pass.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ktA4KgCkxC"}],"key":"kgtG0elB1F"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"attention is the only layer that mixes information across time\nevery other operation is applied at every (b,t) position independently\n(and of course, no layer mixes information across batch)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ZUonDHhPfr"}],"key":"kasQUpQ7FY"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Parameters:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"p4hx3P8xWL"}],"key":"OC6BWHY46n"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":12,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"out: output matrix (B,T,C)","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"HLoiupToPG"}],"key":"qUfypu6MUb"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"preatt: pre-attention scores (B,NH,T,T)","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"WudwdQwPJU"}],"key":"qQlTZT7iiJ"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"att: post-attention scores (B,NH,T,T)","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"AES65zuiFU"}],"key":"P7Q92UiHAH"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"inp: input matrix (B,T,3C) holding Query, Key, Value vectors","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"ZtopOv1RCR"}],"key":"ZcxYIyQrLf"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"B: batch size","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"odPJzMzN8c"}],"key":"QbBf0f19Sp"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"T: sequence length (number of time steps)","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"yfEfQ5VKan"}],"key":"OnfsY5sVxQ"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"C: input dimension (number of features)","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"VPFayOp5vI"}],"key":"mPbTGZPbvr"},{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"NH: number of attention heads","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"TF15U9FyVE"}],"key":"rHUJ6YrSMG"}],"key":"Achmjr53co"},{"type":"heading","depth":4,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Papers","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"qxsnN09bRk"}],"identifier":"papers","label":"Papers","html_id":"papers-2","implicit":true,"key":"TGlrTNF9le"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":23,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":23,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1706.03762v7","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"strong","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"Attention Is All You Need","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"o2z830p9TO"}],"key":"Upj8ZPdDni"}],"urlSource":"https://arxiv.org/abs/1706.03762v7","key":"bDfvKxMrAf"},{"type":"text","value":" - The attention mechanism was introduced in the original transformer paper.","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"ze26P04j2p"}],"key":"zTDQ0zSLJC"}],"key":"tWT9qgIU03"},{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"EAIimIN4Pt"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"gtq5FQYCx8"}],"key":"afeJEDc9Xh"}],"key":"ionz2tmG9M"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func attentionForward(out, preatt, att, inp []float32, B, T, C, NH int) {\n\tC3 := C * 3  // This is the dimensions for the key, query and values\n\ths := C / NH // head size\n\tscale := 1.0 / Sqrt(float32(hs))\n\t// Iterate over batch, sequence length, and number of heads\n\tvar wg sync.WaitGroup\n\tfor b := 0; b \u003c B; b++ {\n\t\t// Sequence length\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\tfor h := 0; h \u003c NH; h++ {\n\t\t\t\twg.Add(1)\n\t\t\t\tgo func(b, t, h int) {\n\t\t\t\t\tdefer wg.Done()\n\t\t\t\t\t// Calculate indices for query, pre-attention, and attention arrays\n\t\t\t\t\t// query is any particular input asking for information from other inputs\n\t\t\t\t\tqueryT := inp[b*T*C3+t*C3+h*hs:] // inp[B][T][C3]\n\t\t\t\t\tpreattBth := preatt[b*NH*T*T+h*T*T+t*T:]\n\t\t\t\t\tattBth := att[b*NH*T*T+h*T*T+t*T:]\n\t\t\t\t\t// Pass 1: Calculate query dot key and max value\n\t\t\t\t\t// The dot product is described in the paper as being better because\n\t\t\t\t\t// it can be optimized with matrix multiplication\n\t\t\t\t\tvar maxval float32 = -10000.0\n\t\t\t\t\t// range from 0 to the current inp\n\t\t\t\t\tfor t2 := 0; t2 \u003c= t; t2++ {\n\t\t\t\t\t\t// Calculate key index for t2\n\t\t\t\t\t\tkey_t2 := inp[b*T*C3+t2*C3+h*hs+C:] // +C because it's key\n\t\t\t\t\t\t// Compute dot product and update max value\n\t\t\t\t\t\tvar val float32\n\t\t\t\t\t\tfor i := 0; i \u003c hs; i++ {\n\t\t\t\t\t\t\tval += queryT[i] * key_t2[i]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tval *= scale\n\t\t\t\t\t\tif val \u003e maxval {\n\t\t\t\t\t\t\tmaxval = val\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// preatt[b][h][t1][t2] == dot product (similarity) between query vector at position t1 and\n\t\t\t\t\t\t// key vector at t2.\n\t\t\t\t\t\tpreattBth[t2] = val\n\t\t\t\t\t}\n\t\t\t\t\t// Pass 2: Calculate the exp and keep track of sum\n\t\t\t\t\t// Calculate exponential sum and update preatt and att arrays\n\t\t\t\t\t// maps the max value to zero,\n\t\t\t\t\t// and everything else negative.\n\t\t\t\t\t// when the exp function is called then the range of numbers will be\n\t\t\t\t\t// between 0 and e.\n\t\t\t\t\tvar expsum float32\n\t\t\t\t\tfor t2 := 0; t2 \u003c= t; t2++ {\n\t\t\t\t\t\texpv := Exp((preattBth[t2]) - maxval)\n\t\t\t\t\t\t// expsum is a sum of all the exp'd pre_att values\n\t\t\t\t\t\texpsum += expv\n\t\t\t\t\t\t// att_bth[t2] is the exp'd preatt_bth[t2]\n\t\t\t\t\t\tattBth[t2] = expv\n\t\t\t\t\t}\n\t\t\t\t\tvar expsum_inv float32\n\t\t\t\t\tif expsum != 0.0 {\n\t\t\t\t\t\texpsum_inv = 1.0 / expsum\n\t\t\t\t\t}\n\t\t\t\t\t// Pass 3: Normalize to get softmax\n\t\t\t\t\t// from 0 -\u003e t2: att_bth[t2] = exp(preatt[t2]) / sum(exp(preatt[:]))\n\t\t\t\t\t// for everything else it's zero\n\t\t\t\t\tfor t2 := 0; t2 \u003c T; t2++ {\n\t\t\t\t\t\tif t2 \u003c= t {\n\t\t\t\t\t\t\tattBth[t2] *= expsum_inv\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t// Causal attention mask (optional; used for debugging and comparison)\n\t\t\t\t\t\t\tattBth[t2] = 0.0\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Pass 4: Accumulate weighted values into the output of attention\n\t\t\t\t\t// out = attention * values\n\t\t\t\t\t// The values in this instance are the initial token/position embeddings that have gone through many linear\n\t\t\t\t\t// transformations at this point.\n\t\t\t\t\t// This is simply applying the learned attention \"weights\" to the lkqv values.\n\t\t\t\t\t// These weights must change a whole bunch after back propagation.\n\t\t\t\t\tout_bth := out[b*T*C+t*C+h*hs:]\n\t\t\t\t\tfor i := 0; i \u003c hs; i++ {\n\t\t\t\t\t\tout_bth[i] = 0.0\n\t\t\t\t\t}\n\t\t\t\t\tfor t2 := 0; t2 \u003c= t; t2++ {\n\t\t\t\t\t\tvalue_t2 := inp[b*T*C3+t2*C3+h*hs+C*2:] // +C*2 because it's value\n\t\t\t\t\t\tatt_btht2 := attBth[t2]\n\t\t\t\t\t\tfor i := 0; i \u003c hs; i++ {\n\t\t\t\t\t\t\tout_bth[i] += att_btht2 * value_t2[i]\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}(b, t, h)\n\t\t\t}\n\t\t}\n\t}\n\twg.Wait()\n}","key":"FDgvwQdDcH"},{"type":"output","id":"yP_oaMNOTzaBtK7JWTuH6","data":[],"key":"men5dt0KbL"}],"key":"xoAP1IpSbq"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"%test\nfunc TestAttentionForward(t *testing.T) {\n\ttype args struct {\n\t\tinp []float32\n\t\tB   int\n\t\tT   int\n\t\tC   int\n\t\tNH  int\n\t}\n\ttests := []struct {\n\t\tname       string\n\t\targs       args\n\t\twantOut    []float32\n\t\twantPreatt []float32\n\t\twantAtt    []float32\n\t}{\n\t\t{\n\t\t\tname: \"Small Input Test\",\n\t\t\targs: args{\n\t\t\t\tinp: []float32{1, 2, 3, 4, 5, 6},\n\t\t\t\tB:   1,\n\t\t\t\tT:   1,\n\t\t\t\tC:   2,\n\t\t\t\tNH:  1,\n\t\t\t},\n\t\t\twantOut:    []float32{5, 6},\n\t\t\twantPreatt: []float32{7.7781744},\n\t\t\twantAtt:    []float32{1},\n\t\t},\n\t\t{\n\t\t\tname: \"Larger Input Test\",\n\t\t\targs: args{\n\t\t\t\tinp: []float32{ // (B, T, C3)\n\t\t\t\t\t/* B = 1 */\n\t\t\t\t\t/* T =  0 */\n\t\t\t\t\t/*qry*/ 1, 2, 3, // query compared against (4, 5, 6) but not (13, 14, 15) because it's in the future (t=1)\n\t\t\t\t\t/*key*/ 4, 5, 6,\n\t\t\t\t\t/*val*/ 7, 8, 9,\n\t\t\t\t\t/* T =  1 */\n\t\t\t\t\t/*qry*/ 10, 11, 12, // will be compared against (4, 5, 6) (t-1) and (13, 14, 15)\n\t\t\t\t\t/*key*/ 13, 14, 15,\n\t\t\t\t\t/*val*/ 16, 17, 18, // vals are updated to\n\t\t\t\t},\n\t\t\t\tB:  1,\n\t\t\t\tT:  2,\n\t\t\t\tC:  3,\n\t\t\t\tNH: 1,\n\t\t\t},\n\t\t\twantOut: []float32{ // (B, T, C)\n\t\t\t\t/*      B = 0       */\n\t\t\t\t/*      T = 0       */\n\t\t\t\t/* C =  0    1    2 */\n\t\t\t\t/*  */ 7, 8, 9,\n\t\t\t\t/* T = 1 */\n\t\t\t\t/* C =  0    1    2 */\n\t\t\t\t/*  */ 16, 17, 18,\n\t\t\t},\n\t\t\twantPreatt: []float32{ // (B, NH, T, T)\n\t\t\t\t/* B =  0    */\n\t\t\t\t/* NH = 0    */\n\t\t\t\t/*T =   1  2 */\n\t\t\t\t/*T=1*/ 18.475208, 0, // preatt: 18 -\u003e 1, 0 -\u003e 0\n\t\t\t\t/*T=2*/ 96.417496, 267.89053, // 96 -\u003e 9, 267 -\u003e 1\n\t\t\t},\n\t\t\twantAtt: []float32{ // (B, NH, T, T)\n\t\t\t\t/* B = 0     */\n\t\t\t\t/* NH = 0    */\n\t\t\t\t/*T =   1  2 */\n\t\t\t\t/*T=1*/ 1, 0,\n\t\t\t\t/*T=2*/ 0, 1,\n\t\t\t},\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tout, preatt, att := make([]float32, len(tt.wantOut)), make([]float32, len(tt.wantPreatt)), make([]float32, len(tt.wantAtt))\n\t\t\tattentionForward(out, preatt, att, tt.args.inp, tt.args.B, tt.args.T, tt.args.C, tt.args.NH)\n\t\t\tassert.InDeltaSlice(t, tt.wantOut, out, 1e-4, fmt.Sprintf(\"want: %v got: %v\", tt.wantOut, out))\n\t\t\tassert.InDeltaSlice(t, tt.wantPreatt, preatt, 1e-4, fmt.Sprintf(\"want: %v got: %v\", tt.wantPreatt, preatt))\n\t\t\tassert.InDeltaSlice(t, tt.wantAtt, att, 1e-4, fmt.Sprintf(\"want: %v got: %v\", tt.wantAtt, att))\n\t\t})\n\t}\n}\n","key":"qUbkvdSaRB"},{"type":"output","id":"lIYO-g3S6etjMYIVb4NqF","data":[{"name":"stdout","output_type":"stream","text":"=== RUN   TestAttentionForward\n=== RUN   TestAttentionForward/Small_Input_Test\n=== RUN   TestAttentionForward/Larger_Input_Test\n--- PASS: TestAttentionForward (0.00s)\n    --- PASS: TestAttentionForward/Small_Input_Test (0.00s)\n    --- PASS: TestAttentionForward/Larger_Input_Test (0.00s)\nPASS\n"}],"key":"mAIpJVjZiA"}],"key":"VJ5QZDe65d"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Residual forward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ch2krry2Po"}],"identifier":"residual-forward","label":"Residual forward","html_id":"residual-forward","implicit":true,"key":"lUzmgAcuIL"},{"type":"image","url":"/build/residual-f4c8ca201cf38843afcbd05e356dbb20.svg","alt":"residual","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"YewX2rSkVF","urlSource":"residual.svg"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"residualForward implements a simple residual connection, a common technique used in deep neural networks to improve training and performance.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"mVcuEfAcm6"}],"key":"xuww4VL5Ik"},{"type":"heading","depth":4,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Papers","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"b5rbCdjBcP"}],"identifier":"papers","label":"Papers","html_id":"papers-3","implicit":true,"key":"c4qIWDuO7N"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/pdf/1512.03385","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Deep Residual Learning for Image Recognition","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"hyARYt9xT4"}],"key":"ZQpmMHFYjr"}],"urlSource":"https://arxiv.org/pdf/1512.03385","key":"b2ndbu1Il3"},{"type":"text","value":" - The introduction of residuals allowed for deeper networks. Before this paper the depth of a neural network was limited because it would diverge enough and back propagation was really, really difficult to do because of vanishing gradients. Residuals essentially have a “short circuit” past a block which limits how much the neural networks can influence.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"gNEE5JnjmE"}],"key":"QfGbOfktnY"}],"key":"odU38E8y6Q"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"PNo4yVpTWG"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"QhCsjls7ya"}],"key":"cA9cIQ7oEh"}],"key":"LNlBq0lRJf"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func residualForward(out, inp1, inp2 []float32, N int) {\n\tfor i := 0; i \u003c N; i++ {\n\t\tout[i] = inp1[i] + inp2[i]\n\t}\n}","key":"cdokChwKcs"},{"type":"output","id":"2Amsrj0ilye91KP2pNQsL","data":[],"key":"eG5jJGiXkv"}],"key":"RSLckvjfJx"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"geluForward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"b3H9ah0YkG"}],"identifier":"geluforward","label":"geluForward","html_id":"geluforward","implicit":true,"key":"tF8NZLPMVc"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The geluForward function applies the GELU activation to the input values stored in the inp slice and writes the activated values to the out slice.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"O3azjpkM9p"}],"key":"qU79Hjfqk1"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"geluForward is the Gaussian Error Linear Units activation function.\nIt leaves positive values mostly unchanged but\nmaps negative value close to zero.\nThis introduces “non-linearity” to the neural network and allows for the model to fit to functions that aren’t just linear regressions.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"OpZLUydvTN"}],"key":"hmyOZbfTpQ"},{"type":"heading","depth":4,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Papers","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"YzCKJHe3Rh"}],"identifier":"papers","label":"Papers","html_id":"papers-4","implicit":true,"key":"GX6VgSUMvi"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1606.08415v5","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Gaussian Error Linear Units (GELUs)","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"xmja7RABYm"}],"key":"Yzkm6n5eWZ"}],"urlSource":"https://arxiv.org/abs/1606.08415v5","key":"kQDwrS6w79"},{"type":"text","value":" - Activation function that leaves positive values unchanged but maps negative numbers to near zero. Other architectures use different activation functions. For example, OpenElm uses SwiGLU.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Vs04A8TnPQ"}],"key":"DznkR6ZmDp"}],"key":"JTlQPEOgwP"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"EYGjPztuNz"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"RAGtasPdlz"}],"key":"ULJaUiujWs"}],"key":"tsFfHfOw3T"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"var GELUSCALEFACTOR = Sqrt(2.0 / math.Pi)\nfunc geluForward(out, inp []float32, n int) {\n\tfor i := 0; i \u003c n; i++ {\n\t\tx := inp[i]\n\t\tcube := 0.044715 * x * x * x\n\t\tout[i] = 0.5 * x * (1.0 + Tanh(GELUSCALEFACTOR*(x+cube)))\n\t}\n}","key":"j9yxvMFC1K"},{"type":"output","id":"kCOczTi49L1lyyQOp2cei","data":[],"key":"g7YQb86A6c"}],"key":"OgjAHN1aeK"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Softmax","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zJED8aO0Ec"}],"identifier":"softmax","label":"Softmax","html_id":"softmax","implicit":true,"key":"hnV8racmMw"}],"key":"JxBvEsx5ua"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"softmaxForward calculates the softmax probabilities for a batch of input logits, converting them into a probability distribution over multiple classes. It’s a common operation in neural networks, especially for classification tasks.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Kan3Ji7dZ8"}],"key":"FnyJwizcRV"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AJ5PMSuhEG"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"mFwlOMdVaw"}],"key":"LXsVcaYeZV"}],"key":"bEIlcyrZCU"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func softmaxForward(probs, logits []float32, B, T, V int) {\n\tvar wg sync.WaitGroup\n\tfor b := 0; b \u003c B; b++ {\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\twg.Add(1)\n\t\t\tgo func(b, t int) {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tbaseIndex := b*T*V + t*V\n\t\t\t\tlogitsBT := logits[baseIndex : baseIndex+V]\n\t\t\t\tprobsBT := probs[baseIndex : baseIndex+V]\n\t\t\t\t// Numerical Stability\n\t\t\t\tvar maxval float32 = -10000.0\n\t\t\t\tfor i := 0; i \u003c V; i++ {\n\t\t\t\t\tif logitsBT[i] \u003e maxval {\n\t\t\t\t\t\tmaxval = logitsBT[i]\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Calculate exponentials and sum\n\t\t\t\tvar sum float32\n\t\t\t\tfor i := 0; i \u003c V; i++ {\n\t\t\t\t\tprobsBT[i] = Exp((logitsBT[i] - maxval))\n\t\t\t\t\tsum += probsBT[i] // Using float32 for potential precision gain\n\t\t\t\t}\n\t\t\t\t// Normalize\n\t\t\t\tfor i := 0; i \u003c V; i++ {\n\t\t\t\t\tprobsBT[i] /= sum\n\t\t\t\t}\n\t\t\t}(b, t)\n\t\t}\n\t}\n\twg.Wait()\n}","key":"FJw2XUevms"},{"type":"output","id":"OJhqPi4iBJblLrTuri-AH","data":[],"key":"ji1rlaGVsi"}],"key":"LM9M8M1FwB"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"CrossEntropyForward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"T6SMcp2jaA"}],"identifier":"crossentropyforward","label":"CrossEntropyForward","html_id":"crossentropyforward","implicit":true,"key":"aSrq4DpNrJ"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The function crossEntropyForward calculates the cross-entropy loss for a batch of predicted probability distributions and their corresponding target labels.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"EmJiib1AGm"}],"key":"wr5K3jiR5j"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"Ld7qJqikuv"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"M6SrWwCWe8"}],"key":"MwYNPE6QVA"}],"key":"x7mwEWxaTm"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"// crossEntropyForward\nfunc crossEntropyForward(losses []float32, probs []float32, targets []int32, B, T, V int) {\n\t// Iterate over each batch\n\tfor b := 0; b \u003c B; b++ {\n\t\t// Iterate over each time step in the sequence\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\t// Calculate the index in the probability slice\n\t\t\tstartIndex := int32(b*T*V + t*V)\n\t\t\t// Get the correct index in the logits for the current batch and time step\n\t\t\tix := targets[b*T+t]\n\t\t\t// Calculate the cross-entropy loss\n\t\t\tprob := probs[startIndex+ix]\n\t\t\t// Calculate the negative log of the probability for the correct target index\n\t\t\tlosses[b*T+t] = -Log((prob))\n\t\t}\n\t}\n}\n","key":"ZWUIfMpPR4"},{"type":"output","id":"PGrJqko2tW5D-JZ-Kxv9J","data":[],"key":"BlblDIYqo7"}],"key":"s6a8EnrY5x"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Putting it all together","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"m6cyUqbuAr"}],"identifier":"putting-it-all-together","label":"Putting it all together","html_id":"putting-it-all-together","implicit":true,"key":"Zho2XzoDUw"}],"key":"zCxC1EBwBi"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"type GPT2Config struct {\n\tMaxSeqLen int `json:\"max_seq_len\"`\n\tV         int `json:\"vocab_size\"`\n\tL         int `json:\"num_layers\"`\n\tNH        int `json:\"num_heads\"`\n\tC         int `json:\"channels\"`\n\tEOT       int32\n}\n\n\ntype GPT2 struct {\n\tTokenizer Tokenizer\n\tConfig    GPT2Config // Hyper-parameters of the model\n\t// Params has the actual weights of the model. Params.Memory is for convenience to be able to set/reset parameters simply\n\tParams ParameterTensors // Weights of the model\n\t// Grads contains the delta/gradient that will eventually be applied to the params in the model\n\tGrads ParameterTensors // Gradients of the weights\n\t// Fields for AdamW optimizer\n\tMMemory []float32         // First moment estimates (for AdamW)\n\tVMemory []float32         // Second moment estimates (for AdamW)\n\tActs    ActivationTensors // Activations of the model\n\t// gradients of the activations\n\tGradsActs ActivationTensors\n\tB         int     // Current batch size (B)\n\tT         int     // Current sequence length (T)\n\tInputs    []int32 // Input tokens\n\tTargets   []int32 // Target tokens\n\tMeanLoss  float32 // Mean loss after a forward pass\n\tRand      *rand.Rand\n}\n\n\nfunc loadFromReader(f io.Reader) (*GPT2, error) {\n\theader := make([]int32, 256)\n\terr := binary.Read(f, binary.LittleEndian, header)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error reading model header: %v\", err)\n\t}\n\tif header[0] != 20240326 || header[1] != 1 {\n\t\treturn nil, fmt.Errorf(\"bad model file format\")\n\t}\n\tmodel := \u0026GPT2{\n\t\tConfig: GPT2Config{\n\t\t\tMaxSeqLen: int(header[2]),\n\t\t\tV:         int(header[3]),\n\t\t\tL:         int(header[4]),\n\t\t\tNH:        int(header[5]),\n\t\t\tC:         int(header[6]),\n\t\t\tEOT:       GPT2_EOT,\n\t\t},\n\t\tRand: rand.New(rand.NewSource(21)),\n\t}\n\tmodel.Params.Init(model.Config.V, model.Config.C, model.Config.MaxSeqLen, model.Config.L)\n\tif err := binary.Read(f, binary.LittleEndian, model.Params.Memory); err != nil {\n\t\treturn nil, fmt.Errorf(\"error reading model: %v\", err)\n\t}\n\treturn model, nil\n}\n// LoadGPT2Model loads the GPT-2 model from a checkpoint file.\nfunc LoadGPT2Model(checkpointPath, tokenizerFile string) (*GPT2, error) {\n\t// File Reading\n\tf, err := os.Open(checkpointPath)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error opening model file: %v\", err)\n\t}\n\tdefer f.Close()\n\t// Read Model Header\n\tmodel, err := loadFromReader(f)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif tokenizerFile == \"\" {\n\t\treturn model, err\n\t}\n\ttok, err := NewTokenizer(tokenizerFile)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmodel.Tokenizer = tok\n\treturn model, nil\n}","key":"cH3uEY5Laq"},{"type":"output","id":"6XhtS7FGfUhMUeyjj0xWX","data":[],"key":"fX2pLi4obV"}],"key":"zecfmgu8Ta"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Forward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IxNoCSTcCn"}],"identifier":"forward","label":"Forward","html_id":"forward","implicit":true,"key":"LyJDgR4kys"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The function Forward implements the forward pass of a GPT-2 language model. It takes a sequence of input tokens and a sequence of target tokens (if available) as input, and it calculates the model’s output probabilities for the next token in the sequence.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"A2rtiZVbAP"}],"key":"hBO1iLZ7KQ"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"DMZu9nprjx"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"lLshOACElT"}],"key":"WY3fkju3yr"}],"key":"aGpEGLkc2i"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func (model *GPT2) Forward(input, target []int32, B, T int) {\n\tV, L, NH, C := model.Config.V, model.Config.L, model.Config.NH, model.Config.C\n\tif model.Acts.Memory == nil {\n\t\tmodel.B, model.T = B, T\n\t\tmodel.Acts.Init(B, C, T, L, NH, V)\n\t\tmodel.Inputs = make([]int32, B*T)\n\t\tmodel.Targets = make([]int32, B*T)\n\t}\n\tcopy(model.Inputs, input)\n\tcopy(model.Targets, target)\n\tparams, acts := model.Params, model.Acts\n\t// This encodes the word token embeddings with the positional embeddings\n\t// so that those vectors have spacial information and aren't just purely made up of the\n\t// token embeddings. The result of this is stored in acts.Encoded.\n\t// Input is a slice of ids/tokens that correspond to the vectors in WTE and their index is the \"position\"\n\tencoderForward(acts.Encoded.data, input, params.WordTokEmbed.data, params.WordPosEmbed.data, B, T, C)\n\tvar residual []float32\n\tfor l := 0; l \u003c L; l++ {\n\t\t// residual is a connection between the last layers output, or the initial token/pos embedding (as applied above)\n\t\tif l == 0 {\n\t\t\tresidual = acts.Encoded.data\n\t\t} else {\n\t\t\tresidual = acts.Residual3.data[(l-1)*B*T*C:]\n\t\t}\n\t\t// Parameters\n\t\tl_ln1w := params.LayerNorm1W.data[l*C:]\n\t\tl_ln1b := params.LayerNorm1B.data[l*C:]\n\t\tl_qkvw := params.QueryKeyValW.data[l*3*C*C:]\n\t\tl_qkvb := params.QueryKeyValB.data[l*3*C:]\n\t\tl_attprojw := params.AttProjW.data[l*C*C:]\n\t\tl_attprojb := params.AttProjB.data[l*C:]\n\t\tl_ln2w := params.Layer2NormW.data[l*C:]\n\t\tl_ln2b := params.Layer2NormB.data[l*C:]\n\t\tl_fcw := params.FeedFwdW.data[l*4*C*C:]\n\t\tl_fcb := params.FeedFwdB.data[l*4*C:]\n\t\tl_fcprojw := params.FeedFwdProjW.data[l*C*4*C:]\n\t\tl_fcprojb := params.FeedFwdProjB.data[l*C:]\n\t\t// Activations\n\t\tl_ln1 := acts.Layer1Act.data[l*B*T*C:]\n\t\tl_ln1_mean := acts.LayerNorm1Mean.data[l*B*T:]\n\t\tl_ln1_rstd := acts.LayerNorm1Rstd.data[l*B*T:]\n\t\tl_qkv := acts.QueryKeyVal.data[l*B*T*3*C:]\n\t\tl_atty := acts.AttentionInter.data[l*B*T*C:]\n\t\tl_preatt := acts.PreAttention.data[l*B*NH*T*T:]\n\t\tl_att := acts.Attention.data[l*B*NH*T*T:]\n\t\tl_attproj := acts.AttentionProj.data[l*B*T*C:]\n\t\tl_residual2 := acts.Residual2.data[l*B*T*C:]\n\t\tl_ln2 := acts.LayerNorm2Act.data[l*B*T*C:]\n\t\tl_ln2_mean := acts.LayerNorm2Mean.data[l*B*T:]\n\t\tl_ln2_rstd := acts.LayerNorm2Rstd.data[l*B*T:]\n\t\tl_fch := acts.FeedForward.data[l*B*T*4*C:]\n\t\tl_fch_gelu := acts.FeedForwardGelu.data[l*B*T*4*C:]\n\t\tl_fcproj := acts.FeedForwardProj.data[l*B*T*C:]\n\t\tl_residual3 := acts.Residual3.data[l*B*T*C:]\n\t\t// Here we normalise the layer so that the mean is 0 and the standard deviation is ~1.\n\t\t// residual contains the un-edited activations\n\t\tlayernormForward(l_ln1, l_ln1_mean, l_ln1_rstd, residual /*inp*/, l_ln1w /*weight*/, l_ln1b /*bias*/, B, T, C)\n\t\t/*\n\t\t\t\t\tl_qkvw = weight = Query Key Val Weights (C * 3C)\n\t\t\t\t\tl_ln1 = inp = layer activations\n\t\t\t\t\tl_qkvb = bias = Query Key Val Bias\n\t\t\t\t\tl_qkv = out = key/query/value matrix\n\t\t\t\tHere we're matrix multiplying  l_ln1(inp)*l_qkvw(weight) + l_qkvb(bias)\n\t\t\t\tThis matrix multiplication essentially gets a layer activation for the model inputs (activations) which are multiplied\n\t\t\t\tby the model weights.\n\t\t\tThis does the input \"projection\" via linear transformations via the model query/key/value weights into higher dimensionality.\n\t\t*/\n\t\tmatmulForward(l_qkv, l_ln1, l_qkvw, l_qkvb, B, T, C, 3*C)\n\t\t/*\n\t\t\tThe attention forward pass takes these query/key/value vectors, along with the model attention weights\n\t\t\tThe model pre-attention scores, after the forward pass, have the un-normalised attention scores\n\t\t\tatt has the attention acores and l_atty has the attention scores + the query/key/value scores\n\t\t\tl_qkv has the projection of the activations into a higher dimension.\n\t\t\tl_preatt: has the projection qkv vectors dot product(similarity), between an input's query and another input's key.\n\t\t\t\tThis basically goes like this:\n\t\t\t\tword a: has a query vector \"what am i looking for\"\n\t\t\t\tword b: has a query vector \"what do i need\"\n\t\t\t\tif they're similar, these vectors will be similar, therefore the scores will be high and be stored in l_preatt\n\t\t\tthe v in the qkv is the original token/position embeddings which have been through a number of linear transformations at this point.\n\t\t*/\n\t\tattentionForward(l_atty, l_preatt, l_att, l_qkv, B, T, C, NH)\n\n\t\t/*\n\t\t\tHere we do another matrix multiplication of attention weights and biases\n\t\t\tThis projects the l_atty into another dimension. These will probably also get back propagated.\n\t\t*/\n\t\tmatmulForward(l_attproj, l_atty, l_attprojw, l_attprojb, B, T, C, C)\n\t\t/*\n\t\t\tThe residual forward simply adds the attention projection and the residual layer, which is the\n\t\t\tweights(or activations?) before any of the previous transformations. This allows a stronger signal and\n\t\t\tprevents weight dropout and i think makes back propagation more efficient.\n\t\t*/\n\t\tresidualForward(l_residual2, residual, l_attproj, B*T*C)\n\t\t/*\n\t\t\tThe weights in this level are the layer 2 activations, which are multiplied with the residual through the above sections\n\t\t\tThis is normalised and everything into layernorm2\n\t\t*/\n\t\tlayernormForward(l_ln2, l_ln2_mean, l_ln2_rstd, l_residual2, l_ln2w, l_ln2b, B, T, C)\n\t\t/*\n\t\t\tFeedforward is just another layer of a multi layer perceptron to make the \"higher level\" connections.\n\t\t*/\n\t\tmatmulForward(l_fch, l_ln2, l_fcw, l_fcb, B, T, C, 4*C)\n\t\t/*\n\t\t\tThis is an acitvation function which maps large values to close to one and smaller values to zero.\n\t\t*/\n\t\tgeluForward(l_fch_gelu, l_fch, B*T*4*C)\n\t\t/*\n\t\t\tThis now squishes the last layer into a smaller dimension so it can be added to the next layer.\n\t\t*/\n\t\tmatmulForward(l_fcproj, l_fch_gelu, l_fcprojw, l_fcprojb, B, T, 4*C, C)\n\t\t/*\n\t\t\tNow we set the next residual layer as the output of this layer. This is the l_fcproj + the current layer residual\n\t\t*/\n\t\tresidualForward(l_residual3, l_residual2, l_fcproj, B*T*C)\n\t}\n\tresidual = acts.Residual3.data[(L-1)*B*T*C:]\n\n\t/*\n\t\tNow this is the last thing. We're layer norming the final layer activations so that the logits can be calculated\n\n\t*/\n\tlayernormForward(acts.LayerNormFinal.data, acts.LayerNormFinalMean.data, acts.LayerNormFinalStd.data, residual, params.LayerFinNormW.data, params.LayerFinNormB.data, B, T, C)\n\t/*\n\t\t\tMatrix multiplying the Word Token embedding gives us the logits.\n\t\tThis is calculating a weighted sum. More likely tokens will be blown up and less likely will be zero or negative.\n\t*/\n\tmatmulForward(acts.Logits.data, acts.LayerNormFinal.data, params.WordTokEmbed.data, nil, B, T, C, V)\n\t/*\n\t\tAfter all of this we can softmax the logits to get probabilities over the entire vocabulary\n\t*/\n\tsoftmaxForward(acts.Probabilities.data, acts.Logits.data, B, T, V)\n\t// also forward the cross-entropy loss function if we have the targets\n\tif len(target) \u003e 0 {\n\t\t/*\n\t\t\tThis compares the probabilities for each token and compares it to the target to calculate a loss.\n\t\t*/\n\t\tcrossEntropyForward(model.Acts.Losses.data, model.Acts.Probabilities.data, target, B, T, V)\n\t\t// for convenience also evaluate the mean loss\n\t\tvar meanLoss float32\n\t\tfor i := range model.Acts.Losses.data {\n\t\t\tmeanLoss += model.Acts.Losses.data[i]\n\t\t}\n\t\tmeanLoss /= float32(B * T)\n\t\tmodel.MeanLoss = meanLoss\n\n\t} else {\n\t\tmodel.MeanLoss = -1.0\n\t}\n}","key":"FCU3Vp3EsV"},{"type":"output","id":"Q7XQ82H3TzREe0XvOXWLE","data":[],"key":"yHqLRzXEDS"}],"key":"LqxwFIuZW0"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Sampling","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"eHI8YM3EAj"}],"identifier":"sampling","label":"Sampling","html_id":"sampling","implicit":true,"key":"LZVGlPLbVs"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The probabilities are a float array of:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gxOatde009"}],"key":"E2eln4649C"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"index/tokenid:probability","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"AxLnXaUkyI"}],"key":"amaWZ4qaNb"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"coin is a random value between 0 and 1.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"sUCg9Uup8n"}],"key":"fRUL2w0C7G"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"We start with a cumulative sum, and when it gets above our target coin, we return.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"aRGgLXDhqn"}],"key":"qdA2nNHlOm"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"This makes it that the most likely token returned is the one that has the most probability, but we still have the possibiility of choosing other ones, proportional to how likley they are.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Jq2jTESNuF"}],"key":"bm0zV1roDo"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"mDNDMfIPGV"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"bNBL7ika0T"}],"key":"ITMKkXyigq"}],"key":"AACDLDjH1I"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func sampleMult(probabilities []float32, coin float32) int {\n\tvar cdf float32\n\tfor i, prob := range probabilities {\n\t\tcdf += prob\n\t\tif coin \u003c cdf {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn len(probabilities) - 1\n}\n","key":"PK8pt70F24"},{"type":"output","id":"t67_kvt2Qm5NjzOwht6jb","data":[],"key":"uxfzk05z9p"}],"key":"fbThEoLaOb"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func (model *GPT2) Inference(input string) (string, error) {\n\tB, T, nTokens := 1, 64, 20\n\tstart := time.Now()\n\tdefer func() {\n\t\tfmt.Printf(\"inference time took: %v\\n\", time.Now().Sub(start))\n\t}()\n\ttokens, err := model.Tokenizer.Encode(input)\n\t//prompt_len := len(tokens)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\tif len(tokens) \u003c T {\n\t\tfor i := len(tokens); i \u003c= T; i++ {\n\t\t\ttokens = append(tokens, model.Config.EOT)\n\t\t}\n\t}\n\tfmt.Printf(\"input is %d tokens long\\n\", len(tokens))\n\tmodel.Forward(tokens, tokens[1:], B, T)\n\tfor t := 1; t \u003c nTokens; t++ {\n\t\t// for each t, we re-compute all activations between 0 and t\n\t\t// leaving this alone because you want separate code for inference anyway\n\t\t// the inference here is just for sanity checking purposes\n\t\tmodel.Forward(tokens, nil, B, t)\n\t\tprobabilities := model.Acts.Probabilities.data[(t-1)*model.Config.V:]\n\t\tcoin := model.Rand.Float32()\n\t\tnextToken2 := sampleMult(probabilities, coin)\n\t\ttokens[t] = rune(nextToken2)\n\t\tout, err := model.Tokenizer.Decode([]int32{tokens[t]})\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tfmt.Print(out)\n\n\t}\n\treturn model.Tokenizer.Decode(tokens)\n}","key":"W77oWpC8rn"},{"type":"output","id":"MyJy-YU6H9BtTFXGNOqb2","data":[],"key":"FhQGW30n5r"}],"key":"goFdLq7I42"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func newGPT2(MaxSeqLen, V, L, NH, C int, vocab []string) GPT2 {\n\tmodel := GPT2{\n\t\tConfig: GPT2Config{\n\t\t\tMaxSeqLen: MaxSeqLen,\n\t\t\tV:         V,\n\t\t\tL:         L,\n\t\t\tNH:        NH,\n\t\t\tC:         C,\n\t\t},\n\t\tParams:    newParameterTensors(V, C, MaxSeqLen, L),\n\t\tTokenizer: newTokenizer(vocab),\n\t\tRand:      rand.New(rand.NewSource(21)),\n\t}\n\treturn model\n}","key":"itJUfeZv8g"},{"type":"output","id":"jYhzL8HRICoxseNWzBqdM","data":[],"key":"tHEcSqlXCZ"}],"key":"KhDHkh8Qfl"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Do some inference","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tag7ideVpW"}],"identifier":"do-some-inference","label":"Do some inference","html_id":"do-some-inference","implicit":true,"key":"E1676TVQXo"}],"key":"f1dWwfr4Pd"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"%%\n\npath := \"/Users/joshcarp/Documents/the-interactive-transformer/\"\nmodel, err := LoadGPT2Model(path+\"/gpt2_124M.bin\", path+\"/gpt2_tokenizer.bin\")\nif err != nil {\n    panic(err)\n}\ngonbui.RequestInput(\"gpt2 text complete: \", false)\nreader := bufio.NewReader(os.Stdin)\ninputText, err := reader.ReadString('\\n')\nif err != nil {\n    panic(err)\n}\n_, err = model.Inference(inputText)\nif err != nil {\n    panic(err)\n}\n","key":"FmNP87n4Df"},{"type":"output","id":"zCykR9hZtQIS6z4kifGyG","data":[{"name":"stdout","output_type":"stream","text":"input is 65 tokens long\nahlvinyl.org\u003e \u003clink rel=\"stylesheet\"\u003e\u003cspan class=\"affiliate iconinference time took: 6.370601958s\n"}],"key":"BBfphk3szb"}],"key":"DgiVmNS1zS"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Backward Pass","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Qv4Kf5tBpU"}],"identifier":"backward-pass","label":"Backward Pass","html_id":"backward-pass","implicit":true,"key":"l7r4sy9Oec"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The backwards pass is where the “learning” happens. It is used to update the weights of the model.\nIf we’re using the model for inference, deploying it as a chatbot, etc, we don’t do a backwards pass.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"pDv5WWiMOm"}],"key":"LnlMEzYoLF"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The backward pass calculates the difference between the predicted tokens (before the sampling), and calculates a gradient based on the learning algorithm.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"bzP4JLBFsC"}],"key":"be4oWg40DE"},{"type":"container","kind":"figure","children":[{"type":"iframe","src":"https://www.youtube.com/embed?v=Ilg3gGewQ5U","width":"100%","key":"YF0bEzXEBk"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Backpropagation","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"Wo4rPShUhR"}],"key":"qBG1U1Doet"}],"key":"oJjxFJ51fp"}],"enumerator":"5","key":"i2RFm9Bkjv"},{"type":"heading","depth":4,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Papers","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"MwPrx640c6"}],"identifier":"papers","label":"Papers","html_id":"papers-5","implicit":true,"key":"SLImDs5rOC"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":15,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"link","url":"https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Learning representations by back-propagating errors","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"HU8l3JSpg9"}],"key":"plQRkiB8Hb"}],"urlSource":"https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf","key":"t3kVDJwEoN"},{"type":"text","value":" - Back-propagation was introduced here, couldn’t find the original paper. This was done by Hinton and co and was what lead to the AI era of the 80s.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"dIJ9KMk7OU"}],"key":"U2r81HZW9V"}],"key":"l8bo4UYVu9"},{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"PrjhWPuerm"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"NXCJ4eL8TD"}],"key":"gZolAf3jDl"}],"key":"y0BKMHGB0g"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"crossentropySoftmaxBackward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N78YcJP0fH"}],"identifier":"crossentropysoftmaxbackward","label":"crossentropySoftmaxBackward","html_id":"crossentropysoftmaxbackward","implicit":true,"key":"NQPyXoYSSp"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The function computes the gradients of the logits (dlogits) with respect to the loss, given the probabilities (probs) and target labels (targets).\nThis gradient information is used during backpropagation to update the weights and biases of the network to minimize the cross-entropy loss.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"mocdmrXmnl"}],"key":"SOGSfpr1gx"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"glK6EQsyao"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"MfmXouMA44"}],"key":"BBzAi0L1NQ"}],"key":"CAilUkJTnB"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"// crossentropySoftmaxBackward calculates the cross entropy\nfunc crossentropySoftmaxBackward(dlogits, dlosses, probs []float32, targets []int32, B, T, V int) {\n\tfor b := 0; b \u003c B; b++ {\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\tbaseIndex := b*T*V + t*V\n\t\t\tdlogitsBT := dlogits[baseIndex : baseIndex+V]\n\t\t\tprobsBT := probs[baseIndex : baseIndex+V]\n\t\t\tdloss := dlosses[b*T+t]\n\t\t\tix := targets[b*T+t]\n\t\t\tfor i := 0; i \u003c V; i++ {\n\t\t\t\tp := probsBT[i]\n\t\t\t\tvar indicator float32\n\t\t\t\tif int32(i) == ix {\n\t\t\t\t\tindicator = 1.0\n\t\t\t\t} else {\n\t\t\t\t\tindicator = 0.0\n\t\t\t\t}\n\t\t\t\tdlogitsBT[i] += (p - indicator) * dloss\n\t\t\t}\n\t\t}\n\t}\n}\n","key":"b3da7fLm1r"},{"type":"output","id":"s0Qyl_CzZao1WdNg6SHoJ","data":[],"key":"k7BWRYDNaJ"}],"key":"aU9IeWt1Cy"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"matmulBackward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"e4hsDfb7ds"}],"identifier":"matmulbackward","label":"matmulBackward","html_id":"matmulbackward","implicit":true,"key":"cirHPGEhTf"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The function computes the gradients of the inputs (dinp), weights (dweight), and biases (dbias) for a matrix multiplication operation. These gradients are necessary for adjusting the model parameters during training to minimize the error.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"yV8DVRjvj8"}],"key":"tPxsbTYeY5"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"a33HGgVjL5"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"dkpsKuqIr8"}],"key":"U2Y74Qv1jH"}],"key":"aB89w08XnW"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func matmulBackward(dinp, dweight, dbias, dout, inp, weight []float32, B, T, C, OC int) {\n\tvar wg sync.WaitGroup\n\tfor b := 0; b \u003c B; b++ {\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\twg.Add(1)\n\t\t\tgo func(b, t int) {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tdoutBt := dout[b*T*OC+t*OC:]\n\t\t\t\tdinpBt := dinp[b*T*C+t*C:]\n\t\t\t\tfor o := 0; o \u003c OC; o++ {\n\t\t\t\t\twrow := weight[o*C:]\n\t\t\t\t\td := doutBt[o]\n\t\t\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\t\t\tdinpBt[i] += wrow[i] * d\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}(b, t)\n\t\t}\n\t}\n\twg.Wait()\n\tfor o := 0; o \u003c OC; o++ {\n\t\twg.Add(1)\n\t\tgo func(o int) {\n\t\t\tdefer wg.Done()\n\t\t\tfor b := 0; b \u003c B; b++ {\n\t\t\t\tfor t := 0; t \u003c T; t++ {\n\t\t\t\t\tdoutBt := dout[b*T*OC+t*OC:]\n\t\t\t\t\tinpBt := inp[b*T*C+t*C:]\n\t\t\t\t\tdwrow := dweight[o*C:]\n\t\t\t\t\td := doutBt[o]\n\t\t\t\t\tif dbias != nil {\n\t\t\t\t\t\tdbias[o] += d\n\t\t\t\t\t}\n\t\t\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\t\t\tdwrow[i] += inpBt[i] * d\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}(o)\n\t}\n\twg.Wait()\n}","key":"ILCZxazfZn"},{"type":"output","id":"Dj-LeTxqU9VhVeBBCQfXO","data":[],"key":"bLHIddJ6zM"}],"key":"pacSKYOfnf"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"layernormBackward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"b6ulfpuc3q"}],"identifier":"layernormbackward","label":"layernormBackward","html_id":"layernormbackward","implicit":true,"key":"f41KYawx8v"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The function layernormBackward calculates the gradients for the backward pass of a Layer Normalization (LayerNorm) operation in a neural network. Here’s a breakdown of what it does:","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Xmh0Ul7GSt"}],"key":"jCAJHu2ap9"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Layer Normalization is a technique used to normalize the activations of a layer across its features, improving the training stability and performance of deep neural networks. It involves normalizing the input to have zero mean and unit variance. This function calculates the gradients needed to update the weights and biases of the LayerNorm operation during backpropagation.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"LqDpG4OnbZ"}],"key":"am4KnDcndG"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"NYFIQWeld7"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"PnnIHQcMMN"}],"key":"M9r3QexTJk"}],"key":"Q4WvrsW0KR"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func layernormBackward(dinp, dweight, dbias, dout, inp, weight, mean, rstd []float32, B, T, C int) {\n\tfor b := 0; b \u003c B; b++ {\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\tbaseIndex := b*T*C + t*C\n\t\t\tdoutBT := dout[baseIndex : baseIndex+C]\n\t\t\tinpBT := inp[baseIndex : baseIndex+C]\n\t\t\tdinpBT := dinp[baseIndex : baseIndex+C]\n\t\t\tmeanBT := mean[b*T+t]\n\t\t\trstdBT := rstd[b*T+t]\n\n\t\t\t// Reduce operations\n\t\t\tvar dnormMean float32 = 0.0\n\t\t\tvar dnormNormMean float32 = 0.0\n\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\tnormBTI := (inpBT[i] - meanBT) * rstdBT\n\t\t\t\tdnormI := weight[i] * doutBT[i]\n\t\t\t\tdnormMean += dnormI\n\t\t\t\tdnormNormMean += dnormI * normBTI\n\t\t\t}\n\t\t\tdnormMean /= float32(C)\n\t\t\tdnormNormMean /= float32(C)\n\n\t\t\t// Accumulation loop\n\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\tnormBTI := (inpBT[i] - meanBT) * rstdBT\n\t\t\t\tdnormI := weight[i] * doutBT[i]\n\t\t\t\tdbias[i] += doutBT[i]\n\t\t\t\tdweight[i] += normBTI * doutBT[i]\n\n\t\t\t\tvar dval float32\n\t\t\t\tdval += dnormI                  // Term 1\n\t\t\t\tdval -= dnormMean               // Term 2\n\t\t\t\tdval -= normBTI * dnormNormMean // Term 3\n\t\t\t\tdval *= rstdBT                  // Final scale\n\t\t\t\tdinpBT[i] += dval\n\t\t\t}\n\t\t}\n\t}\n}\n","key":"uuw0mf7aMY"},{"type":"output","id":"d4z_JWzCf9g1hbhkgyzvK","data":[],"key":"u1xka0J4kb"}],"key":"TrCZJU0oNT"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"residualBackward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bPZuLV55Fj"}],"identifier":"residualbackward","label":"residualBackward","html_id":"residualbackward","implicit":true,"key":"pN6qE0ORDG"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The function residualBackward calculates the gradients for the backward pass of a residual connection in a neural network. Here’s a breakdown of what it does:","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"g9adm9xWMl"}],"key":"ebosU6HTIj"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"UKc4dACgg4"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"NfKBuOAj0c"}],"key":"qykz2uz4K1"}],"key":"VGXmTIcxaw"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func residualBackward(dinp1, dinp2, dout []float32, N int) {\n\tfor i := 0; i \u003c N; i++ {\n\t\tdinp1[i] += dout[i]\n\t\tdinp2[i] += dout[i]\n\t}\n}","key":"Ws8FT1BdLf"},{"type":"output","id":"6-702OlI21q5sQUrrJJEm","data":[],"key":"XB4liug2uV"}],"key":"BWbS3SlaN7"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"geluBackward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qhxuCJSHDU"}],"identifier":"gelubackward","label":"geluBackward","html_id":"gelubackward","implicit":true,"key":"Et15R6cnO0"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Computes the gradient of the Gaussian Error Linear Unit (GELU) activation function for backpropagation in a neural network.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"rS7L3xbvsj"}],"key":"AmBZ2ZZuD3"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"q2RrvJ8V6j"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"M5lpOJv20A"}],"key":"l8VO98d6eJ"}],"key":"fhoSpTSmma"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"// geluBackward computes the backward pass of the GeLU non-linearity\nfunc geluBackward(dinp, inp, dout []float32, n int) {\n\tfor i := 0; i \u003c n; i++ {\n\t\tx := inp[i]\n\t\tcube := 0.044715 * x * x * x\n\t\ttanhArg := GELUSCALEFACTOR * (x + cube)\n\t\ttanhOut := Tanh(tanhArg)\n\t\tcoshfOut := Cosh(tanhArg)\n\t\tsechOut := 1.0 / (coshfOut * coshfOut)\n\t\tlocalGrad := 0.5*(1.0+tanhOut) + x*0.5*sechOut*GELUSCALEFACTOR*(1.0+3.0*0.044715*x*x)\n\t\tdinp[i] += localGrad * dout[i]\n\t}\n}\n","key":"HVPZx2EPYy"},{"type":"output","id":"aO6VSVXiKSLP6Blf57Red","data":[],"key":"JajSE88CmS"}],"key":"W17zBcByho"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"attentionBackward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LW8KooLUN2"}],"identifier":"attentionbackward","label":"attentionBackward","html_id":"attentionbackward","implicit":true,"key":"kpDhiLgUkN"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The attentionBackward function implements the backward pass for a self-attention mechanism in a neural network. This is a crucial part of training attention-based models, like transformers. It calculates the gradients of the attention weights, queries, keys, and values with respect to the outputs of the attention layer, allowing the model to adjust its parameters to improve performance.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"woSIdBY22f"}],"key":"kDZu2wN5kg"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"tg1eqCjVKu"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"fGnkebWNNv"}],"key":"SUSxK0JaNo"}],"key":"knWoXwrJ0f"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"// attentionBackward performs the backward pass for an attention mechanism\nfunc attentionBackward(dinp, dpreatt, datt, dout, inp, att []float32, B, T, C, NH int) {\n\t// C3 is 3 times C, representing the size of Q, K, and V combined\n\tC3 := C * 3\n\t// hs is the size of each head\n\ths := C / NH\n\t// scale is the factor used in the forward pass to scale the dot product\n\tscale := 1.0 / Sqrt(float32(hs))\n\t// Iterate through batch, time, and heads\n\tfor b := 0; b \u003c B; b++ {\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\tfor h := 0; h \u003c NH; h++ {\n\t\t\t\t// Calculate the indices for the arrays in this specific iteration\n\t\t\t\tattBTH := att[b*NH*T*T+h*T*T+t*T:]\n\t\t\t\tdattBTH := datt[b*NH*T*T+h*T*T+t*T:]\n\t\t\t\tdpreattBTH := dpreatt[b*NH*T*T+h*T*T+t*T:]\n\t\t\t\tdqueryT := dinp[b*T*C3+t*C3+h*hs:]\n\t\t\t\tqueryT := inp[b*T*C3+t*C3+h*hs:]\n\t\t\t\t// Backward pass 4: value accumulation\n\t\t\t\tdoutBTH := dout[b*T*C+t*C+h*hs:]\n\t\t\t\tfor t2 := 0; t2 \u003c= t; t2++ {\n\t\t\t\t\tvalueT2 := inp[b*T*C3+t2*C3+h*hs+C*2:]\n\t\t\t\t\tdvalueT2 := dinp[b*T*C3+t2*C3+h*hs+C*2:]\n\t\t\t\t\tfor i := 0; i \u003c hs; i++ {\n\t\t\t\t\t\t// Compute gradients for attention and value accumulation\n\t\t\t\t\t\tdattBTH[t2] += valueT2[i] * doutBTH[i]\n\t\t\t\t\t\tdvalueT2[i] += attBTH[t2] * doutBTH[i]\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Backward pass 2 \u0026 3: softmax backward\n\t\t\t\t// Softmax does not require input (preatt) to backward\n\t\t\t\tfor t2 := 0; t2 \u003c= t; t2++ {\n\t\t\t\t\tfor t3 := 0; t3 \u003c= t; t3++ {\n\t\t\t\t\t\tvar indicator float32\n\t\t\t\t\t\tif t2 == t3 {\n\t\t\t\t\t\t\tindicator = 1.0\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlocalDerivative := attBTH[t2] * (indicator - attBTH[t3])\n\t\t\t\t\t\tdpreattBTH[t3] += localDerivative * dattBTH[t2]\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Backward pass 1: query @ key matmul\n\t\t\t\tfor t2 := 0; t2 \u003c= t; t2++ {\n\t\t\t\t\tkeyT2 := inp[b*T*C3+t2*C3+h*hs+C:]\n\t\t\t\t\tdkeyT2 := dinp[b*T*C3+t2*C3+h*hs+C:]\n\t\t\t\t\tfor i := 0; i \u003c hs; i++ {\n\t\t\t\t\t\t// Compute gradients for query and key\n\t\t\t\t\t\tdqueryT[i] += keyT2[i] * dpreattBTH[t2] * scale\n\t\t\t\t\t\tdkeyT2[i] += queryT[i] * dpreattBTH[t2] * scale\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n","key":"jSg82a26j3"},{"type":"output","id":"MVvBl8fieY1vEnzueY_5z","data":[],"key":"qA0cQTt6fh"}],"key":"NdV9bZt4A2"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"matmulBackward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"byAyZh2Uct"}],"identifier":"matmulbackward","label":"matmulBackward","html_id":"matmulbackward-1","implicit":true,"key":"aZhZCe3WPf"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The function computes the gradients of the inputs (dinp), weights (dweight), and biases (dbias) for a matrix multiplication operation. These gradients are necessary for adjusting the model parameters during training to minimize the error.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"mBsQC43TfC"}],"key":"ecGUm2PNxJ"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"dinp: A slice of floats representing the gradients of the outputs with respect to the inputs of the matrix multiplication. This is often calculated by the subsequent layer in the network.\ndweight: A slice of floats representing the gradients of the outputs with respect to the weights. Initially, this slice is filled with zeros.\ndbias: A slice of floats representing the gradients of the outputs with respect to the biases. Initially, this slice is filled with zeros.\ndout: A slice of floats representing the outputs of the matrix multiplication.\ninp: A slice of floats representing the inputs to the matrix multiplication.\nweight: A slice of floats representing the weights of the matrix multiplication.\nB: The batch size (number of samples).\nT: The time steps or sequence length.\nC: The number of input features.\nOC: The number of output features.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IxKhmQ7z73"}],"key":"zTGV107tip"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"Bd19tlw4ob"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"zGLLhTpqmj"}],"key":"FPa9W7YWe7"}],"key":"mv3gSWw3mk"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func matmulBackward(dinp, dweight, dbias, dout, inp, weight []float32, B, T, C, OC int) {\n\tvar wg sync.WaitGroup\n\tfor b := 0; b \u003c B; b++ {\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\twg.Add(1)\n\t\t\tgo func(b, t int) {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tdoutBt := dout[b*T*OC+t*OC:]\n\t\t\t\tdinpBt := dinp[b*T*C+t*C:]\n\t\t\t\tfor o := 0; o \u003c OC; o++ {\n\t\t\t\t\twrow := weight[o*C:]\n\t\t\t\t\td := doutBt[o]\n\t\t\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\t\t\tdinpBt[i] += wrow[i] * d\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}(b, t)\n\t\t}\n\t}\n\twg.Wait()\n\tfor o := 0; o \u003c OC; o++ {\n\t\twg.Add(1)\n\t\tgo func(o int) {\n\t\t\tdefer wg.Done()\n\t\t\tfor b := 0; b \u003c B; b++ {\n\t\t\t\tfor t := 0; t \u003c T; t++ {\n\t\t\t\t\tdoutBt := dout[b*T*OC+t*OC:]\n\t\t\t\t\tinpBt := inp[b*T*C+t*C:]\n\t\t\t\t\tdwrow := dweight[o*C:]\n\t\t\t\t\td := doutBt[o]\n\t\t\t\t\tif dbias != nil {\n\t\t\t\t\t\tdbias[o] += d\n\t\t\t\t\t}\n\t\t\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\t\t\tdwrow[i] += inpBt[i] * d\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}(o)\n\t}\n\twg.Wait()\n}\n","key":"mcm8WqfcGU"},{"type":"output","id":"0tygBnoGUTqt5Jl2MTZO7","data":[],"key":"WzhWCTprp4"}],"key":"ETjzOGO0sP"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"encoderBackward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"erhg4XdRqp"}],"identifier":"encoderbackward","label":"encoderBackward","html_id":"encoderbackward","implicit":true,"key":"aSOhJEkn3f"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"encoderBackward calculates gradients during backpropagation\nParameters:","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"UgIDG2sMLz"}],"key":"azmpEglN8K"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":4,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"dwte: gradients with respect to word embeddings (wte)","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"zgTHxFFap8"}],"key":"rZBb7VVWwL"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"dwpe: gradients with respect to positional embeddings (wpe)","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"tpLT0CVpvH"}],"key":"zu3sEMCALm"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"dout: the gradient to apply to dwte and dwpe","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"qHggTG4uPV"}],"key":"cbBddpWzj7"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"inp: input tokens (ids that refer to indexes within wte)","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"tpOKlgphGl"}],"key":"skrj9HsRYU"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"B: batch size","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"lEq361XcBN"}],"key":"ZNylY8SjoF"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"T: sequence length (number of time steps)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"a7kteMhZ4D"}],"key":"j7fWmNhNcU"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"C: embedding dimension (number of features)","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"acKukY0foG"}],"key":"iSNVWCZH81"}],"key":"S8TmL4ziGE"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"pbkO8BV6kQ"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"GFFnW9ZYUp"}],"key":"grGRGgsukF"}],"key":"XwILlN6Dyt"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"\nfunc encoderBackward(dwte, dwpe []float32, dout []float32, inp []int32, B, T, C int) {\n\t// Iterate over the batch and time steps\n\tfor b := 0; b \u003c B; b++ {\n\t\tfor t := 0; t \u003c T; t++ {\n\t\t\t// Calculate offsets for indexing\n\t\t\tdoutBTOffset := b*T*C + t*C\n\t\t\tix := inp[b*T+t]              // Get the input token id\n\t\t\tdwteIxOffset := ix * int32(C) // Calculate the offset for dwte\n\t\t\tdwpeTOffset := t * C          // Calculate the offset for dwpe\n\n\t\t\t// Iterate over the embedding dimension and apply computations\n\t\t\tfor i := 0; i \u003c C; i++ {\n\t\t\t\t// Get the gradient value from dout\n\t\t\t\td := dout[doutBTOffset+i]\n\t\t\t\t// Update the gradients for word embeddings (dwte) and positional embeddings (dwpe)\n\t\t\t\tdwte[dwteIxOffset+int32(i)] += d\n\t\t\t\tdwpe[dwpeTOffset+i] += d\n\t\t\t}\n\t\t}\n\t}\n}","key":"aK7nW0yi0y"},{"type":"output","id":"J6oTOP9VuyWF3eSJfc-w8","data":[],"key":"OvmrR58JN8"}],"key":"yKS6DbrnoP"},{"type":"block","kind":"notebook-code","data":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"\nfunc (model *GPT2) ZeroGradient() {\n\tfor i := range model.GradsActs.Memory {\n\t\tmodel.GradsActs.Memory[i] = 0.0\n\t}\n\tfor i := range model.Grads.Memory {\n\t\tmodel.Grads.Memory[i] = 0.0\n\t}\n}\n","key":"gDnMb6yizv"},{"type":"output","id":"sUTFIi6TuzhrBiTfgrv0s","data":[],"key":"zGsk54BOMQ"}],"key":"CQ9kYRhfzb"},{"type":"block","kind":"notebook-content","data":{"pycharm":{"name":"#%% md\n"}},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Optimiser","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jpBjHXTjGz"}],"identifier":"optimiser","label":"Optimiser","html_id":"optimiser","implicit":true,"key":"ArQ1I1tgfj"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The optimiser implementation keeps track of the weights that are being changed, and how fast they’re being changed.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AtMOFXRHDQ"}],"key":"LkVjHMJcZm"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Most neural network back propagation algorithms use AdamW, which is a weight-decay ontop of the Adam optimiser.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ial8qiQHN9"}],"key":"rfPgdYlnKc"},{"type":"heading","depth":4,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Papers","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"mnPbUMqqZr"}],"identifier":"papers","label":"Papers","html_id":"papers-6","implicit":true,"key":"hEmdg3LHfO"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":10,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1412.6980","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Adam: A Method for Stochastic Optimization","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"a5f9Q6PvE7"}],"key":"hbhG2AlCD7"}],"urlSource":"https://arxiv.org/abs/1412.6980","key":"ssGgiA588q"},{"type":"text","value":" - Introduced the Adam optimiser.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"XpDCX06LR9"}],"key":"kxBy7TJwf8"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1711.05101","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"DECOUPLED WEIGHT DECAY REGULARIZATION","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"hzFtejY1Vm"}],"key":"PBh5LkKOZR"}],"urlSource":"https://arxiv.org/abs/1711.05101","key":"YEGyYIuGKr"},{"type":"text","value":" - Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"waG8llhurS"}],"key":"XT5sqVTbYa"}],"key":"iDAGYcDzLT"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"wkZkovrQUx"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"Vr6eXjl4D8"}],"key":"VMl1AXghRE"}],"key":"jCvkpgxTES"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Optimiser","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l7NgxYjuQJ"}],"identifier":"optimiser","label":"Optimiser","html_id":"optimiser-1","implicit":true,"key":"sEbrOSMlHr"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The optimiser implementation keeps track of the weights that are being changed, and how fast they’re being changed.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"NfIqLffJX6"}],"key":"zGRozumnyo"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Most neural network back propagation algorithms use AdamW, which is a weight-decay ontop of the Adam optimiser.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"H59C3oXm6x"}],"key":"BF95n98AK8"},{"type":"heading","depth":4,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Papers","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"q1iFjilfJ3"}],"identifier":"papers","label":"Papers","html_id":"papers-7","implicit":true,"key":"n969eEqTgP"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":10,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1412.6980","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Adam: A Method for Stochastic Optimization","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"IA6LaJEQcF"}],"key":"Jw1vyV1eXV"}],"urlSource":"https://arxiv.org/abs/1412.6980","key":"P2FtuTys93"},{"type":"text","value":" - Introduced the Adam optimiser.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"UXvhE5q7E8"}],"key":"dZUQuKjmxR"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1711.05101","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"DECOUPLED WEIGHT DECAY REGULARIZATION","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"mOD7g3QlKw"}],"key":"GysukIRI6S"}],"urlSource":"https://arxiv.org/abs/1711.05101","key":"ZH6cKnenxX"},{"type":"text","value":" - Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"W9FO5L9dXi"}],"key":"Ctl34uE5jV"}],"key":"XSj6Y1GICR"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"crossReference","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"back to top","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"hZD6Wthi4G"}],"identifier":"introduction","label":"Introduction","kind":"heading","template":"{name}","resolved":true,"html_id":"introduction","key":"Ktpozfm6re"}],"key":"BU6aboMumh"}],"key":"Hq7rWieAs9"},{"type":"block","kind":"notebook-code","data":{"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"func (model *GPT2) Update(learningRate, beta1, beta2, eps, weightDecay float32, t int) {\n\t// Lazy memory allocation\n\tif model.MMemory == nil {\n\t\tmodel.MMemory = make([]float32, model.Params.Len())\n\t\tmodel.VMemory = make([]float32, model.Params.Len())\n\t}\n\t// Parameter updates\n\tfor i := 0; i \u003c model.Params.Len(); i++ {\n\t\tparameter := model.Params.Memory[i]\n\t\tgradient := model.Grads.Memory[i]\n\t\t// Momentum update\n\t\tm := beta1*model.MMemory[i] + (1.0-beta1)*gradient\n\t\t// RMSprop update\n\t\tv := beta2*model.VMemory[i] + (1.0-beta2)*gradient*gradient\n\t\t// Bias correction\n\t\tmHat := m / (1.0 - Pow(beta1, float32(t)))\n\t\tvHat := v / (1.0 - Pow(beta2, float32(t)))\n\t\t// Parameter update\n\t\tmodel.MMemory[i] = m\n\t\tmodel.VMemory[i] = v\n\t\tmodel.Params.Memory[i] -= learningRate * (mHat/(Sqrt(vHat)+eps) + weightDecay*parameter)\n\t}\n}\n","key":"uWVi0wfxKt"},{"type":"output","id":"ol1IzjZqbr6rF5wtRc9vO","data":[],"key":"PY3UMZQyS3"}],"key":"HJ3VzzAS4d"},{"type":"block","kind":"notebook-code","data":{"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"\nfunc (model *GPT2) Backward() error {\n\t//// double check we forwarded previously, with targets\n\tif model.MeanLoss == -1.0 {\n\t\treturn errors.New(\"error: must forward with targets before backward\")\n\t}\n\t// lazily allocate the memory for gradients of the weights and activations, if needed\n\t// convenience shortcuts\n\tB, T, V, L, NH, C := model.B, model.T, model.Config.V, model.Config.L, model.Config.NH, model.Config.C\n\tif len(model.Grads.Memory) == 0 {\n\t\tmodel.Grads.Init(V, C, model.Config.MaxSeqLen, L)\n\t\tmodel.GradsActs.Init(B, C, T, L, NH, V)\n\t\tmodel.ZeroGradient()\n\t}\n\t// backward pass\n\tparams, grads, acts, gradsActs := model.Params, model.Grads, model.Acts, model.GradsActs\n\t// we kick off the chain by filling in dlosses with 1.0f/(B*T), to get the mean loss\n\tdlossMean := 1.0 / float32(B*T)\n\tfor i := range gradsActs.Losses.data {\n\t\tgradsActs.Losses.data[i] = dlossMean\n\t}\n\tcrossentropySoftmaxBackward(gradsActs.Logits.data, gradsActs.Losses.data, acts.Probabilities.data, model.Targets, B, T, V)\n\tmatmulBackward(gradsActs.LayerNormFinal.data, grads.WordTokEmbed.data, nil, gradsActs.Logits.data, acts.LayerNormFinal.data, params.WordTokEmbed.data, B, T, C, V)\n\tresidual := acts.Residual3.data[(L-1)*B*T*C:]       // last layer's residual\n\tdresidual := gradsActs.Residual3.data[(L-1)*B*T*C:] // write to last layer's residual\n\tlayernormBackward(dresidual, grads.LayerFinNormW.data, grads.LayerFinNormB.data, gradsActs.LayerNormFinal.data, residual, params.LayerFinNormW.data, acts.LayerNormFinalMean.data, acts.LayerNormFinalStd.data, B, T, C)\n\tfor l := L - 1; l \u003e= 0; l-- {\n\t\tif l == 0 {\n\t\t\tresidual = acts.Encoded.data\n\t\t\tdresidual = gradsActs.Encoded.data\n\t\t} else {\n\t\t\tresidual = acts.Residual3.data[(l-1)*B*T*C:]\n\t\t\tdresidual = gradsActs.Residual3.data[(l-1)*B*T*C:]\n\t\t}\n\n\t\t// Assuming you have a 'params' variable of your ParameterTensors type\n\t\tl_ln1w := params.LayerNorm1W.data[l*C:]\n\t\tl_qkvw := params.QueryKeyValW.data[l*3*C*C:]\n\t\tl_attprojw := params.AttProjW.data[l*C*C:]\n\t\tl_ln2w := params.Layer2NormW.data[l*C:]\n\t\tl_fcw := params.FeedFwdW.data[l*4*C*C:]\n\t\tl_fcprojw := params.FeedFwdProjW.data[l*C*4*C:]\n\t\t// Gradients of weights\n\t\tdl_ln1w := grads.LayerNorm1W.data[l*C:]\n\t\tdl_ln1b := grads.LayerNorm1B.data[l*C:]\n\t\tdl_qkvw := grads.QueryKeyValW.data[l*3*C*C:]\n\t\tdl_qkvb := grads.QueryKeyValB.data[l*3*C:]\n\t\tdl_attprojw := grads.AttProjW.data[l*C*C:]\n\t\tdl_attprojb := grads.AttProjB.data[l*C:]\n\t\tdl_ln2w := grads.Layer2NormW.data[l*C:]\n\t\tdl_ln2b := grads.Layer2NormB.data[l*C:]\n\t\tdl_fcw := grads.FeedFwdW.data[l*4*C*C:]\n\t\tdl_fcb := grads.FeedFwdB.data[l*4*C:]\n\t\tdl_fcprojw := grads.FeedFwdProjW.data[l*C*4*C:]\n\t\tdl_fcprojb := grads.FeedFwdProjB.data[l*C:]\n\t\t// Activations\n\t\tl_ln1 := acts.Layer1Act.data[l*B*T*C:]\n\t\tl_ln1_mean := acts.LayerNorm1Mean.data[l*B*T:]\n\t\tl_ln1_rstd := acts.LayerNorm1Rstd.data[l*B*T:]\n\t\tl_qkv := acts.QueryKeyVal.data[l*B*T*3*C:]\n\t\tl_atty := acts.AttentionInter.data[l*B*T*C:]\n\t\tl_att := acts.Attention.data[l*B*NH*T*T:]\n\t\tl_residual2 := acts.Residual2.data[l*B*T*C:]\n\t\tl_ln2 := acts.LayerNorm2Act.data[l*B*T*C:]\n\t\tl_ln2_mean := acts.LayerNorm2Mean.data[l*B*T:]\n\t\tl_ln2_rstd := acts.LayerNorm2Rstd.data[l*B*T:]\n\t\tl_fch := acts.FeedForward.data[l*B*T*4*C:]\n\t\tl_fch_gelu := acts.FeedForwardGelu.data[l*B*T*4*C:]\n\n\t\tdl_ln1 := gradsActs.Layer1Act.data[l*B*T*C:]\n\t\tdl_qkv := gradsActs.QueryKeyVal.data[l*B*T*3*C:]\n\t\tdl_atty := gradsActs.AttentionInter.data[l*B*T*C:]\n\t\tdl_preatt := gradsActs.PreAttention.data[l*B*NH*T*T:]\n\t\tdl_att := gradsActs.Attention.data[l*B*NH*T*T:]\n\t\tdl_attproj := gradsActs.AttentionProj.data[l*B*T*C:]\n\t\tdl_residual2 := gradsActs.Residual2.data[l*B*T*C:]\n\t\tdl_ln2 := gradsActs.LayerNorm2Act.data[l*B*T*C:]\n\t\tdl_fch := gradsActs.FeedForward.data[l*B*T*4*C:]\n\t\tdl_fch_gelu := gradsActs.FeedForwardGelu.data[l*B*T*4*C:]\n\t\tdl_fcproj := gradsActs.FeedForwardProj.data[l*B*T*C:]\n\t\tdl_residual3 := gradsActs.Residual3.data[l*B*T*C:]\n\t\tresidualBackward(dl_residual2, dl_fcproj, dl_residual3, B*T*C)\n\t\tmatmulBackward(dl_fch_gelu, dl_fcprojw, dl_fcprojb, dl_fcproj, l_fch_gelu, l_fcprojw, B, T, 4*C, C)\n\t\tgeluBackward(dl_fch, l_fch, dl_fch_gelu, B*T*4*C)\n\t\tmatmulBackward(dl_ln2, dl_fcw, dl_fcb, dl_fch, l_ln2, l_fcw, B, T, C, 4*C)\n\t\tlayernormBackward(dl_residual2, dl_ln2w, dl_ln2b, dl_ln2, l_residual2, l_ln2w, l_ln2_mean, l_ln2_rstd, B, T, C)\n\t\tresidualBackward(dresidual, dl_attproj, dl_residual2, B*T*C)\n\t\tmatmulBackward(dl_atty, dl_attprojw, dl_attprojb, dl_attproj, l_atty, l_attprojw, B, T, C, C)\n\t\tattentionBackward(dl_qkv, dl_preatt, dl_att, dl_atty, l_qkv, l_att, B, T, C, NH)\n\t\tmatmulBackward(dl_ln1, dl_qkvw, dl_qkvb, dl_qkv, l_ln1, l_qkvw, B, T, C, 3*C)\n\t\tlayernormBackward(dresidual, dl_ln1w, dl_ln1b, dl_ln1, residual, l_ln1w, l_ln1_mean, l_ln1_rstd, B, T, C)\n\t}\n\t// Here we want to apply our gradients to our encoded data.\n\tencoderBackward(grads.WordTokEmbed.data, grads.WordPosEmbed.data, gradsActs.Encoded.data, model.Inputs, B, T, C)\n\treturn nil\n}\n","key":"NAZ2Io3PcL"},{"type":"output","id":"sU1zPSnxM87XbxS-UZhZJ","data":[],"key":"qIlIWbfniH"}],"key":"STDuxSY9hT"},{"type":"block","kind":"notebook-code","data":{"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"\nfunc (model *GPT2) Train(valDataloader, trainDataloader *DataLoader, B, T int) error {\n\tfmt.Printf(\"train dataset num_batches: %d\\n\", valDataloader.NumBatches)\n\tconst genMaxLength, valNumBatches = 20, 3\n\tfor step := 0; step \u003c= 3; step++ {\n\t\tif step%1 == 0 {\n\t\t\tvar valLoss float32\n\t\t\tvalDataloader.Reset()\n\t\t\tfor i := 0; i \u003c valNumBatches; i++ {\n\t\t\t\tinput, target, err := valDataloader.NextBatch()\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tmodel.Forward(input, target, B, T)\n\t\t\t\tvalLoss += model.MeanLoss\n\t\t\t}\n\t\t\tvalLoss /= float32(valNumBatches)\n\t\t\tfmt.Printf(\"val loss %f\\n\", valLoss)\n\t\t}\n\t\t// do a training step\n\t\tstart := time.Now()\n\t\tinput, targets, err := trainDataloader.NextBatch()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tmodel.Forward(input, targets, B, T)\n\t\tmodel.ZeroGradient()\n\t\tmodel.Backward()\n\t\tmodel.Update(1e-4, 0.9, 0.999, 1e-8, 0.0, step+1)\n\t\tfmt.Printf(\"step %d: train loss %f (took %v ms)\\n\", step, model.MeanLoss, time.Since(start))\n\t}\n\treturn nil\n}","key":"adCQQVr0Q4"},{"type":"output","id":"JtMqIvQ8RNC6sTb52GJpn","data":[],"key":"PWTScEkgi6"}],"key":"vCV5w3QIZm"},{"type":"block","kind":"notebook-code","data":{"pycharm":{"name":"#%%\n"}},"children":[{"type":"code","lang":"go","executable":true,"value":"%main\nmodel, err := LoadGPT2Model(\"./gpt2_124M.bin\", \"./gpt2_tokenizer.bin\")\nif err != nil {\n    log.Fatal(err)\n}\nB, T := 4, 64\ntrainDataloader, err := NewDataLoader(\"./TinyStories_train.bin\", B, T)\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"train dataset num_batches: %d\\n\", trainDataloader.NumBatches)\nvalDataloader, err := NewDataLoader(\"./TinyStories_val.bin\", B, T)\nif err != nil {\n    log.Fatal(err)\n}\nif err := model.Train(valDataloader, trainDataloader, B, T); err != nil {\n    log.Fatal(err)\n}","key":"dkxtB91gya"},{"type":"output","id":"enIBa3uM23ZbyF3Km3334","data":[{"name":"stderr","output_type":"stream","text":"2024/08/26 17:53:26 Error opening model file: open ./gpt2_124M.bin: no such file or directory\nexit status 1\n"}],"key":"f0XQ4ATMOH"}],"key":"S1pOe1VwMi"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"image","url":"/build/qr-code-3e8da2a510f1483b7b7296455a0de318.png","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IGt5dzCz1P","urlSource":"qr-code.png","urlOptimized":"/build/qr-code-3e8da2a510f1483b7b7296455a0de318.webp"}],"key":"URSXJZ9vbw"}],"key":"SjGB15lrCI"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"CognitionTO Community","url":"/projects/cognition-to","group":"ML Notes"},"next":{"title":"Glossary","url":"/glossary","group":"ML Notes"}}},"domain":"http://localhost:3000"},"project":{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"},{"children":[{"file":"experiments/higher-abstract-reasoning.ipynb"}],"file":"experiments/index.md","title":"Experiments"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"experiments.index","title":"Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"experiments.higher-abstract-reasoning","title":"Transformers and Higher-Order Abstract Reasoning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-A92797E9.js";
import * as route0 from "/build/root-HROFNPGU.js";
import * as route1 from "/build/routes/$-WNZNXUO2.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>