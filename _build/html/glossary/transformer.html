<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>The Transformer - ML Notes</title><meta property="og:title" content="The Transformer - ML Notes"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/build/_assets/app-H3NBUYVS.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="/myst-theme.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">ML Notes</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3iop:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">‚åò</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="ML Notes" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">ML Notes</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Projects" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/projects">Projects</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rbd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rbd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Glossary" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200 active" href="/glossary">Glossary</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rfd8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:Rfd8p:" class="pl-3 pr-[2px] collapsible-content"><a title="Dropout" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/dropout">Dropout</a><a title="Fine-Tuning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/fine-tuning">Fine-Tuning</a><a title="Pre-Training" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/pre-training">Pre-Training</a><a title="Reinforcement Learning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/reinforcement-learning">Reinforcement Learning</a><a title="Sparse/Dense Reward" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/sparsedense-reward">Sparse/Dense Reward</a><a title="The Transformer" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/glossary/transformer">The Transformer</a><a title="Dropout" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/dropout-1">Dropout</a><a title="Feed-Forward Network" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/feed-forward-network">Feed-Forward Network</a><a title="Fine-Tuning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/fine-tuning-1">Fine-Tuning</a><a title="LoRA (Low-Rank Adaptation)" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/lora">LoRA (Low-Rank Adaptation)</a><a title="Model Collapse" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/model-collapse">Model Collapse</a><a title="Poly-semanticity" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/poly-semanticity">Poly-semanticity</a><a title="Pre-Training" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/pre-training-1">Pre-Training</a><a title="RAG (Retrieval-Augmented Generation)" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/rag">RAG (Retrieval-Augmented Generation)</a><a title="Reinforcement Learning" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/reinforcement-learning-1">Reinforcement Learning</a><a title="Residual Stream" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/residual-stream">Residual Stream</a><a title="Sparse/Dense Reward" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/sparsedense-reward-1">Sparse/Dense Reward</a><a title="The Transformer" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/glossary/transformer-1">The Transformer</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Papers" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/paper-notes">Papers</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rjd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rjd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/joshcarp/ml-notes" title="GitHub Repository: joshcarp/ml-notes" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">The Transformer</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="fO8NL7PYVc" class="relative group/block article-grid subgrid-gap col-screen"><p>üì¢ TLDR: Links and notes to transformer related research papers.</p><p>Below is a list of all the important research papers to fully understand the transformer architecture as introduced in the ‚ÄúAttention is all you need‚Äù paper by Google in 2017.</p><p>This page has a collection of research papers + notes in a directed graph to indicate dependencies between the papers and is to be used as a reference page. Obviously there‚Äôs still more to add (RNNs, LSTMs, etc), and they are on my reading list and will be added in time.</p><figure></figure><h2 id="neural-networks" class="relative group"><span class="heading-text">Neural Networks</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#neural-networks" title="Link to this Section" aria-label="Link to this Section">¬∂</a></h2><p>Neural networks have been around for a while and these are core components of what allows neural networks and transformers to be effective at what they do.</p><ul><li><p><a target="_blank" href="https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf" rel="noreferrer">**Learning representations by back-propagating errors</a> -** Back-propagation was introduced here, couldn‚Äôt find the original paper. This was done by Hinton and co and was what lead to the AI era of the 80s. Before this paper Multi-layer-perceptrons (MLPs) weren‚Äôt very common because they were very, very difficult to train.</p></li><li><p><a target="_blank" href="https://arxiv.org/abs/1512.03385" rel="noreferrer">**Deep Residual Learning for Image Recognition</a>** - The introduction of residuals (also known as skip connections) allowed for deeper networks. Before this paper the depth of a neural network was limited because it would diverge enough and back propagation was really, really difficult to do because of vanishing gradients. Residuals essentially have a ‚Äúshort circuit‚Äù past a block which allows for gradients to flow backwards through back propagation to earlier components without needing to go through intermediate layers. This greatly speeds up convergence.</p></li><li><p><a target="_blank" href="https://arxiv.org/abs/1607.06450" rel="noreferrer">**Layer Normalization</a> -** Layernorm happens in each layer to make sure that the values don‚Äôt explode and is applied at each layers output activations. It makes the surface more regular so that it‚Äôs more symmetrical and easier to optimize over. This means that weight updates can take the same increment step in all directions and not need to worry about overstepping in one dimension but under-stepping in another, and the outputs of the activations will be more regular so that the inputs to the activation functions are all within the same order of magnitude - for example one input to a neuron being 0.00001 and another one being 1,000,000 would cause a lot of problems for floating point rounding and quantization, for example.</p></li><li><p><a target="_blank" href="https://arxiv.org/abs/1606.08415v5" rel="noreferrer">**Gaussian Error Linear Units (GELUs)</a> -** Activation function ****that leaves positive values unchanged but maps negative numbers to near zero. Implemented here in <a href="https://github.com/joshcarp/llm.go/blob/56de2430b95ff3f89657637a4c97794653a994ec/math.go#L414" class="italic" target="_blank" rel="noreferrer" data-state="closed">llm.go</a>. Other architectures use different activation functions. For example, OpenElm uses SwiGLU FFN which I don‚Äôt exactly understand. Should probably add that to the reading list.</p></li></ul><h2 id="optimizers" class="relative group"><span class="heading-text">Optimizers</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#optimizers" title="Link to this Section" aria-label="Link to this Section">¬∂</a></h2><p>Optimizers are the functions that control how the weights get changed during training.</p><ul><li><a target="_blank" href="https://arxiv.org/abs/1412.6980" rel="noreferrer">**Adam: A Method for Stochastic Optimization</a> -** Introduced the Adam optimiser. Weight updates are important because it causes the training to converge more quickly. Adam has two parameters for each model parameter.</li><li><a target="_blank" href="https://arxiv.org/abs/1711.05101" rel="noreferrer">**Decoupled Weight Decay Regularization</a> -** Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.</li></ul><h2 id="the-transformer" class="relative group"><span class="heading-text">The Transformer</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#the-transformer" title="Link to this Section" aria-label="Link to this Section">¬∂</a></h2><ul><li><p><a target="_blank" href="https://arxiv.org/abs/1706.03762v7" rel="noreferrer">**Attention Is All You Need</a> -** The OG introduced the idea of self-attention and the encoder/decoder architecture for language translation tasks (the encoder later got dropped because it was only used for translation). Another breakthrough from this paper was the training; ‚ÄúThe Transformer allows for significantly more parallelisation and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.‚Äù - This fact here was what let it: overtake RNNs (which weren‚Äôt parallelisable), and lead NVIDIA to be worth more than 2.7 Trillion token credits.</p></li><li><p><a target="_blank" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="noreferrer">**Improving Language Understanding by Generative Pre-Training</a> -** This paper introduced the ‚ÄúGPT‚Äù which was a breakthrough at the time. It introduced the idea of using next token prediction as a way to do self-supervised learning, which meant that we can put all of the internet into it and with a simple loss function over the vocabulary adjust the weights via back propagation.</p></li><li><p><a target="_blank" href="https://arxiv.org/pdf/1911.02150" rel="noreferrer">**Fast Transformer Decoding: One Write-Head is All
You Need</a> -** People always point to the original Attention is all you need paper or the GPT paper that introduced the <em>decoder only</em> model~~, but this one was the first one that actually used it in practice. It also has very nice implementations of a transformer in python.~~  This previous explanation was incorrect as the GPT paper was released in 2018, a full year before this paper was released. The GPT paper introduced the concept of a decoder only model, but this paper coined the term ‚Äúdecoder only‚Äù model (I think)</p></li></ul><h2 id="training" class="relative group"><span class="heading-text">Training</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#training" title="Link to this Section" aria-label="Link to this Section">¬∂</a></h2><p>These papers introduced methods to align LLMs to human preferences, and therefore allow them to be useful as chatbots/instruct models, etc.</p><ul><li><p><a target="_blank" href="https://arxiv.org/abs/1706.03741" rel="noreferrer">**Deep Reinforcement Learning from Human Preferences</a> -** Reward modelling is introduced in this paper and allows for a small amount of human time to train a model that sits in as a ‚Äúhuman proxy‚Äù. This allows for the model to train multiple orders of magnitude more human-time efficient than having a human sit there for 1,000 years judging if a simulation looks like it‚Äôs walking correctly.</p></li><li><p><a target="_blank" href="https://arxiv.org/pdf/2203.02155" rel="noreferrer">**Training language models to follow instructions with human feedback</a> -** Reinforcement learning used on language models for the first time. This is what allowed for ‚ÄúPre-Trained‚Äù (the P in GPT), to be useful for downstream tasks like being a chat-bot and other things.</p></li></ul></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/glossary/sparsedense-reward"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>Sparse/Dense Reward</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/glossary/dropout-1"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>Dropout</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-JLDGA2DL.js"/><link rel="modulepreload" href="/build/_shared/chunk-YAIQ7LUU.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-ZQWAZXET.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-IQBJE7PC.js"/><link rel="modulepreload" href="/build/_shared/chunk-5CFTM6YW.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-HROFNPGU.js"/><link rel="modulepreload" href="/build/_shared/chunk-N544LW6X.js"/><link rel="modulepreload" href="/build/routes/$-WNZNXUO2.js"/><script>window.__remixContext = {"url":"/glossary/transformer","state":{"loaderData":{"root":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-ae9bd270a9377f87335d2f3aac742ddf.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3101","MODE":"static"},"routes/$":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-ae9bd270a9377f87335d2f3aac742ddf.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"kind":"Article","sha256":"7060c0b72c0e2b4fb875edaaca56bcc97f4ec8b782c807b3bdceb78d5132309a","slug":"glossary.transformer-1","location":"/glossary/transformer.md","dependencies":[],"frontmatter":{"title":"The Transformer","content_includes_title":false,"github":"https://github.com/joshcarp/ml-notes","exports":[{"format":"md","filename":"transformer.md","url":"/build/transformer-63be44c766bab77b8ee45060a94450bc.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","children":[{"type":"text","value":"üì¢ TLDR: Links and notes to transformer related research papers.","key":"zMHZbqbDX5"}],"key":"nRK87iUdu0"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Below is a list of all the important research papers to fully understand the transformer architecture as introduced in the ‚ÄúAttention is all you need‚Äù paper by Google in 2017.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Q3hvxS4gdx"}],"key":"aemauxu70Q"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"This page has a collection of research papers + notes in a directed graph to indicate dependencies between the papers and is to be used as a reference page. Obviously there‚Äôs still more to add (RNNs, LSTMs, etc), and they are on my reading list and will be added in time.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"PY6HumD10l"}],"key":"yDWMVAXRwo"},{"type":"mermaid","value":"%%{init: {'theme': 'base', 'themeVariables': { 'nodeTextColor': '#333333', 'mainBkg': '#f0f0f0', 'lineColor': '#F8B229'}}}%%\n\ngraph TD\n\t\ttitle[Research Collections: The Transformer]\n    subgraph \"Neural Networks: Learning\"\n        A[\"\u003ca href='https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf'\u003eLearning representations by back-propagating errors\u003c/a\u003e\"]\n        B[\"\u003ca href='https://arxiv.org/abs/1512.03385'\u003eDeep Residual Learning\u003c/a\u003e\"]\n        C[\"\u003ca href='https://arxiv.org/abs/1412.6980'\u003eAdam: A Method for Stochastic Optimization\u003c/a\u003e\"]\n        D[\"\u003ca href='https://arxiv.org/abs/1711.05101'\u003eDecoupled Weight Decay Regularization\u003c/a\u003e\"]\n    end\n\n    subgraph \"Model Components\"\n        E[\"\u003ca href='https://arxiv.org/abs/1606.08415v5'\u003eGaussian Error Linear Units (GELUs)\u003c/a\u003e\"]\n        F[\"\u003ca href='https://arxiv.org/abs/1607.06450'\u003eLayer Normalization\u003c/a\u003e\"]\n    end\n\n    subgraph \"The Transformer\"\n\t\t    G[\"\u003ca href='https://arxiv.org/abs/1706.03762v7'\u003eAttention Is All You Need\u003c/a\u003e\"]\n        X[\"\u003ca href='https://arxiv.org/abs/1911.02150'\u003eFast Transformer Decoding: One Write-Head is All You Need\u003c/a\u003e\"]\n        H[\"\u003ca href='https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf'\u003eImproving Language Understanding by Generative Pre-Training\u003c/a\u003e\"]\n\n    end\n\n    subgraph \"Training LLMs\"\n\t\t\t\tI[\"\u003ca href='https://arxiv.org/abs/1706.03741'\u003eDeep reinforcement learning from human preferences\u003c/a\u003e\"]\n        J[\"\u003ca href='https://arxiv.org/abs/2203.02155'\u003eTraining language models to follow instructions with human feedback\u003c/a\u003e\"]\n    end\n\n    A --\u003e B\n    B --\u003e G\n    C --\u003e D\n    D --\u003e G\n    E --\u003e G\n    F --\u003e G\n    G --\u003e X\n    X --\u003e H\n    H --\u003e J\n    I --\u003e J","position":{"start":{"line":11,"column":1},"end":{"line":50,"column":1}},"key":"RQr5LstSZq"},{"type":"heading","depth":2,"position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"Neural Networks","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"nNz26KkeqO"}],"identifier":"neural-networks","label":"Neural Networks","html_id":"neural-networks","implicit":true,"key":"c2bwcrWfjm"},{"type":"paragraph","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"text","value":"Neural networks have been around for a while and these are core components of what allows neural networks and transformers to be effective at what they do.","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"qHagRbjEOT"}],"key":"qgRECEaV3o"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":56,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":56,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"link","url":"https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"text","value":"**Learning representations by back-propagating errors","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"x2UHD9djnx"}],"urlSource":"https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf","key":"lHu6Eq96M9"},{"type":"text","value":" -** Back-propagation was introduced here, couldn‚Äôt find the original paper. This was done by Hinton and co and was what lead to the AI era of the 80s. Before this paper Multi-layer-perceptrons (MLPs) weren‚Äôt very common because they were very, very difficult to train.","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"XI26CqKrfs"}],"key":"soLpC4CBEL"}],"key":"pdj6kbxCAl"},{"type":"listItem","spread":true,"position":{"start":{"line":58,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1512.03385","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"**Deep Residual Learning for Image Recognition","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"f3qDlHkdH4"}],"urlSource":"https://arxiv.org/abs/1512.03385","key":"xDW3ExAFDX"},{"type":"text","value":"** - The introduction of residuals (also known as skip connections) allowed for deeper networks. Before this paper the depth of a neural network was limited because it would diverge enough and back propagation was really, really difficult to do because of vanishing gradients. Residuals essentially have a ‚Äúshort circuit‚Äù past a block which allows for gradients to flow backwards through back propagation to earlier components without needing to go through intermediate layers. This greatly speeds up convergence.","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"Q7kGtEvGTC"}],"key":"I3nk4YidMp"}],"key":"Vr7Gs6vA0Y"},{"type":"listItem","spread":true,"position":{"start":{"line":60,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1607.06450","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"text","value":"**Layer Normalization","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"WE92VN1NuG"}],"urlSource":"https://arxiv.org/abs/1607.06450","key":"wmRKJuTOLE"},{"type":"text","value":" -** Layernorm happens in each layer to make sure that the values don‚Äôt explode and is applied at each layers output activations. It makes the surface more regular so that it‚Äôs more symmetrical and easier to optimize over. This means that weight updates can take the same increment step in all directions and not need to worry about overstepping in one dimension but under-stepping in another, and the outputs of the activations will be more regular so that the inputs to the activation functions are all within the same order of magnitude - for example one input to a neuron being 0.00001 and another one being 1,000,000 would cause a lot of problems for floating point rounding and quantization, for example.","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"gNPOUCFHWo"}],"key":"XYowXJaL4c"}],"key":"tK0gB6zdSI"},{"type":"listItem","spread":true,"position":{"start":{"line":62,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1606.08415v5","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"text","value":"**Gaussian Error Linear Units (GELUs)","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"VkxUDnEFtz"}],"urlSource":"https://arxiv.org/abs/1606.08415v5","key":"tGU5gEX1u4"},{"type":"text","value":" -** Activation function ****that leaves positive values unchanged but maps negative numbers to near zero. Implemented here in ","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"sIJNClkEhW"},{"type":"link","url":"https://github.com/joshcarp/llm.go/blob/56de2430b95ff3f89657637a4c97794653a994ec/math.go#L414","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"text","value":"llm.go","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"BwOgg632IE"}],"urlSource":"https://github.com/joshcarp/llm.go/blob/56de2430b95ff3f89657637a4c97794653a994ec/math.go#L414","data":{"kind":"file","org":"joshcarp","repo":"llm.go","reference":"56de2430b95ff3f89657637a4c97794653a994ec","file":"math.go","from":414,"raw":"https://raw.githubusercontent.com/joshcarp/llm.go/56de2430b95ff3f89657637a4c97794653a994ec/math.go"},"internal":false,"protocol":"github","key":"YjlnryWwqA"},{"type":"text","value":". Other architectures use different activation functions. For example, OpenElm uses SwiGLU FFN which I don‚Äôt exactly understand. Should probably add that to the reading list.","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"mKSZsVk7P5"}],"key":"yvggLi2x7S"}],"key":"YGJDP52Gdy"}],"key":"EqLUchEwbD"},{"type":"heading","depth":2,"position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"Optimizers","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"Nfa60RC4O8"}],"identifier":"optimizers","label":"Optimizers","html_id":"optimizers","implicit":true,"key":"oWIai3n9xI"},{"type":"paragraph","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"text","value":"Optimizers are the functions that control how the weights get changed during training.","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"skDE7BG2zc"}],"key":"ILcqPwa8Xu"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":68,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1412.6980","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"text","value":"**Adam: A Method for Stochastic Optimization","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"g4FPCWh3PI"}],"urlSource":"https://arxiv.org/abs/1412.6980","key":"iObizxK3Fj"},{"type":"text","value":" -** Introduced the Adam optimiser. Weight updates are important because it causes the training to converge more quickly. Adam has two parameters for each model parameter.","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"qKOVXNC0Na"}],"key":"k99zb7L2sn"},{"type":"listItem","spread":true,"position":{"start":{"line":69,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1711.05101","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"text","value":"**Decoupled Weight Decay Regularization","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"mFILnXuZeh"}],"urlSource":"https://arxiv.org/abs/1711.05101","key":"H7P6M0r801"},{"type":"text","value":" -** Introduces AdamW optimiser used in the first transformer. Adam with weight where weight increases as time goes on.","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"pWJRF1m38o"}],"key":"qhhau6n9Ww"}],"key":"EZ327iozJD"},{"type":"heading","depth":2,"position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"text","value":"The Transformer","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"tWYCEDhIfS"}],"identifier":"the-transformer","label":"The Transformer","html_id":"the-transformer","implicit":true,"key":"Fd0RwNcp6z"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":73,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":73,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1706.03762v7","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"text","value":"**Attention Is All You Need","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"qqJwcepJEj"}],"urlSource":"https://arxiv.org/abs/1706.03762v7","key":"bFUiRvikIx"},{"type":"text","value":" -** The OG introduced the idea of self-attention and the encoder/decoder architecture for language translation tasks (the encoder later got dropped because it was only used for translation). Another breakthrough from this paper was the training; ‚ÄúThe Transformer allows for significantly more parallelisation and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.‚Äù - This fact here was what let it: overtake RNNs (which weren‚Äôt parallelisable), and lead NVIDIA to be worth more than 2.7 Trillion token credits.","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"vTzxDQNnij"}],"key":"Whb61EIE5C"}],"key":"MieKtRYLEm"},{"type":"listItem","spread":true,"position":{"start":{"line":75,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"children":[{"type":"link","url":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"children":[{"type":"text","value":"**Improving Language Understanding by Generative Pre-Training","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"key":"IBr6Z1Bstf"}],"urlSource":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","key":"ZMvsMzqCpP"},{"type":"text","value":" -** This paper introduced the ‚ÄúGPT‚Äù which was a breakthrough at the time. It introduced the idea of using next token prediction as a way to do self-supervised learning, which meant that we can put all of the internet into it and with a simple loss function over the vocabulary adjust the weights via back propagation.","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"key":"uMNusSonwe"}],"key":"aVcCSRRLLk"}],"key":"wnTu7di2iW"},{"type":"listItem","spread":true,"position":{"start":{"line":77,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":77,"column":1},"end":{"line":78,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/pdf/1911.02150","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"text","value":"**Fast Transformer Decoding: One Write-Head is All\nYou Need","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"NF78LhntTl"}],"urlSource":"https://arxiv.org/pdf/1911.02150","key":"oMuA8nutWE"},{"type":"text","value":" -** People always point to the original Attention is all you need paper or the GPT paper that introduced the ","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"b2WUXTpid5"},{"type":"emphasis","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"text","value":"decoder only","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"aqxH9qJjEf"}],"key":"TCtSQ9kJVu"},{"type":"text","value":" model~~, but this one was the first one that actually used it in practice. It also has very nice implementations of a transformer in python.~~  This previous explanation was incorrect as the GPT paper was released in 2018, a full year before this paper was released. The GPT paper introduced the concept of a decoder only model, but this paper coined the term ‚Äúdecoder only‚Äù model (I think)","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"ZKXGvNkt3c"}],"key":"RjdIkQnl8c"}],"key":"hB1cP66vo9"}],"key":"NJRgmku7hT"},{"type":"heading","depth":2,"position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"children":[{"type":"text","value":"Training","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"LaV0loq0ay"}],"identifier":"training","label":"Training","html_id":"training","implicit":true,"key":"pipPzlVb4h"},{"type":"paragraph","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"text","value":"These papers introduced methods to align LLMs to human preferences, and therefore allow them to be useful as chatbots/instruct models, etc.","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"key":"BgEyFYi505"}],"key":"b7emIHOea5"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":84,"column":1},"end":{"line":86,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":84,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/abs/1706.03741","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"text","value":"**Deep Reinforcement Learning from Human Preferences","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"key":"vZjbZZNAHx"}],"urlSource":"https://arxiv.org/abs/1706.03741","key":"YYTSrhNU2U"},{"type":"text","value":" -** Reward modelling is introduced in this paper and allows for a small amount of human time to train a model that sits in as a ‚Äúhuman proxy‚Äù. This allows for the model to train multiple orders of magnitude more human-time efficient than having a human sit there for 1,000 years judging if a simulation looks like it‚Äôs walking correctly.","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"key":"m464wejvXp"}],"key":"RrnmI0Oq4z"}],"key":"bghNHXt56v"},{"type":"listItem","spread":true,"position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"children":[{"type":"link","url":"https://arxiv.org/pdf/2203.02155","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"children":[{"type":"text","value":"**Training language models to follow instructions with human feedback","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"key":"GAfY2xZ7Ap"}],"urlSource":"https://arxiv.org/pdf/2203.02155","key":"zAYTXxqNrl"},{"type":"text","value":" -** Reinforcement learning used on language models for the first time. This is what allowed for ‚ÄúPre-Trained‚Äù (the P in GPT), to be useful for downstream tasks like being a chat-bot and other things.","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"key":"Z9WQFKOC40"}],"key":"UYT9SJy4pF"}],"key":"HBVj0ggPIb"}],"key":"aiOlAzIb4n"}],"key":"fO8NL7PYVc"}],"key":"AblKGW13hC"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Sparse/Dense Reward","url":"/glossary/sparsedense-reward","group":"ML Notes"},"next":{"title":"Dropout","url":"/glossary/dropout-1","group":"ML Notes"}}},"domain":"http://localhost:3002"},"project":{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-ae9bd270a9377f87335d2f3aac742ddf.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-A92797E9.js";
import * as route0 from "/build/root-HROFNPGU.js";
import * as route1 from "/build/routes/$-WNZNXUO2.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>