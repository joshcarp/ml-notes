<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Papers - ML Notes</title><meta property="og:title" content="Papers - ML Notes"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/build/_assets/app-H3NBUYVS.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="/myst-theme.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">ML Notes</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3iop:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="ML Notes" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">ML Notes</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Projects" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/projects">Projects</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rbd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rbd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Glossary" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/glossary">Glossary</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rfd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rfd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none bg-blue-300/30"><a title="Papers" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200 active" href="/paper-notes">Papers</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rjd8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:Rjd8p:" class="pl-3 pr-[2px] collapsible-content"><a title="Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/paper-notes/perplexity-based-data-pruning">Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Experiments" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/experiments">Experiments</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rnd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rnd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/joshcarp/ml-notes" title="GitHub Repository: joshcarp/ml-notes" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Papers</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="XbKTvxoqkn" class="relative group/block article-grid subgrid-gap col-screen"><p>A collection of papers with summaries and quick access links.</p><h2 id="paper-notes" class="relative group"><span class="heading-text">Paper Notes</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#paper-notes" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><figure id="kRrmz6QPon" class="fig-table"><table><tbody><tr><th class="">Title</th><th class="">Tags</th><th class="">Full Notes</th></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2411.07191" target="_blank" rel="noreferrer" class="hover-link">The Super Weight in Large Language Models</a></cite></td><td class="">Model internals</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2410.02725" target="_blank" rel="noreferrer" class="hover-link">Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation</a></cite></td><td class=""></td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.03592" target="_blank" rel="noreferrer" class="hover-link">ReFT: Representation Finetuning for Language Models</a></cite></td><td class="">Fine-tuning, Model representations</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://doi.org/10.5555/2627435.2670313" rel="noreferrer">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></td><td class="">Model performance, Optimization, Model architecture</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.06111" target="_blank" rel="noreferrer" class="hover-link">Observation-based unit test generation at Meta</a></cite></td><td class="">Automated testing, Software engineering</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2403.20327" target="_blank" rel="noreferrer" class="hover-link">Gecko: Versatile Text Embeddings Distilled from Large Language Models</a></cite></td><td class="">Embeddings, Model distillation</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2210.07128" target="_blank" rel="noreferrer" class="hover-link">Language Models of Code are Few-Shot Commonsense Learners</a></cite></td><td class="">Code models, Transfer learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2407.10969" target="_blank" rel="noreferrer" class="hover-link">Q-Sparse: All Large Language Models can be Fully Sparsely-Activated</a></cite></td><td class="">Efficiency, Model performance</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2207.01780" target="_blank" rel="noreferrer" class="hover-link">CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning</a></cite></td><td class="">Code generation, Reinforcement learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2405.20541" target="_blank" rel="noreferrer" class="hover-link">Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</a></cite></td><td class="">Data pruning, Perplexity</td><td class=""><a href="/paper-notes/perplexity-based-data-pruning">Details</a></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.17764" target="_blank" rel="noreferrer" class="hover-link">The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits</a></cite></td><td class="">Hardware optimization, Model compression</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2305.17493" target="_blank" rel="noreferrer" class="hover-link">The Curse of Recursion: Training on Generated Data Makes Models Forget</a></cite></td><td class="">Model collapse, Training data</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html" rel="noreferrer">Chain of thought prompting</a></td><td class="">Prompting strategies</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.07143" target="_blank" rel="noreferrer" class="hover-link">Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</a></cite></td><td class="">Attention mechanisms, Context window</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.07496" target="_blank" rel="noreferrer" class="hover-link">TextGrad</a></cite></td><td class="">Agent systems, Text optimization</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.02528" target="_blank" rel="noreferrer" class="hover-link">Scalable MatMul-free Language Modeling</a></cite></td><td class="">Attention mechanisms, Model efficiency</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1712.00676" target="_blank" rel="noreferrer" class="hover-link">Will humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?</a></cite></td><td class="">AI in software development, Future of coding</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2311.17035" target="_blank" rel="noreferrer" class="hover-link">Scalable Extraction of Training Data from (Production) Language Models</a></cite></td><td class="">Data accumulation, Model performance, Curated datasets</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2305.07759" target="_blank" rel="noreferrer" class="hover-link">TinyStories: How Small Can Language Models Be and Still Speak Coherent English?</a></cite></td><td class="">Dataset creation, Small language models</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2311.12983" target="_blank" rel="noreferrer" class="hover-link">GAIA: A Benchmark for General AI Assistants</a></cite></td><td class="">AI assistants, Benchmarking</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.anthropic.com/news/mapping-mind-language-model" rel="noreferrer">Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet</a></td><td class="">Feature extraction, Interpretability</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.04692" target="_blank" rel="noreferrer" class="hover-link">Mixture-of-Agents Enhances Large Language Model Capabilities</a></cite></td><td class="">Model performance, Multi-agent systems</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2311.05884" target="_blank" rel="noreferrer" class="hover-link">Hiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems</a></cite></td><td class="">Transformers, Model architecture, Model performance</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2307.11760" target="_blank" rel="noreferrer" class="hover-link">Large Language Models Understand and Can Be Enhanced by Emotional Stimuli</a></cite></td><td class="">emotional stimuli, Model behavior</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.09171" target="_blank" rel="noreferrer" class="hover-link">Automated Unit Test Improvement using Large Language Models at Meta</a></cite></td><td class="">Automated testing, Software engineering</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.01413" target="_blank" rel="noreferrer" class="hover-link">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</a></cite></td><td class="">Data accumulation, Model collapse prevention</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2102.04518" target="_blank" rel="noreferrer" class="hover-link">A\ Search Without Expansions: Learning Heuristic Functions With Deep Q-Networks</a></cite></td><td class="">Reinforcement learning, Search algorithms</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.06196" target="_blank" rel="noreferrer" class="hover-link">Large Language Models: A Survey</a></cite></td><td class="">LLM capabilities, Survey</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.14433" target="_blank" rel="noreferrer" class="hover-link">A Language Model’s Guide Through Latent Space</a></cite></td><td class="">Interpretability, Latent space</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2205.05124" target="_blank" rel="noreferrer" class="hover-link">Extracting Latent Steering Vectors from Pretrained Language Models</a></cite></td><td class="">Interpretability, Latent space</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.anthropic.com/research/many-shot-jailbreaking" rel="noreferrer">Many-shot jailbreaking</a></td><td class="">Jailbreaking, Model safety</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1910.10683" target="_blank" rel="noreferrer" class="hover-link">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></cite></td><td class="">Transfer learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2308.10248" target="_blank" rel="noreferrer" class="hover-link">Activation Addition: Steering Language Models Without Optimization</a></cite></td><td class="">Activation manipulation, Model steering</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2107.03374" target="_blank" rel="noreferrer" class="hover-link">Evaluating Large Language Models Trained on Code</a></cite></td><td class="">Code generation, Model evaluation</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.02543" target="_blank" rel="noreferrer" class="hover-link">To Believe or Not to Believe Your LLM</a></cite></td><td class="">Hallucination detection, Uncertainty quantification</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.04692" target="_blank" rel="noreferrer" class="hover-link">Mixture of Agents</a></cite></td><td class="">Multi-agent systems, Prompting</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.14619" target="_blank" rel="noreferrer" class="hover-link">OpenELM: An Efficient Language Model Family with Open Training and Inference Framework</a></cite></td><td class="">Efficiency, Model architecture</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1706.03741" target="_blank" rel="noreferrer" class="hover-link">Deep Reinforcement Learning from Human Preferences</a></cite></td><td class="">human feedback, Reinforcement learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2307.08925" target="_blank" rel="noreferrer" class="hover-link">Federated Large Language Model: A Position Paper</a></cite></td><td class="">Distributed training, Federated learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2212.02508" target="_blank" rel="noreferrer" class="hover-link">MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning</a></cite></td><td class="">Music representation, Self-supervised learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2302.13971" target="_blank" rel="noreferrer" class="hover-link">LLaMA: Open and Efficient Foundation Language Models</a></cite></td><td class="">Model architecture, Open-source LLMs</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/" rel="noreferrer">Phi1: Textbooks Are All You Need</a></td><td class="">Curated datasets, Model efficiency</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1607.06450" target="_blank" rel="noreferrer" class="hover-link">Layer Normalization</a></cite></td><td class="">Model internals, Optimization</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1706.03762" target="_blank" rel="noreferrer" class="hover-link">Attention Is All You Need</a></cite></td><td class="">OG papers, Transformers</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.09412" target="_blank" rel="noreferrer" class="hover-link">Explore the Limits of Omni-modal Pretraining at Scale</a></cite></td><td class="">Multi-modal models, Pretraining</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1606.08415" target="_blank" rel="noreferrer" class="hover-link">Gaussian Error Linear Units (GELUs)</a></cite></td><td class="">Activation functions, Model internals</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2401.09796" target="_blank" rel="noreferrer" class="hover-link">A Fast, Performant, Secure Distributed Training Framework For Large Language Model</a></cite></td><td class="">Distributed training, Security</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1910.01108" target="_blank" rel="noreferrer" class="hover-link">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</a></cite></td><td class="">Efficiency, Model distillation</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="noreferrer">Improving Language Understanding by Generative Pre-Training</a></td><td class="">OG papers, Pre-training</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2203.02155" target="_blank" rel="noreferrer" class="hover-link">Training language models to follow instructions with human feedback</a></cite></td><td class="">Instruction following, Reinforcement learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2307.09288" target="_blank" rel="noreferrer" class="hover-link">Llama 2: Open Foundation and Fine-Tuned Chat Models</a></cite></td><td class="">Fine-tuning, Open-source LLMs</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2104.09864" target="_blank" rel="noreferrer" class="hover-link">RoFormer: Enhanced Transformer with Rotary Position Embedding</a></cite></td><td class="">Embeddings, Model architecture</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.nature.com/articles/s42256-023-00748-9" rel="noreferrer">Spatially embedded recurrent neural networks reveal widespread links between structural and functional neuroscience findings | Nature Machine Intelligence</a></td><td class="">Biological Brains</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.1111/tops.12737" target="_blank" rel="noreferrer" class="hover-link">Understanding Human Cognition Through Computational Modeling - Hsiao - 2024 - Topics in Cognitive Science - Wiley Online Library</a></cite></td><td class="">Biological Brains</td><td class=""></td></tr></tbody></table></figure></div><div></div><section id="references" class="article-grid subgrid-gap col-screen"><div><button class="float-right p-1 px-2 text-xs border rounded hover:border-blue-500 dark:hover:border-blue-400">Show All</button><header class="text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2411.07191">Yu, M., Wang, D., Shan, Q., Reed, C., & Wan, A. (2024). <i>The Super Weight in Large Language Models</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2411.07191">10.48550/ARXIV.2411.07191</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2410.02725">Manvi, R., Singh, A., & Ermon, S. (2024). <i>Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2410.02725">10.48550/ARXIV.2410.02725</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2404.03592">Wu, Z., Arora, A., Wang, Z., Geiger, A., Jurafsky, D., Manning, C. D., & Potts, C. (2024). <i>ReFT: Representation Finetuning for Language Models</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2404.03592">10.48550/ARXIV.2404.03592</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2402.06111">Alshahwan, N., Harman, M., Marginean, A., Tal, R., & Wang, E. (2024). <i>Observation-based unit test generation at Meta</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2402.06111">10.48550/ARXIV.2402.06111</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2403.20327">Lee, J., Dai, Z., Ren, X., Chen, B., Cer, D., Cole, J. R., Hui, K., Boratko, M., Kapadia, R., Ding, W., Luan, Y., Duddu, S. M. K., Abrego, G. H., Shi, W., Gupta, N., Kusupati, A., Jain, P., Jonnalagadda, S. R., Chang, M.-W., & Naim, I. (2024). <i>Gecko: Versatile Text Embeddings Distilled from Large Language Models</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2403.20327">10.48550/ARXIV.2403.20327</a></li><li class="text-center list-none"><button class="p-2 border rounded hover:border-blue-500 dark:hover:border-blue-400">Show all 46 references</button></li></ol></div></section><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/glossary/transformer-1"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>The Transformer</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/paper-notes/perplexity-based-data-pruning"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-JLDGA2DL.js"/><link rel="modulepreload" href="/build/_shared/chunk-YAIQ7LUU.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-ZQWAZXET.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-IQBJE7PC.js"/><link rel="modulepreload" href="/build/_shared/chunk-5CFTM6YW.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-HROFNPGU.js"/><link rel="modulepreload" href="/build/_shared/chunk-N544LW6X.js"/><link rel="modulepreload" href="/build/routes/$-WNZNXUO2.js"/><script>window.__remixContext = {"url":"/paper-notes","state":{"loaderData":{"root":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"},{"children":[{"file":"experiments/higher-abstract-reasoning.ipynb"}],"file":"experiments/index.md","title":"Experiments"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"experiments.index","title":"Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"experiments.higher-abstract-reasoning","title":"Transformers and Higher-Order Abstract Reasoning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"},{"children":[{"file":"experiments/higher-abstract-reasoning.ipynb"}],"file":"experiments/index.md","title":"Experiments"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"experiments.index","title":"Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"experiments.higher-abstract-reasoning","title":"Transformers and Higher-Order Abstract Reasoning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"kind":"Article","sha256":"de6f13421b9e894a3495f69d13e261da2b558605fa45aba906e17ebef11a1aea","slug":"paper-notes.index","location":"/paper-notes/index.md","dependencies":[],"frontmatter":{"title":"Papers","content_includes_title":false,"github":"https://github.com/joshcarp/ml-notes","exports":[{"format":"md","filename":"index.md","url":"/build/index-9dfa02596a7187a304c8eaa96ee86b22.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"A collection of papers with summaries and quick access links.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"yQtyAz2gY4"}],"key":"Q71PCkQmCj"},{"type":"heading","depth":2,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Paper Notes","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"EorUXR5ZoB"}],"identifier":"paper-notes","label":"Paper Notes","html_id":"paper-notes","implicit":true,"key":"RmWkdZwaaZ"},{"type":"container","kind":"table","children":[{"type":"table","children":[{"type":"tableRow","children":[{"type":"tableCell","header":true,"children":[{"type":"text","value":"Title","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"BPHUFjllww"}],"key":"ghsTyXFku6"},{"type":"tableCell","header":true,"children":[{"type":"text","value":"Tags","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"tvD0Rfeecj"}],"key":"tASRjMpQgT"},{"type":"tableCell","header":true,"children":[{"type":"text","value":"Full Notes","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"M2YZ6xadrn"}],"key":"iTEiu4Tg6p"}],"key":"AZvdFUifm7"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2411.07191","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"The Super Weight in Large Language Models","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"pO66B3CAx8"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2411.07191","identifier":"https://doi.org/10.48550/arXiv.2411.07191","enumerator":"1","key":"CRP6g18JOb"}],"key":"InmbrKk5LL"},{"type":"tableCell","children":[{"type":"text","value":"Model internals","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"I8fUYq4sUY"}],"key":"r2Z8et94SX"},{"type":"tableCell","children":[],"key":"LxKPxnOvhl"}],"key":"ngSNvBNK15"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2410.02725","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"IRbibc9KUF"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2410.02725","identifier":"https://doi.org/10.48550/arXiv.2410.02725","enumerator":"2","key":"XSAFNWfQGZ"}],"key":"nROv7RnVE0"},{"type":"tableCell","children":[],"key":"rHhMmexgHr"},{"type":"tableCell","children":[],"key":"Et0TD6ukjX"}],"key":"EBqTFrgmnR"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.03592","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"ReFT: Representation Finetuning for Language Models","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"ol5n1DX9Vl"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.03592","identifier":"https://doi.org/10.48550/arXiv.2404.03592","enumerator":"3","key":"jpJm3ohZKF"}],"key":"Fk7wkPXdSC"},{"type":"tableCell","children":[{"type":"text","value":"Fine-tuning, Model representations","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"IbU0cW6suk"}],"key":"AjiVjcgXWM"},{"type":"tableCell","children":[],"key":"zcSAgz1nPH"}],"key":"rhWKbYJjpB"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://doi.org/10.5555/2627435.2670313","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Dropout: A Simple Way to Prevent Neural Networks from Overfitting","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"hrc1viblzc"}],"urlSource":"https://dl.acm.org/doi/abs/10.5555/2627435.2670313","data":{"doi":"10.5555/2627435.2670313"},"internal":false,"protocol":"doi","key":"KB2vRpPmAM"}],"key":"bIRNYcyDv4"},{"type":"tableCell","children":[{"type":"text","value":"Model performance, Optimization, Model architecture","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"kVPEEP0hOY"}],"key":"DxyigPzbKQ"},{"type":"tableCell","children":[],"key":"ImmUsf02ck"}],"key":"CWRVvkTMHU"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.06111","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Observation-based unit test generation at Meta","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"h4Fof3Zk1V"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.06111","identifier":"https://doi.org/10.48550/arXiv.2402.06111","enumerator":"4","key":"pfLaGKo8aH"}],"key":"gAxS7yCBEY"},{"type":"tableCell","children":[{"type":"text","value":"Automated testing, Software engineering","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"vrbwjFjJ2J"}],"key":"Jsu7sLFXvU"},{"type":"tableCell","children":[],"key":"RACFmH7P4H"}],"key":"NcwzYQCyOz"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2403.20327","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"Gecko: Versatile Text Embeddings Distilled from Large Language Models","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"yK2YXLfNCr"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2403.20327","identifier":"https://doi.org/10.48550/arXiv.2403.20327","enumerator":"5","key":"zi9VIcHWtM"}],"key":"aumhkUoT4d"},{"type":"tableCell","children":[{"type":"text","value":"Embeddings, Model distillation","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"h0lfEb7kBM"}],"key":"A0TSaZEDRx"},{"type":"tableCell","children":[],"key":"SRbpxCTnt3"}],"key":"Pt7JZd1xmv"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2210.07128","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Language Models of Code are Few-Shot Commonsense Learners","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"lBywRDd94t"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2210.07128","identifier":"https://doi.org/10.48550/arXiv.2210.07128","enumerator":"6","key":"SyNxY9Goa5"}],"key":"KA58uXhvNp"},{"type":"tableCell","children":[{"type":"text","value":"Code models, Transfer learning","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"kMsrLszhgI"}],"key":"iLkvNjTnt8"},{"type":"tableCell","children":[],"key":"qEaMYhQpyB"}],"key":"ro3NIpNgbi"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2407.10969","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Q-Sparse: All Large Language Models can be Fully Sparsely-Activated","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"MGXg3Mcgoq"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2407.10969","identifier":"https://doi.org/10.48550/arXiv.2407.10969","enumerator":"7","key":"st0RNwUDRt"}],"key":"G8CqJBIgbP"},{"type":"tableCell","children":[{"type":"text","value":"Efficiency, Model performance","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"TWBwaiymLg"}],"key":"SgRcbdHGsz"},{"type":"tableCell","children":[],"key":"NfwJ7XVFap"}],"key":"ii7XmLboc6"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2207.01780","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"JKZQ9YZJSW"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2207.01780","identifier":"https://doi.org/10.48550/arXiv.2207.01780","enumerator":"8","key":"VXYCXf1WEQ"}],"key":"i86OAT1EGp"},{"type":"tableCell","children":[{"type":"text","value":"Code generation, Reinforcement learning","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"TvlyIa9fbx"}],"key":"EXy1Yc7HUs"},{"type":"tableCell","children":[],"key":"i3euPgR4Ub"}],"key":"EEZ7MvTZvj"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2405.20541","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"HNZGuxQHTu"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2405.20541","identifier":"https://doi.org/10.48550/arXiv.2405.20541","enumerator":"9","key":"rFTXCEZPp9"}],"key":"FuW8akJioL"},{"type":"tableCell","children":[{"type":"text","value":"Data pruning, Perplexity","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"iszQBRJDoa"}],"key":"j1hIg6Wa7p"},{"type":"tableCell","children":[{"type":"link","url":"/paper-notes/perplexity-based-data-pruning","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"Details","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"YZDP5zDjhB"}],"urlSource":"perplexity-based-data-pruning","dataUrl":"/paper-notes.perplexity-based-data-pruning.json","internal":true,"protocol":"file","key":"PsDQsktW06"}],"key":"oUQIzbP7x9"}],"key":"hYeR32T8q2"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.17764","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"tSJopTN4AC"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.17764","identifier":"https://doi.org/10.48550/arXiv.2402.17764","enumerator":"10","key":"dGiITO3osb"}],"key":"MLn3SHK6F5"},{"type":"tableCell","children":[{"type":"text","value":"Hardware optimization, Model compression","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"WrLH8dLkPv"}],"key":"gUyYsx6bnB"},{"type":"tableCell","children":[],"key":"ch00kswPrp"}],"key":"GVutzUKIdF"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2305.17493","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"The Curse of Recursion: Training on Generated Data Makes Models Forget","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"LZHhj8Mx4v"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2305.17493","identifier":"https://doi.org/10.48550/arXiv.2305.17493","enumerator":"11","key":"W756PWqVKx"}],"key":"OWyyZ3ZMpG"},{"type":"tableCell","children":[{"type":"text","value":"Model collapse, Training data","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"MR7t68ScXh"}],"key":"g5RjqlGarx"},{"type":"tableCell","children":[],"key":"O4qZiJRFtQ"}],"key":"rL5WebgKS6"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Chain of thought prompting","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"SWAuZHyBr1"}],"urlSource":"https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html","key":"DmOq2T2aF3"}],"key":"rpsgGEIV4i"},{"type":"tableCell","children":[{"type":"text","value":"Prompting strategies","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"NBpokSM74c"}],"key":"jJ3TAOjYlQ"},{"type":"tableCell","children":[],"key":"gtSo6MZHZ7"}],"key":"PiimZybqiT"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.07143","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"qVthnOB6XQ"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.07143","identifier":"https://doi.org/10.48550/arXiv.2404.07143","enumerator":"12","key":"va2wSHMuDs"}],"key":"Sxzzskl7tE"},{"type":"tableCell","children":[{"type":"text","value":"Attention mechanisms, Context window","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"RTr4r2eCAB"}],"key":"gGApGbQhuR"},{"type":"tableCell","children":[],"key":"yrMWQJAIoR"}],"key":"F5VcVA1PY9"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.07496","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"TextGrad","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"IKz35v4kSi"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.07496","identifier":"https://doi.org/10.48550/arXiv.2406.07496","enumerator":"13","key":"sIRAZbCXFN"}],"key":"gSdRuaNcbQ"},{"type":"tableCell","children":[{"type":"text","value":"Agent systems, Text optimization","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"pVFuBW0QkS"}],"key":"ySh3aLekxh"},{"type":"tableCell","children":[],"key":"IvbA3yIayP"}],"key":"kpeqa0PfN1"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.02528","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"Scalable MatMul-free Language Modeling","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"pWYTQLeea4"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.02528","identifier":"https://doi.org/10.48550/arXiv.2406.02528","enumerator":"14","key":"impIchf78H"}],"key":"UnxHPif3Jo"},{"type":"tableCell","children":[{"type":"text","value":"Attention mechanisms, Model efficiency","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"RvmmFgSPBP"}],"key":"WEigoqMJij"},{"type":"tableCell","children":[],"key":"GrAOpmrDbB"}],"key":"XAZ6FEWeik"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1712.00676","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"Will humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"XyiGyUzK1N"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1712.00676","identifier":"https://doi.org/10.48550/arXiv.1712.00676","enumerator":"15","key":"vXZPGu9w0S"}],"key":"ZKAl5zwVJK"},{"type":"tableCell","children":[{"type":"text","value":"AI in software development, Future of coding","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"zwtPe67S3K"}],"key":"Nfs7VPB6dA"},{"type":"tableCell","children":[],"key":"LNzKL3a6j5"}],"key":"DJWcN2SMAJ"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2311.17035","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"Scalable Extraction of Training Data from (Production) Language Models","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"RaeEHPrVvf"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2311.17035","identifier":"https://doi.org/10.48550/arXiv.2311.17035","enumerator":"16","key":"UeoEvNWhc8"}],"key":"lWobIT4pxl"},{"type":"tableCell","children":[{"type":"text","value":"Data accumulation, Model performance, Curated datasets","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"td5gh3QizI"}],"key":"cFxtZTHaRx"},{"type":"tableCell","children":[],"key":"oUYocm16wg"}],"key":"LTJh9mazR2"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2305.07759","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"TinyStories: How Small Can Language Models Be and Still Speak Coherent English?","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"ietStenMap"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2305.07759","identifier":"https://doi.org/10.48550/arXiv.2305.07759","enumerator":"17","key":"Z8vNESqnUw"}],"key":"S9wkSVgHTd"},{"type":"tableCell","children":[{"type":"text","value":"Dataset creation, Small language models","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"EpfQKbR73k"}],"key":"jJaz6rwWe3"},{"type":"tableCell","children":[],"key":"VuY9qN4FSc"}],"key":"jpPjM2azD3"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2311.12983","position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"text","value":"GAIA: A Benchmark for General AI Assistants","position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"key":"ytEHiQzoYG"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2311.12983","identifier":"https://doi.org/10.48550/arXiv.2311.12983","enumerator":"18","key":"NjZAx14kJZ"}],"key":"p0YpBjwINc"},{"type":"tableCell","children":[{"type":"text","value":"AI assistants, Benchmarking","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"gsaYVXyOoz"}],"key":"NvSP01GrML"},{"type":"tableCell","children":[],"key":"L4tpzqznZc"}],"key":"X7CdYH3dbA"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.anthropic.com/news/mapping-mind-language-model","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"text","value":"Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"ZpTzdja5j4"}],"urlSource":"https://www.anthropic.com/news/mapping-mind-language-model","key":"NUKljlvnT5"}],"key":"bp6b1YBSad"},{"type":"tableCell","children":[{"type":"text","value":"Feature extraction, Interpretability","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"ZkfbHJfCuT"}],"key":"tb2Q2cUK5l"},{"type":"tableCell","children":[],"key":"urwmZxVfGF"}],"key":"q8IJ52jHlH"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.04692","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"Mixture-of-Agents Enhances Large Language Model Capabilities","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"w2GVAV6INa"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.04692","identifier":"https://doi.org/10.48550/arXiv.2406.04692","enumerator":"19","key":"IlMFtq3w47"}],"key":"WWZQYzAPOZ"},{"type":"tableCell","children":[{"type":"text","value":"Model performance, Multi-agent systems","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"qXZX3nqj0s"}],"key":"wbTGdCGVAU"},{"type":"tableCell","children":[],"key":"zJhbp95ub7"}],"key":"X9aiaD8rqL"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2311.05884","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"text","value":"Hiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"key":"Hc0kNjqGQM"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2311.05884","identifier":"https://doi.org/10.48550/arXiv.2311.05884","enumerator":"20","key":"YSqiZCZQrZ"}],"key":"q1ZPlBZlA8"},{"type":"tableCell","children":[{"type":"text","value":"Transformers, Model architecture, Model performance","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"uT3ZJHa8dm"}],"key":"GZ1FaxKD6E"},{"type":"tableCell","children":[],"key":"WgEWHnn45E"}],"key":"UnF2fH6s55"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2307.11760","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"text","value":"Large Language Models Understand and Can Be Enhanced by Emotional Stimuli","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"key":"Tl8uj1Eit4"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2307.11760","identifier":"https://doi.org/10.48550/arXiv.2307.11760","enumerator":"21","key":"iQFsfLF8ZH"}],"key":"XNgSK2368G"},{"type":"tableCell","children":[{"type":"text","value":"emotional stimuli, Model behavior","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"key":"DIR59M470D"}],"key":"fbb4DiqH3t"},{"type":"tableCell","children":[],"key":"FhuceeIv8Q"}],"key":"i69lTrmMzE"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.09171","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"text","value":"Automated Unit Test Improvement using Large Language Models at Meta","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"key":"bxF3qKmySP"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.09171","identifier":"https://doi.org/10.48550/arXiv.2402.09171","enumerator":"22","key":"CEIvlWgBYS"}],"key":"e82kudNa42"},{"type":"tableCell","children":[{"type":"text","value":"Automated testing, Software engineering","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"key":"nJzyBQwRP2"}],"key":"PBKkaQrg1Q"},{"type":"tableCell","children":[],"key":"ZhUBBqnHz4"}],"key":"mhqcCHv7Ll"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.01413","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"children":[{"type":"text","value":"Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"key":"OZtxCbmlw1"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.01413","identifier":"https://doi.org/10.48550/arXiv.2404.01413","enumerator":"23","key":"HM9jOTNTBI"}],"key":"iwljre214l"},{"type":"tableCell","children":[{"type":"text","value":"Data accumulation, Model collapse prevention","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"J0saVNvygM"}],"key":"gFc3s4I6X2"},{"type":"tableCell","children":[],"key":"cdID5yUMpn"}],"key":"PVy00hr2Uh"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2102.04518","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"children":[{"type":"text","value":"A\\ Search Without Expansions: Learning Heuristic Functions With Deep Q-Networks","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"key":"XCuQjUXlsn"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2102.04518","identifier":"https://doi.org/10.48550/arXiv.2102.04518","enumerator":"24","key":"I8FZtGyboY"}],"key":"zNM496X1uE"},{"type":"tableCell","children":[{"type":"text","value":"Reinforcement learning, Search algorithms","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"hQidghfiIS"}],"key":"S7oofjFWum"},{"type":"tableCell","children":[],"key":"tlpxXM5fsL"}],"key":"NUSNvrXPQd"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.06196","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"children":[{"type":"text","value":"Large Language Models: A Survey","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"key":"aZUDGLfi3S"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.06196","identifier":"https://doi.org/10.48550/arXiv.2402.06196","enumerator":"25","key":"TqMNzdJ5Oy"}],"key":"VFf6daEkTm"},{"type":"tableCell","children":[{"type":"text","value":"LLM capabilities, Survey","position":{"start":{"line":95,"column":1},"end":{"line":95,"column":1}},"key":"ynJ0iilQDY"}],"key":"yPatBa2xcQ"},{"type":"tableCell","children":[],"key":"egTtUoy3by"}],"key":"eY3hlBHkSW"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.14433","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"children":[{"type":"text","value":"A Language Model’s Guide Through Latent Space","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"RRQV52XBRd"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.14433","identifier":"https://doi.org/10.48550/arXiv.2402.14433","enumerator":"26","key":"BD4sIcA1AJ"}],"key":"ymAje9F898"},{"type":"tableCell","children":[{"type":"text","value":"Interpretability, Latent space","position":{"start":{"line":98,"column":1},"end":{"line":98,"column":1}},"key":"eElZsYttBK"}],"key":"whNasCGe4p"},{"type":"tableCell","children":[],"key":"cVwjiKbi6U"}],"key":"Vm3BChVlO5"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2205.05124","position":{"start":{"line":100,"column":1},"end":{"line":100,"column":1}},"children":[{"type":"text","value":"Extracting Latent Steering Vectors from Pretrained Language Models","position":{"start":{"line":100,"column":1},"end":{"line":100,"column":1}},"key":"pSpajn1FMn"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2205.05124","identifier":"https://doi.org/10.48550/arXiv.2205.05124","enumerator":"27","key":"d1E1ZNxJiN"}],"key":"LSJ8NpoAYF"},{"type":"tableCell","children":[{"type":"text","value":"Interpretability, Latent space","position":{"start":{"line":101,"column":1},"end":{"line":101,"column":1}},"key":"cYldMSmwdh"}],"key":"MWSj1EYKPq"},{"type":"tableCell","children":[],"key":"lww9Ry47em"}],"key":"uSzoKsnX7L"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.anthropic.com/research/many-shot-jailbreaking","position":{"start":{"line":103,"column":1},"end":{"line":103,"column":1}},"children":[{"type":"text","value":"Many-shot jailbreaking","position":{"start":{"line":103,"column":1},"end":{"line":103,"column":1}},"key":"esOCTxx4hT"}],"urlSource":"https://www.anthropic.com/research/many-shot-jailbreaking","key":"cd5TYLnWVy"}],"key":"fCjzGM9U5l"},{"type":"tableCell","children":[{"type":"text","value":"Jailbreaking, Model safety","position":{"start":{"line":104,"column":1},"end":{"line":104,"column":1}},"key":"hRzGtO41Kl"}],"key":"QQHBhT2EBp"},{"type":"tableCell","children":[],"key":"iiqxleRCQu"}],"key":"A43pvde3c3"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1910.10683","position":{"start":{"line":106,"column":1},"end":{"line":106,"column":1}},"children":[{"type":"text","value":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer","position":{"start":{"line":106,"column":1},"end":{"line":106,"column":1}},"key":"kOoLcakAQ3"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1910.10683","identifier":"https://doi.org/10.48550/arXiv.1910.10683","enumerator":"28","key":"TkjJfmka0E"}],"key":"LIVnB6wsAL"},{"type":"tableCell","children":[{"type":"text","value":"Transfer learning","position":{"start":{"line":107,"column":1},"end":{"line":107,"column":1}},"key":"y3CbN3VnZ9"}],"key":"C2QAWFvzr7"},{"type":"tableCell","children":[],"key":"fZrgTBVVf0"}],"key":"JKouqpWhmD"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2308.10248","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"Activation Addition: Steering Language Models Without Optimization","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"gDc0h10OWS"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2308.10248","identifier":"https://doi.org/10.48550/arXiv.2308.10248","enumerator":"29","key":"g1ZT1BDu6S"}],"key":"VExUSJymJt"},{"type":"tableCell","children":[{"type":"text","value":"Activation manipulation, Model steering","position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"key":"BpunEnYy4c"}],"key":"PvyM7lByAA"},{"type":"tableCell","children":[],"key":"jvUzgkvVq2"}],"key":"zE0eFIa2Ij"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2107.03374","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"children":[{"type":"text","value":"Evaluating Large Language Models Trained on Code","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"VHOli3F9TW"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2107.03374","identifier":"https://doi.org/10.48550/arXiv.2107.03374","enumerator":"30","key":"MRcFVsFuZu"}],"key":"JMUjA6zb8a"},{"type":"tableCell","children":[{"type":"text","value":"Code generation, Model evaluation","position":{"start":{"line":113,"column":1},"end":{"line":113,"column":1}},"key":"lx8qFmBGGd"}],"key":"KMAs0nbNdQ"},{"type":"tableCell","children":[],"key":"WgcYGSXg8p"}],"key":"MtndLqP9p8"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.02543","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"children":[{"type":"text","value":"To Believe or Not to Believe Your LLM","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"key":"e7pdNVL7mS"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.02543","identifier":"https://doi.org/10.48550/arXiv.2406.02543","enumerator":"31","key":"Vz6544B6JW"}],"key":"zP13LddElc"},{"type":"tableCell","children":[{"type":"text","value":"Hallucination detection, Uncertainty quantification","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"jw7J6sfF0f"}],"key":"necBTWEuzP"},{"type":"tableCell","children":[],"key":"qu0lwyCRS1"}],"key":"sxI5D4HFBQ"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.04692","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"children":[{"type":"text","value":"Mixture of Agents","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"key":"otZLXHajhM"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.04692","identifier":"https://doi.org/10.48550/arXiv.2406.04692","enumerator":"19","key":"iAgvU7ePnb"}],"key":"NYHxvNElWu"},{"type":"tableCell","children":[{"type":"text","value":"Multi-agent systems, Prompting","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"key":"Ao5hQIZhbM"}],"key":"c3QOLmgWg8"},{"type":"tableCell","children":[],"key":"FKEMFeauek"}],"key":"V6CMnjGGYl"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.14619","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"children":[{"type":"text","value":"OpenELM: An Efficient Language Model Family with Open Training and Inference Framework","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"key":"nHjtMQggyj"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.14619","identifier":"https://doi.org/10.48550/arXiv.2404.14619","enumerator":"32","key":"IyTbTUxKCF"}],"key":"kpcqCx6RHt"},{"type":"tableCell","children":[{"type":"text","value":"Efficiency, Model architecture","position":{"start":{"line":122,"column":1},"end":{"line":122,"column":1}},"key":"bhauwhyC9v"}],"key":"YGgYBw1Ips"},{"type":"tableCell","children":[],"key":"GOj8riHZmS"}],"key":"AUWZZf9uf1"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1706.03741","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"text","value":"Deep Reinforcement Learning from Human Preferences","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"undRTyPmKN"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1706.03741","identifier":"https://doi.org/10.48550/arXiv.1706.03741","enumerator":"33","key":"WK3uijre55"}],"key":"mfxgHyw9Vv"},{"type":"tableCell","children":[{"type":"text","value":"human feedback, Reinforcement learning","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":1}},"key":"cbIWZPaSwM"}],"key":"rUdfN0JgfP"},{"type":"tableCell","children":[],"key":"GB8d7bzmix"}],"key":"blbMT9xzAR"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2307.08925","position":{"start":{"line":127,"column":1},"end":{"line":127,"column":1}},"children":[{"type":"text","value":"Federated Large Language Model: A Position Paper","position":{"start":{"line":127,"column":1},"end":{"line":127,"column":1}},"key":"zFMiAr682e"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2307.08925","identifier":"https://doi.org/10.48550/arXiv.2307.08925","enumerator":"34","key":"WZnBne4AWX"}],"key":"wJJoC2x7sy"},{"type":"tableCell","children":[{"type":"text","value":"Distributed training, Federated learning","position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"key":"SwZLccilxE"}],"key":"xzTk6Y2uvj"},{"type":"tableCell","children":[],"key":"pf1cduj5PK"}],"key":"UYMC5fm2hi"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2212.02508","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"children":[{"type":"text","value":"MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"key":"ugLqS4QCOh"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2212.02508","identifier":"https://doi.org/10.48550/arXiv.2212.02508","enumerator":"35","key":"qYM2UkD63b"}],"key":"QlZSkjd5R6"},{"type":"tableCell","children":[{"type":"text","value":"Music representation, Self-supervised learning","position":{"start":{"line":131,"column":1},"end":{"line":131,"column":1}},"key":"vGAJQjo1V8"}],"key":"qKQNGkKIPF"},{"type":"tableCell","children":[],"key":"fAVtwrmflU"}],"key":"QL2UDnytTu"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2302.13971","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"children":[{"type":"text","value":"LLaMA: Open and Efficient Foundation Language Models","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"key":"aZmn7elYMT"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2302.13971","identifier":"https://doi.org/10.48550/arXiv.2302.13971","enumerator":"36","key":"LFZvSNJqu5"}],"key":"y4msMKXHWf"},{"type":"tableCell","children":[{"type":"text","value":"Model architecture, Open-source LLMs","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"yHYlcJQaJF"}],"key":"KKilm4otYL"},{"type":"tableCell","children":[],"key":"a9GMtpHyue"}],"key":"T7EfkgyXLV"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"text","value":"Phi1: Textbooks Are All You Need","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"W1q957Hihi"}],"urlSource":"https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/","key":"qJ8TJbszxQ"}],"key":"P83pprZ9J4"},{"type":"tableCell","children":[{"type":"text","value":"Curated datasets, Model efficiency","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"OKRM37EK1X"}],"key":"Ay5l8sUlzj"},{"type":"tableCell","children":[],"key":"q3afSkyD3r"}],"key":"jp6ichJ3PE"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1607.06450","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"children":[{"type":"text","value":"Layer Normalization","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"key":"PHoiUfny6j"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1607.06450","identifier":"https://doi.org/10.48550/arXiv.1607.06450","enumerator":"37","key":"jh4xGy0dlT"}],"key":"m6bIrJDjUj"},{"type":"tableCell","children":[{"type":"text","value":"Model internals, Optimization","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"key":"YVjtm7zmN0"}],"key":"mhEWzvkjg1"},{"type":"tableCell","children":[],"key":"Z2hKpAkKHd"}],"key":"mFm09GLjid"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1706.03762","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"children":[{"type":"text","value":"Attention Is All You Need","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"key":"a5QRgOHd6h"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1706.03762","identifier":"https://doi.org/10.48550/arXiv.1706.03762","enumerator":"38","key":"h9rhzAbIM3"}],"key":"koVoaWG522"},{"type":"tableCell","children":[{"type":"text","value":"OG papers, Transformers","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"KJMDFV2TFs"}],"key":"MoRtmmd9RJ"},{"type":"tableCell","children":[],"key":"CRlznKnEDJ"}],"key":"WuHNAjQtXs"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.09412","position":{"start":{"line":145,"column":1},"end":{"line":145,"column":1}},"children":[{"type":"text","value":"Explore the Limits of Omni-modal Pretraining at Scale","position":{"start":{"line":145,"column":1},"end":{"line":145,"column":1}},"key":"IjefKzQcfm"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.09412","identifier":"https://doi.org/10.48550/arXiv.2406.09412","enumerator":"39","key":"GgRdFihkWI"}],"key":"aB6ktXCGJ9"},{"type":"tableCell","children":[{"type":"text","value":"Multi-modal models, Pretraining","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"VumnJWJxbd"}],"key":"G3cOv3xX68"},{"type":"tableCell","children":[],"key":"VlSziVNJBq"}],"key":"PeRc3p6SM7"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1606.08415","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"children":[{"type":"text","value":"Gaussian Error Linear Units (GELUs)","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"key":"QKaBUmIGoX"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1606.08415","identifier":"https://doi.org/10.48550/arXiv.1606.08415","enumerator":"40","key":"Bm886pGJfx"}],"key":"MJLVLOpESi"},{"type":"tableCell","children":[{"type":"text","value":"Activation functions, Model internals","position":{"start":{"line":149,"column":1},"end":{"line":149,"column":1}},"key":"paXYoLQQAl"}],"key":"PBdCT5eFaz"},{"type":"tableCell","children":[],"key":"TTyo9qKzER"}],"key":"wiaoJIiKQ2"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2401.09796","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"children":[{"type":"text","value":"A Fast, Performant, Secure Distributed Training Framework For Large Language Model","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"key":"q4WuxvQZsK"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2401.09796","identifier":"https://doi.org/10.48550/arXiv.2401.09796","enumerator":"41","key":"jxFGnkafzW"}],"key":"G3nALXV5aK"},{"type":"tableCell","children":[{"type":"text","value":"Distributed training, Security","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"wNE5QqEpMJ"}],"key":"xt8ugzbUTb"},{"type":"tableCell","children":[],"key":"qGoWAl92oF"}],"key":"mMDD9V8zSP"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1910.01108","position":{"start":{"line":154,"column":1},"end":{"line":154,"column":1}},"children":[{"type":"text","value":"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter","position":{"start":{"line":154,"column":1},"end":{"line":154,"column":1}},"key":"G4TN2iet6K"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1910.01108","identifier":"https://doi.org/10.48550/arXiv.1910.01108","enumerator":"42","key":"ynCp9mroDP"}],"key":"WazU5u59Wg"},{"type":"tableCell","children":[{"type":"text","value":"Efficiency, Model distillation","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"wPfOj8qBbt"}],"key":"nT7zR94daA"},{"type":"tableCell","children":[],"key":"bHR0mC9wol"}],"key":"HLu8Ro0p8U"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","position":{"start":{"line":157,"column":1},"end":{"line":157,"column":1}},"children":[{"type":"text","value":"Improving Language Understanding by Generative Pre-Training","position":{"start":{"line":157,"column":1},"end":{"line":157,"column":1}},"key":"cFfzdqLAoL"}],"urlSource":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","key":"zBaBRRZUa3"}],"key":"Vv2eSGqcOL"},{"type":"tableCell","children":[{"type":"text","value":"OG papers, Pre-training","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"key":"iuxIHTC2NQ"}],"key":"AP9gyvjuc0"},{"type":"tableCell","children":[],"key":"qUOlNc76CH"}],"key":"psJVNouwb7"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2203.02155","position":{"start":{"line":160,"column":1},"end":{"line":160,"column":1}},"children":[{"type":"text","value":"Training language models to follow instructions with human feedback","position":{"start":{"line":160,"column":1},"end":{"line":160,"column":1}},"key":"lSUssObI9X"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2203.02155","identifier":"https://doi.org/10.48550/arXiv.2203.02155","enumerator":"43","key":"kUj3DfhSXl"}],"key":"pvLL2QtQ7J"},{"type":"tableCell","children":[{"type":"text","value":"Instruction following, Reinforcement learning","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"key":"BWz1G5fua2"}],"key":"hwtvwEBX9S"},{"type":"tableCell","children":[],"key":"XteYPh67ln"}],"key":"vR9eK4YyTZ"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2307.09288","position":{"start":{"line":163,"column":1},"end":{"line":163,"column":1}},"children":[{"type":"text","value":"Llama 2: Open Foundation and Fine-Tuned Chat Models","position":{"start":{"line":163,"column":1},"end":{"line":163,"column":1}},"key":"OdpHw4ndGU"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2307.09288","identifier":"https://doi.org/10.48550/arXiv.2307.09288","enumerator":"44","key":"sF1maLFMvQ"}],"key":"mP5AXT7xwX"},{"type":"tableCell","children":[{"type":"text","value":"Fine-tuning, Open-source LLMs","position":{"start":{"line":164,"column":1},"end":{"line":164,"column":1}},"key":"MtFU7bKfpj"}],"key":"ZAvQEju8AH"},{"type":"tableCell","children":[],"key":"P3UosgxG9z"}],"key":"vecITUEXp7"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2104.09864","position":{"start":{"line":166,"column":1},"end":{"line":166,"column":1}},"children":[{"type":"text","value":"RoFormer: Enhanced Transformer with Rotary Position Embedding","position":{"start":{"line":166,"column":1},"end":{"line":166,"column":1}},"key":"cSfDF6MzEU"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2104.09864","identifier":"https://doi.org/10.48550/arXiv.2104.09864","enumerator":"45","key":"xMOlhUGCZZ"}],"key":"AXkC0addsH"},{"type":"tableCell","children":[{"type":"text","value":"Embeddings, Model architecture","position":{"start":{"line":167,"column":1},"end":{"line":167,"column":1}},"key":"kOkbO6os6n"}],"key":"s00o1oMiGx"},{"type":"tableCell","children":[],"key":"IclrNrDx5Q"}],"key":"bwEYOnYsD6"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.nature.com/articles/s42256-023-00748-9","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"children":[{"type":"text","value":"Spatially embedded recurrent neural networks reveal widespread links between structural and functional neuroscience findings | Nature Machine Intelligence","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"key":"MVdoz6zoBQ"}],"urlSource":"https://www.nature.com/articles/s42256-023-00748-9","key":"PUaS8rbQW8"}],"key":"Kw6LB0WVXj"},{"type":"tableCell","children":[{"type":"text","value":"Biological Brains","position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"key":"gsQ1mzCI8o"}],"key":"vCRvjj4tTN"},{"type":"tableCell","children":[],"key":"qMflO9Mjq5"}],"key":"Qg4oQaX7Gv"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://onlinelibrary.wiley.com/doi/10.1111/tops.12737","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"children":[{"type":"text","value":"Understanding Human Cognition Through Computational Modeling - Hsiao - 2024 - Topics in Cognitive Science - Wiley Online Library","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"key":"sMyZSQDKug"}],"kind":"narrative","label":"Hsiao_2024","identifier":"https://onlinelibrary.wiley.com/doi/10.1111/tops.12737","enumerator":"46","key":"PNVo8WIOo2"}],"key":"XMe433LBqn"},{"type":"tableCell","children":[{"type":"text","value":"Biological Brains","position":{"start":{"line":173,"column":1},"end":{"line":173,"column":1}},"key":"VvMqDFUbJF"}],"key":"vq5BD8hmPL"},{"type":"tableCell","children":[],"key":"LsQlWqEMD7"}],"key":"AUBD0bptej"}],"key":"huj6Vm8GHN"}],"enumerator":"1","key":"kRrmz6QPon"}],"key":"XbKTvxoqkn"}],"key":"GQLPrvEx5i"},"references":{"cite":{"order":["https://doi.org/10.48550/arxiv.2411.07191","https://doi.org/10.48550/arxiv.2410.02725","https://doi.org/10.48550/arxiv.2404.03592","https://doi.org/10.48550/arxiv.2402.06111","https://doi.org/10.48550/arxiv.2403.20327","https://doi.org/10.48550/arxiv.2210.07128","https://doi.org/10.48550/arxiv.2407.10969","https://doi.org/10.48550/arxiv.2207.01780","https://doi.org/10.48550/arxiv.2405.20541","https://doi.org/10.48550/arxiv.2402.17764","https://doi.org/10.48550/arxiv.2305.17493","https://doi.org/10.48550/arxiv.2404.07143","https://doi.org/10.48550/arxiv.2406.07496","https://doi.org/10.48550/arxiv.2406.02528","https://doi.org/10.48550/arxiv.1712.00676","https://doi.org/10.48550/arxiv.2311.17035","https://doi.org/10.48550/arxiv.2305.07759","https://doi.org/10.48550/arxiv.2311.12983","https://doi.org/10.48550/arxiv.2406.04692","https://doi.org/10.48550/arxiv.2311.05884","https://doi.org/10.48550/arxiv.2307.11760","https://doi.org/10.48550/arxiv.2402.09171","https://doi.org/10.48550/arxiv.2404.01413","https://doi.org/10.48550/arxiv.2102.04518","https://doi.org/10.48550/arxiv.2402.06196","https://doi.org/10.48550/arxiv.2402.14433","https://doi.org/10.48550/arxiv.2205.05124","https://doi.org/10.48550/arxiv.1910.10683","https://doi.org/10.48550/arxiv.2308.10248","https://doi.org/10.48550/arxiv.2107.03374","https://doi.org/10.48550/arxiv.2406.02543","https://doi.org/10.48550/arxiv.2404.14619","https://doi.org/10.48550/arxiv.1706.03741","https://doi.org/10.48550/arxiv.2307.08925","https://doi.org/10.48550/arxiv.2212.02508","https://doi.org/10.48550/arxiv.2302.13971","https://doi.org/10.48550/arxiv.1607.06450","https://doi.org/10.48550/arxiv.1706.03762","https://doi.org/10.48550/arxiv.2406.09412","https://doi.org/10.48550/arxiv.1606.08415","https://doi.org/10.48550/arxiv.2401.09796","https://doi.org/10.48550/arxiv.1910.01108","https://doi.org/10.48550/arxiv.2203.02155","https://doi.org/10.48550/arxiv.2307.09288","https://doi.org/10.48550/arxiv.2104.09864","Hsiao_2024"],"data":{"https://doi.org/10.48550/arxiv.2411.07191":{"label":"https://doi.org/10.48550/arxiv.2411.07191","enumerator":"1","doi":"10.48550/ARXIV.2411.07191","html":"Yu, M., Wang, D., Shan, Q., Reed, C., \u0026 Wan, A. (2024). \u003ci\u003eThe Super Weight in Large Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2411.07191\"\u003e10.48550/ARXIV.2411.07191\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2411.07191"},"https://doi.org/10.48550/arxiv.2410.02725":{"label":"https://doi.org/10.48550/arxiv.2410.02725","enumerator":"2","doi":"10.48550/ARXIV.2410.02725","html":"Manvi, R., Singh, A., \u0026 Ermon, S. (2024). \u003ci\u003eAdaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2410.02725\"\u003e10.48550/ARXIV.2410.02725\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2410.02725"},"https://doi.org/10.48550/arxiv.2404.03592":{"label":"https://doi.org/10.48550/arxiv.2404.03592","enumerator":"3","doi":"10.48550/ARXIV.2404.03592","html":"Wu, Z., Arora, A., Wang, Z., Geiger, A., Jurafsky, D., Manning, C. D., \u0026 Potts, C. (2024). \u003ci\u003eReFT: Representation Finetuning for Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.03592\"\u003e10.48550/ARXIV.2404.03592\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.03592"},"https://doi.org/10.48550/arxiv.2402.06111":{"label":"https://doi.org/10.48550/arxiv.2402.06111","enumerator":"4","doi":"10.48550/ARXIV.2402.06111","html":"Alshahwan, N., Harman, M., Marginean, A., Tal, R., \u0026 Wang, E. (2024). \u003ci\u003eObservation-based unit test generation at Meta\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.06111\"\u003e10.48550/ARXIV.2402.06111\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.06111"},"https://doi.org/10.48550/arxiv.2403.20327":{"label":"https://doi.org/10.48550/arxiv.2403.20327","enumerator":"5","doi":"10.48550/ARXIV.2403.20327","html":"Lee, J., Dai, Z., Ren, X., Chen, B., Cer, D., Cole, J. R., Hui, K., Boratko, M., Kapadia, R., Ding, W., Luan, Y., Duddu, S. M. K., Abrego, G. H., Shi, W., Gupta, N., Kusupati, A., Jain, P., Jonnalagadda, S. R., Chang, M.-W., \u0026 Naim, I. (2024). \u003ci\u003eGecko: Versatile Text Embeddings Distilled from Large Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2403.20327\"\u003e10.48550/ARXIV.2403.20327\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2403.20327"},"https://doi.org/10.48550/arxiv.2210.07128":{"label":"https://doi.org/10.48550/arxiv.2210.07128","enumerator":"6","doi":"10.48550/ARXIV.2210.07128","html":"Madaan, A., Zhou, S., Alon, U., Yang, Y., \u0026 Neubig, G. (2022). \u003ci\u003eLanguage Models of Code are Few-Shot Commonsense Learners\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2210.07128\"\u003e10.48550/ARXIV.2210.07128\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2210.07128"},"https://doi.org/10.48550/arxiv.2407.10969":{"label":"https://doi.org/10.48550/arxiv.2407.10969","enumerator":"7","doi":"10.48550/ARXIV.2407.10969","html":"Wang, H., Ma, S., Wang, R., \u0026 Wei, F. (2024). \u003ci\u003eQ-Sparse: All Large Language Models can be Fully Sparsely-Activated\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2407.10969\"\u003e10.48550/ARXIV.2407.10969\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2407.10969"},"https://doi.org/10.48550/arxiv.2207.01780":{"label":"https://doi.org/10.48550/arxiv.2207.01780","enumerator":"8","doi":"10.48550/ARXIV.2207.01780","html":"Le, H., Wang, Y., Gotmare, A. D., Savarese, S., \u0026 Hoi, S. C. H. (2022). \u003ci\u003eCodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2207.01780\"\u003e10.48550/ARXIV.2207.01780\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2207.01780"},"https://doi.org/10.48550/arxiv.2405.20541":{"label":"https://doi.org/10.48550/arxiv.2405.20541","enumerator":"9","doi":"10.48550/ARXIV.2405.20541","html":"Ankner, Z., Blakeney, C., Sreenivasan, K., Marion, M., Leavitt, M. L., \u0026 Paul, M. (2024). \u003ci\u003ePerplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2405.20541\"\u003e10.48550/ARXIV.2405.20541\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2405.20541"},"https://doi.org/10.48550/arxiv.2402.17764":{"label":"https://doi.org/10.48550/arxiv.2402.17764","enumerator":"10","doi":"10.48550/ARXIV.2402.17764","html":"Ma, S., Wang, H., Ma, L., Wang, L., Wang, W., Huang, S., Dong, L., Wang, R., Xue, J., \u0026 Wei, F. (2024). \u003ci\u003eThe Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.17764\"\u003e10.48550/ARXIV.2402.17764\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.17764"},"https://doi.org/10.48550/arxiv.2305.17493":{"label":"https://doi.org/10.48550/arxiv.2305.17493","enumerator":"11","doi":"10.48550/ARXIV.2305.17493","html":"Shumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot, N., \u0026 Anderson, R. (2023). \u003ci\u003eThe Curse of Recursion: Training on Generated Data Makes Models Forget\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2305.17493\"\u003e10.48550/ARXIV.2305.17493\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2305.17493"},"https://doi.org/10.48550/arxiv.2404.07143":{"label":"https://doi.org/10.48550/arxiv.2404.07143","enumerator":"12","doi":"10.48550/ARXIV.2404.07143","html":"Munkhdalai, T., Faruqui, M., \u0026 Gopal, S. (2024). \u003ci\u003eLeave No Context Behind: Efficient Infinite Context Transformers with Infini-attention\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.07143\"\u003e10.48550/ARXIV.2404.07143\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.07143"},"https://doi.org/10.48550/arxiv.2406.07496":{"label":"https://doi.org/10.48550/arxiv.2406.07496","enumerator":"13","doi":"10.48550/ARXIV.2406.07496","html":"Yuksekgonul, M., Bianchi, F., Boen, J., Liu, S., Huang, Z., Guestrin, C., \u0026 Zou, J. (2024). \u003ci\u003eTextGrad: Automatic “Differentiation” via Text\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.07496\"\u003e10.48550/ARXIV.2406.07496\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.07496"},"https://doi.org/10.48550/arxiv.2406.02528":{"label":"https://doi.org/10.48550/arxiv.2406.02528","enumerator":"14","doi":"10.48550/ARXIV.2406.02528","html":"Zhu, R.-J., Zhang, Y., Sifferman, E., Sheaves, T., Wang, Y., Richmond, D., Zhou, P., \u0026 Eshraghian, J. K. (2024). \u003ci\u003eScalable MatMul-free Language Modeling\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.02528\"\u003e10.48550/ARXIV.2406.02528\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.02528"},"https://doi.org/10.48550/arxiv.1712.00676":{"label":"https://doi.org/10.48550/arxiv.1712.00676","enumerator":"15","doi":"10.48550/ARXIV.1712.00676","html":"Billings, J. J., McCaskey, A. J., Vallee, G., \u0026 Watson, G. (2017). \u003ci\u003eWill humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?\u003c/i\u003e arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1712.00676\"\u003e10.48550/ARXIV.1712.00676\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1712.00676"},"https://doi.org/10.48550/arxiv.2311.17035":{"label":"https://doi.org/10.48550/arxiv.2311.17035","enumerator":"16","doi":"10.48550/ARXIV.2311.17035","html":"Nasr, M., Carlini, N., Hayase, J., Jagielski, M., Cooper, A. F., Ippolito, D., Choquette-Choo, C. A., Wallace, E., Tramèr, F., \u0026 Lee, K. (2023). \u003ci\u003eScalable Extraction of Training Data from (Production) Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2311.17035\"\u003e10.48550/ARXIV.2311.17035\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2311.17035"},"https://doi.org/10.48550/arxiv.2305.07759":{"label":"https://doi.org/10.48550/arxiv.2305.07759","enumerator":"17","doi":"10.48550/ARXIV.2305.07759","html":"Eldan, R., \u0026 Li, Y. (2023). \u003ci\u003eTinyStories: How Small Can Language Models Be and Still Speak Coherent English?\u003c/i\u003e arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2305.07759\"\u003e10.48550/ARXIV.2305.07759\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2305.07759"},"https://doi.org/10.48550/arxiv.2311.12983":{"label":"https://doi.org/10.48550/arxiv.2311.12983","enumerator":"18","doi":"10.48550/ARXIV.2311.12983","html":"Mialon, G., Fourrier, C., Swift, C., Wolf, T., LeCun, Y., \u0026 Scialom, T. (2023). \u003ci\u003eGAIA: a benchmark for General AI Assistants\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2311.12983\"\u003e10.48550/ARXIV.2311.12983\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2311.12983"},"https://doi.org/10.48550/arxiv.2406.04692":{"label":"https://doi.org/10.48550/arxiv.2406.04692","enumerator":"19","doi":"10.48550/ARXIV.2406.04692","html":"Wang, J., Wang, J., Athiwaratkun, B., Zhang, C., \u0026 Zou, J. (2024). \u003ci\u003eMixture-of-Agents Enhances Large Language Model Capabilities\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.04692\"\u003e10.48550/ARXIV.2406.04692\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.04692"},"https://doi.org/10.48550/arxiv.2311.05884":{"label":"https://doi.org/10.48550/arxiv.2311.05884","enumerator":"20","doi":"10.48550/ARXIV.2311.05884","html":"Gui, H., Wang, R., Yin, K., Jin, L., Kula, M., Xu, T., Hong, L., \u0026 Chi, E. H. (2023). \u003ci\u003eHiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2311.05884\"\u003e10.48550/ARXIV.2311.05884\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2311.05884"},"https://doi.org/10.48550/arxiv.2307.11760":{"label":"https://doi.org/10.48550/arxiv.2307.11760","enumerator":"21","doi":"10.48550/ARXIV.2307.11760","html":"Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., \u0026 Xie, X. (2023). \u003ci\u003eLarge Language Models Understand and Can be Enhanced by Emotional Stimuli\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2307.11760\"\u003e10.48550/ARXIV.2307.11760\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2307.11760"},"https://doi.org/10.48550/arxiv.2402.09171":{"label":"https://doi.org/10.48550/arxiv.2402.09171","enumerator":"22","doi":"10.48550/ARXIV.2402.09171","html":"Alshahwan, N., Chheda, J., Finegenova, A., Gokkaya, B., Harman, M., Harper, I., Marginean, A., Sengupta, S., \u0026 Wang, E. (2024). \u003ci\u003eAutomated Unit Test Improvement using Large Language Models at Meta\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.09171\"\u003e10.48550/ARXIV.2402.09171\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.09171"},"https://doi.org/10.48550/arxiv.2404.01413":{"label":"https://doi.org/10.48550/arxiv.2404.01413","enumerator":"23","doi":"10.48550/ARXIV.2404.01413","html":"Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., \u0026 Koyejo, S. (2024). \u003ci\u003eIs Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.01413\"\u003e10.48550/ARXIV.2404.01413\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.01413"},"https://doi.org/10.48550/arxiv.2102.04518":{"label":"https://doi.org/10.48550/arxiv.2102.04518","enumerator":"24","doi":"10.48550/ARXIV.2102.04518","html":"Agostinelli, F., Shmakov, A., McAleer, S., Fox, R., \u0026 Baldi, P. (2021). \u003ci\u003eA* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2102.04518\"\u003e10.48550/ARXIV.2102.04518\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2102.04518"},"https://doi.org/10.48550/arxiv.2402.06196":{"label":"https://doi.org/10.48550/arxiv.2402.06196","enumerator":"25","doi":"10.48550/ARXIV.2402.06196","html":"Minaee, S., Mikolov, T., Nikzad, N., Chenaghlu, M., Socher, R., Amatriain, X., \u0026 Gao, J. (2024). \u003ci\u003eLarge Language Models: A Survey\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.06196\"\u003e10.48550/ARXIV.2402.06196\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.06196"},"https://doi.org/10.48550/arxiv.2402.14433":{"label":"https://doi.org/10.48550/arxiv.2402.14433","enumerator":"26","doi":"10.48550/ARXIV.2402.14433","html":"von Rütte, D., Anagnostidis, S., Bachmann, G., \u0026 Hofmann, T. (2024). \u003ci\u003eA Language Model’s Guide Through Latent Space\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.14433\"\u003e10.48550/ARXIV.2402.14433\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.14433"},"https://doi.org/10.48550/arxiv.2205.05124":{"label":"https://doi.org/10.48550/arxiv.2205.05124","enumerator":"27","doi":"10.48550/ARXIV.2205.05124","html":"Subramani, N., Suresh, N., \u0026 Peters, M. E. (2022). \u003ci\u003eExtracting Latent Steering Vectors from Pretrained Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2205.05124\"\u003e10.48550/ARXIV.2205.05124\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2205.05124"},"https://doi.org/10.48550/arxiv.1910.10683":{"label":"https://doi.org/10.48550/arxiv.1910.10683","enumerator":"28","doi":"10.48550/ARXIV.1910.10683","html":"Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., \u0026 Liu, P. J. (2019). \u003ci\u003eExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1910.10683\"\u003e10.48550/ARXIV.1910.10683\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1910.10683"},"https://doi.org/10.48550/arxiv.2308.10248":{"label":"https://doi.org/10.48550/arxiv.2308.10248","enumerator":"29","doi":"10.48550/ARXIV.2308.10248","html":"Turner, A. M., Thiergart, L., Leech, G., Udell, D., Vazquez, J. J., Mini, U., \u0026 MacDiarmid, M. (2023). \u003ci\u003eSteering Language Models With Activation Engineering\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2308.10248\"\u003e10.48550/ARXIV.2308.10248\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2308.10248"},"https://doi.org/10.48550/arxiv.2107.03374":{"label":"https://doi.org/10.48550/arxiv.2107.03374","enumerator":"30","doi":"10.48550/ARXIV.2107.03374","html":"Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., … Zaremba, W. (2021). \u003ci\u003eEvaluating Large Language Models Trained on Code\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2107.03374\"\u003e10.48550/ARXIV.2107.03374\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2107.03374"},"https://doi.org/10.48550/arxiv.2406.02543":{"label":"https://doi.org/10.48550/arxiv.2406.02543","enumerator":"31","doi":"10.48550/ARXIV.2406.02543","html":"Yadkori, Y. A., Kuzborskij, I., György, A., \u0026 Szepesvári, C. (2024). \u003ci\u003eTo Believe or Not to Believe Your LLM\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.02543\"\u003e10.48550/ARXIV.2406.02543\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.02543"},"https://doi.org/10.48550/arxiv.2404.14619":{"label":"https://doi.org/10.48550/arxiv.2404.14619","enumerator":"32","doi":"10.48550/ARXIV.2404.14619","html":"Mehta, S., Sekhavat, M. H., Cao, Q., Horton, M., Jin, Y., Sun, C., Mirzadeh, I., Najibi, M., Belenko, D., Zatloukal, P., \u0026 Rastegari, M. (2024). \u003ci\u003eOpenELM: An Efficient Language Model Family with Open Training and Inference Framework\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.14619\"\u003e10.48550/ARXIV.2404.14619\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.14619"},"https://doi.org/10.48550/arxiv.1706.03741":{"label":"https://doi.org/10.48550/arxiv.1706.03741","enumerator":"33","doi":"10.48550/ARXIV.1706.03741","html":"Christiano, P., Leike, J., Brown, T. B., Martic, M., Legg, S., \u0026 Amodei, D. (2017). \u003ci\u003eDeep reinforcement learning from human preferences\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1706.03741\"\u003e10.48550/ARXIV.1706.03741\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1706.03741"},"https://doi.org/10.48550/arxiv.2307.08925":{"label":"https://doi.org/10.48550/arxiv.2307.08925","enumerator":"34","doi":"10.48550/ARXIV.2307.08925","html":"Chen, C., Feng, X., Li, Y., Lyu, L., Zhou, J., Zheng, X., \u0026 Yin, J. (2023). \u003ci\u003eIntegration of Large Language Models and Federated Learning\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2307.08925\"\u003e10.48550/ARXIV.2307.08925\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2307.08925"},"https://doi.org/10.48550/arxiv.2212.02508":{"label":"https://doi.org/10.48550/arxiv.2212.02508","enumerator":"35","doi":"10.48550/ARXIV.2212.02508","html":"Li, Y., Yuan, R., Zhang, G., Ma, Y., Lin, C., Chen, X., Ragni, A., Yin, H., Hu, Z., He, H., Benetos, E., Gyenge, N., Liu, R., \u0026 Fu, J. (2022). \u003ci\u003eMAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2212.02508\"\u003e10.48550/ARXIV.2212.02508\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2212.02508"},"https://doi.org/10.48550/arxiv.2302.13971":{"label":"https://doi.org/10.48550/arxiv.2302.13971","enumerator":"36","doi":"10.48550/ARXIV.2302.13971","html":"Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., \u0026 Lample, G. (2023). \u003ci\u003eLLaMA: Open and Efficient Foundation Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2302.13971\"\u003e10.48550/ARXIV.2302.13971\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2302.13971"},"https://doi.org/10.48550/arxiv.1607.06450":{"label":"https://doi.org/10.48550/arxiv.1607.06450","enumerator":"37","doi":"10.48550/ARXIV.1607.06450","html":"Ba, J. L., Kiros, J. R., \u0026 Hinton, G. E. (2016). \u003ci\u003eLayer Normalization\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1607.06450\"\u003e10.48550/ARXIV.1607.06450\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1607.06450"},"https://doi.org/10.48550/arxiv.1706.03762":{"label":"https://doi.org/10.48550/arxiv.1706.03762","enumerator":"38","doi":"10.48550/ARXIV.1706.03762","html":"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., \u0026 Polosukhin, I. (2017). \u003ci\u003eAttention Is All You Need\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1706.03762\"\u003e10.48550/ARXIV.1706.03762\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1706.03762"},"https://doi.org/10.48550/arxiv.2406.09412":{"label":"https://doi.org/10.48550/arxiv.2406.09412","enumerator":"39","doi":"10.48550/ARXIV.2406.09412","html":"Zhang, Y., Li, H., Liu, J., \u0026 Yue, X. (2024). \u003ci\u003eExplore the Limits of Omni-modal Pretraining at Scale\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.09412\"\u003e10.48550/ARXIV.2406.09412\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.09412"},"https://doi.org/10.48550/arxiv.1606.08415":{"label":"https://doi.org/10.48550/arxiv.1606.08415","enumerator":"40","doi":"10.48550/ARXIV.1606.08415","html":"Hendrycks, D., \u0026 Gimpel, K. (2016). \u003ci\u003eGaussian Error Linear Units (GELUs)\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1606.08415\"\u003e10.48550/ARXIV.1606.08415\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1606.08415"},"https://doi.org/10.48550/arxiv.2401.09796":{"label":"https://doi.org/10.48550/arxiv.2401.09796","enumerator":"41","doi":"10.48550/ARXIV.2401.09796","html":"Huang, W., Wang, Y., Cheng, A., Zhou, A., Yu, C., \u0026 Wang, L. (2024). \u003ci\u003eA Fast, Performant, Secure Distributed Training Framework For Large Language Model\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2401.09796\"\u003e10.48550/ARXIV.2401.09796\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2401.09796"},"https://doi.org/10.48550/arxiv.1910.01108":{"label":"https://doi.org/10.48550/arxiv.1910.01108","enumerator":"42","doi":"10.48550/ARXIV.1910.01108","html":"Sanh, V., Debut, L., Chaumond, J., \u0026 Wolf, T. (2019). \u003ci\u003eDistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1910.01108\"\u003e10.48550/ARXIV.1910.01108\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1910.01108"},"https://doi.org/10.48550/arxiv.2203.02155":{"label":"https://doi.org/10.48550/arxiv.2203.02155","enumerator":"43","doi":"10.48550/ARXIV.2203.02155","html":"Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., \u0026 Lowe, R. (2022). \u003ci\u003eTraining language models to follow instructions with human feedback\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2203.02155\"\u003e10.48550/ARXIV.2203.02155\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2203.02155"},"https://doi.org/10.48550/arxiv.2307.09288":{"label":"https://doi.org/10.48550/arxiv.2307.09288","enumerator":"44","doi":"10.48550/ARXIV.2307.09288","html":"Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., … Scialom, T. (2023). \u003ci\u003eLlama 2: Open Foundation and Fine-Tuned Chat Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2307.09288\"\u003e10.48550/ARXIV.2307.09288\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2307.09288"},"https://doi.org/10.48550/arxiv.2104.09864":{"label":"https://doi.org/10.48550/arxiv.2104.09864","enumerator":"45","doi":"10.48550/ARXIV.2104.09864","html":"Su, J., Lu, Y., Pan, S., Murtadha, A., Wen, B., \u0026 Liu, Y. (2021). \u003ci\u003eRoFormer: Enhanced Transformer with Rotary Position Embedding\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2104.09864\"\u003e10.48550/ARXIV.2104.09864\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2104.09864"},"Hsiao_2024":{"label":"Hsiao_2024","enumerator":"46","doi":"10.1111/tops.12737","html":"Hsiao, J. H. (2024). Understanding Human Cognition Through Computational Modeling. \u003ci\u003eTopics in Cognitive Science\u003c/i\u003e, \u003ci\u003e16\u003c/i\u003e(3), 349–376. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1111/tops.12737\"\u003e10.1111/tops.12737\u003c/a\u003e","url":"https://doi.org/10.1111/tops.12737"}}}},"footer":{"navigation":{"prev":{"title":"The Transformer","url":"/glossary/transformer-1","group":"ML Notes"},"next":{"title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","url":"/paper-notes/perplexity-based-data-pruning","group":"ML Notes"}}},"domain":"http://localhost:3000"},"project":{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"},{"children":[{"file":"experiments/higher-abstract-reasoning.ipynb"}],"file":"experiments/index.md","title":"Experiments"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"experiments.index","title":"Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"experiments.higher-abstract-reasoning","title":"Transformers and Higher-Order Abstract Reasoning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-A92797E9.js";
import * as route0 from "/build/root-HROFNPGU.js";
import * as route1 from "/build/routes/$-WNZNXUO2.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>