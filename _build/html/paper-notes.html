<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Papers - ML Notes</title><meta property="og:title" content="Papers - ML Notes"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/build/_assets/app-H3NBUYVS.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="/myst-theme.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">ML Notes</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3iop:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="ML Notes" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">ML Notes</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Projects" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/projects">Projects</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rbd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rbd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Glossary" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/glossary">Glossary</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rfd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rfd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none bg-blue-300/30"><a title="Papers" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200 active" href="/paper-notes">Papers</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rjd8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:Rjd8p:" class="pl-3 pr-[2px] collapsible-content"><a title="Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/paper-notes/perplexity-based-data-pruning">Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</a></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Experiments" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/experiments">Experiments</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rnd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rnd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/joshcarp/ml-notes" title="GitHub Repository: joshcarp/ml-notes" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Papers</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="SuEHMbeMBy" class="relative group/block article-grid subgrid-gap col-screen"><p>A collection of papers with summaries and quick access links.</p><h2 id="paper-notes" class="relative group"><span class="heading-text">Paper Notes</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#paper-notes" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><figure id="PHZTJD7NXN" class="fig-table"><table><tbody><tr><th class="">Title</th><th class="">Tags</th><th class="">Full Notes</th></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2411.07191" target="_blank" rel="noreferrer" class="hover-link">The Super Weight in Large Language Models</a></cite></td><td class="">Model internals</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2410.02725" target="_blank" rel="noreferrer" class="hover-link">Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation</a></cite></td><td class=""></td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.03592" target="_blank" rel="noreferrer" class="hover-link">ReFT: Representation Finetuning for Language Models</a></cite></td><td class="">Fine-tuning, Model representations</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://doi.org/10.5555/2627435.2670313" rel="noreferrer">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></td><td class="">Model performance, Optimization, Model architecture</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.06111" target="_blank" rel="noreferrer" class="hover-link">Observation-based unit test generation at Meta</a></cite></td><td class="">Automated testing, Software engineering</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2403.20327" target="_blank" rel="noreferrer" class="hover-link">Gecko: Versatile Text Embeddings Distilled from Large Language Models</a></cite></td><td class="">Embeddings, Model distillation</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2210.07128" target="_blank" rel="noreferrer" class="hover-link">Language Models of Code are Few-Shot Commonsense Learners</a></cite></td><td class="">Code models, Transfer learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2407.10969" target="_blank" rel="noreferrer" class="hover-link">Q-Sparse: All Large Language Models can be Fully Sparsely-Activated</a></cite></td><td class="">Efficiency, Model performance</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2207.01780" target="_blank" rel="noreferrer" class="hover-link">CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning</a></cite></td><td class="">Code generation, Reinforcement learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2405.20541" target="_blank" rel="noreferrer" class="hover-link">Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</a></cite></td><td class="">Data pruning, Perplexity</td><td class=""><a href="/paper-notes/perplexity-based-data-pruning">Details</a></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.17764" target="_blank" rel="noreferrer" class="hover-link">The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits</a></cite></td><td class="">Hardware optimization, Model compression</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2305.17493" target="_blank" rel="noreferrer" class="hover-link">The Curse of Recursion: Training on Generated Data Makes Models Forget</a></cite></td><td class="">Model collapse, Training data</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html" rel="noreferrer">Chain of thought prompting</a></td><td class="">Prompting strategies</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.07143" target="_blank" rel="noreferrer" class="hover-link">Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</a></cite></td><td class="">Attention mechanisms, Context window</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.07496" target="_blank" rel="noreferrer" class="hover-link">TextGrad</a></cite></td><td class="">Agent systems, Text optimization</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.02528" target="_blank" rel="noreferrer" class="hover-link">Scalable MatMul-free Language Modeling</a></cite></td><td class="">Attention mechanisms, Model efficiency</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1712.00676" target="_blank" rel="noreferrer" class="hover-link">Will humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?</a></cite></td><td class="">AI in software development, Future of coding</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2311.17035" target="_blank" rel="noreferrer" class="hover-link">Scalable Extraction of Training Data from (Production) Language Models</a></cite></td><td class="">Data accumulation, Model performance, Curated datasets</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2305.07759" target="_blank" rel="noreferrer" class="hover-link">TinyStories: How Small Can Language Models Be and Still Speak Coherent English?</a></cite></td><td class="">Dataset creation, Small language models</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2311.12983" target="_blank" rel="noreferrer" class="hover-link">GAIA: A Benchmark for General AI Assistants</a></cite></td><td class="">AI assistants, Benchmarking</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.anthropic.com/news/mapping-mind-language-model" rel="noreferrer">Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet</a></td><td class="">Feature extraction, Interpretability</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.04692" target="_blank" rel="noreferrer" class="hover-link">Mixture-of-Agents Enhances Large Language Model Capabilities</a></cite></td><td class="">Model performance, Multi-agent systems</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2311.05884" target="_blank" rel="noreferrer" class="hover-link">Hiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems</a></cite></td><td class="">Transformers, Model architecture, Model performance</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2307.11760" target="_blank" rel="noreferrer" class="hover-link">Large Language Models Understand and Can Be Enhanced by Emotional Stimuli</a></cite></td><td class="">emotional stimuli, Model behavior</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.09171" target="_blank" rel="noreferrer" class="hover-link">Automated Unit Test Improvement using Large Language Models at Meta</a></cite></td><td class="">Automated testing, Software engineering</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.01413" target="_blank" rel="noreferrer" class="hover-link">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</a></cite></td><td class="">Data accumulation, Model collapse prevention</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2102.04518" target="_blank" rel="noreferrer" class="hover-link">A\ Search Without Expansions: Learning Heuristic Functions With Deep Q-Networks</a></cite></td><td class="">Reinforcement learning, Search algorithms</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.06196" target="_blank" rel="noreferrer" class="hover-link">Large Language Models: A Survey</a></cite></td><td class="">LLM capabilities, Survey</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.14433" target="_blank" rel="noreferrer" class="hover-link">A Language Model’s Guide Through Latent Space</a></cite></td><td class="">Interpretability, Latent space</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2205.05124" target="_blank" rel="noreferrer" class="hover-link">Extracting Latent Steering Vectors from Pretrained Language Models</a></cite></td><td class="">Interpretability, Latent space</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.anthropic.com/research/many-shot-jailbreaking" rel="noreferrer">Many-shot jailbreaking</a></td><td class="">Jailbreaking, Model safety</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1910.10683" target="_blank" rel="noreferrer" class="hover-link">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></cite></td><td class="">Transfer learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2308.10248" target="_blank" rel="noreferrer" class="hover-link">Activation Addition: Steering Language Models Without Optimization</a></cite></td><td class="">Activation manipulation, Model steering</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2107.03374" target="_blank" rel="noreferrer" class="hover-link">Evaluating Large Language Models Trained on Code</a></cite></td><td class="">Code generation, Model evaluation</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.02543" target="_blank" rel="noreferrer" class="hover-link">To Believe or Not to Believe Your LLM</a></cite></td><td class="">Hallucination detection, Uncertainty quantification</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.04692" target="_blank" rel="noreferrer" class="hover-link">Mixture of Agents</a></cite></td><td class="">Multi-agent systems, Prompting</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.14619" target="_blank" rel="noreferrer" class="hover-link">OpenELM: An Efficient Language Model Family with Open Training and Inference Framework</a></cite></td><td class="">Efficiency, Model architecture</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1706.03741" target="_blank" rel="noreferrer" class="hover-link">Deep Reinforcement Learning from Human Preferences</a></cite></td><td class="">human feedback, Reinforcement learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2307.08925" target="_blank" rel="noreferrer" class="hover-link">Federated Large Language Model: A Position Paper</a></cite></td><td class="">Distributed training, Federated learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2212.02508" target="_blank" rel="noreferrer" class="hover-link">MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning</a></cite></td><td class="">Music representation, Self-supervised learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2302.13971" target="_blank" rel="noreferrer" class="hover-link">LLaMA: Open and Efficient Foundation Language Models</a></cite></td><td class="">Model architecture, Open-source LLMs</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/" rel="noreferrer">Phi1: Textbooks Are All You Need</a></td><td class="">Curated datasets, Model efficiency</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1607.06450" target="_blank" rel="noreferrer" class="hover-link">Layer Normalization</a></cite></td><td class="">Model internals, Optimization</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1706.03762" target="_blank" rel="noreferrer" class="hover-link">Attention Is All You Need</a></cite></td><td class="">OG papers, Transformers</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.09412" target="_blank" rel="noreferrer" class="hover-link">Explore the Limits of Omni-modal Pretraining at Scale</a></cite></td><td class="">Multi-modal models, Pretraining</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1606.08415" target="_blank" rel="noreferrer" class="hover-link">Gaussian Error Linear Units (GELUs)</a></cite></td><td class="">Activation functions, Model internals</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2401.09796" target="_blank" rel="noreferrer" class="hover-link">A Fast, Performant, Secure Distributed Training Framework For Large Language Model</a></cite></td><td class="">Distributed training, Security</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1910.01108" target="_blank" rel="noreferrer" class="hover-link">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</a></cite></td><td class="">Efficiency, Model distillation</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="noreferrer">Improving Language Understanding by Generative Pre-Training</a></td><td class="">OG papers, Pre-training</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2203.02155" target="_blank" rel="noreferrer" class="hover-link">Training language models to follow instructions with human feedback</a></cite></td><td class="">Instruction following, Reinforcement learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2307.09288" target="_blank" rel="noreferrer" class="hover-link">Llama 2: Open Foundation and Fine-Tuned Chat Models</a></cite></td><td class="">Fine-tuning, Open-source LLMs</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2104.09864" target="_blank" rel="noreferrer" class="hover-link">RoFormer: Enhanced Transformer with Rotary Position Embedding</a></cite></td><td class="">Embeddings, Model architecture</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.nature.com/articles/s42256-023-00748-9" rel="noreferrer">Spatially embedded recurrent neural networks reveal widespread links between structural and functional neuroscience findings | Nature Machine Intelligence</a></td><td class="">Biological Brains</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.1111/tops.12737" target="_blank" rel="noreferrer" class="hover-link">Understanding Human Cognition Through Computational Modeling - Hsiao - 2024 - Topics in Cognitive Science - Wiley Online Library</a></cite></td><td class="">Biological Brains</td><td class=""></td></tr></tbody></table></figure></div><div></div><section id="references" class="article-grid subgrid-gap col-screen"><div><button class="float-right p-1 px-2 text-xs border rounded hover:border-blue-500 dark:hover:border-blue-400">Show All</button><header class="text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2411.07191">Yu, M., Wang, D., Shan, Q., Reed, C., & Wan, A. (2024). <i>The Super Weight in Large Language Models</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2411.07191">10.48550/ARXIV.2411.07191</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2410.02725">Manvi, R., Singh, A., & Ermon, S. (2024). <i>Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2410.02725">10.48550/ARXIV.2410.02725</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2404.03592">Wu, Z., Arora, A., Wang, Z., Geiger, A., Jurafsky, D., Manning, C. D., & Potts, C. (2024). <i>ReFT: Representation Finetuning for Language Models</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2404.03592">10.48550/ARXIV.2404.03592</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2402.06111">Alshahwan, N., Harman, M., Marginean, A., Tal, R., & Wang, E. (2024). <i>Observation-based unit test generation at Meta</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2402.06111">10.48550/ARXIV.2402.06111</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2403.20327">Lee, J., Dai, Z., Ren, X., Chen, B., Cer, D., Cole, J. R., Hui, K., Boratko, M., Kapadia, R., Ding, W., Luan, Y., Duddu, S. M. K., Abrego, G. H., Shi, W., Gupta, N., Kusupati, A., Jain, P., Jonnalagadda, S. R., Chang, M.-W., & Naim, I. (2024). <i>Gecko: Versatile Text Embeddings Distilled from Large Language Models</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2403.20327">10.48550/ARXIV.2403.20327</a></li><li class="text-center list-none"><button class="p-2 border rounded hover:border-blue-500 dark:hover:border-blue-400">Show all 46 references</button></li></ol></div></section><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/glossary/transformer-1"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>The Transformer</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/paper-notes/perplexity-based-data-pruning"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-JLDGA2DL.js"/><link rel="modulepreload" href="/build/_shared/chunk-YAIQ7LUU.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-ZQWAZXET.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-IQBJE7PC.js"/><link rel="modulepreload" href="/build/_shared/chunk-5CFTM6YW.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-HROFNPGU.js"/><link rel="modulepreload" href="/build/_shared/chunk-N544LW6X.js"/><link rel="modulepreload" href="/build/routes/$-WNZNXUO2.js"/><script>window.__remixContext = {"url":"/paper-notes","state":{"loaderData":{"root":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"},{"children":[{"file":"experiments/higher-abstract-reasoning.ipynb"}],"file":"experiments/index.md","title":"Experiments"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"experiments.index","title":"Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"experiments.higher-abstract-reasoning","title":"Transformers and Higher-Order Abstract Reasoning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"},{"children":[{"file":"experiments/higher-abstract-reasoning.ipynb"}],"file":"experiments/index.md","title":"Experiments"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"experiments.index","title":"Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"experiments.higher-abstract-reasoning","title":"Transformers and Higher-Order Abstract Reasoning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"kind":"Article","sha256":"de6f13421b9e894a3495f69d13e261da2b558605fa45aba906e17ebef11a1aea","slug":"paper-notes.index","location":"/paper-notes/index.md","dependencies":[],"frontmatter":{"title":"Papers","content_includes_title":false,"github":"https://github.com/joshcarp/ml-notes","exports":[{"format":"md","filename":"index.md","url":"/build/index-9dfa02596a7187a304c8eaa96ee86b22.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"A collection of papers with summaries and quick access links.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"sFqDceQGxz"}],"key":"p6s4VgFItw"},{"type":"heading","depth":2,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Paper Notes","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"uUTK7AdDMe"}],"identifier":"paper-notes","label":"Paper Notes","html_id":"paper-notes","implicit":true,"key":"XTZQl3354V"},{"type":"container","kind":"table","children":[{"type":"table","children":[{"type":"tableRow","children":[{"type":"tableCell","header":true,"children":[{"type":"text","value":"Title","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"DikmlvynJ4"}],"key":"q0eku8zsm0"},{"type":"tableCell","header":true,"children":[{"type":"text","value":"Tags","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"bJXMt0khHc"}],"key":"NRR4tIZZRT"},{"type":"tableCell","header":true,"children":[{"type":"text","value":"Full Notes","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"oz5kxLs1x5"}],"key":"k3z8QSFYk5"}],"key":"cjDuZcV36a"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2411.07191","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"The Super Weight in Large Language Models","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"ST4I5D77ij"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2411.07191","identifier":"https://doi.org/10.48550/arXiv.2411.07191","enumerator":"1","key":"rRBCop1jbq"}],"key":"eDc11YmRvu"},{"type":"tableCell","children":[{"type":"text","value":"Model internals","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"dj3jjU2mjI"}],"key":"EMNuhHEvDh"},{"type":"tableCell","children":[],"key":"BCPDkKnWLq"}],"key":"DHCHEQjGql"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2410.02725","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"lCGCZZDGuh"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2410.02725","identifier":"https://doi.org/10.48550/arXiv.2410.02725","enumerator":"2","key":"USOOnOR72E"}],"key":"PSZ9uckftr"},{"type":"tableCell","children":[],"key":"xWNxBOuDUk"},{"type":"tableCell","children":[],"key":"TUbY75rO7n"}],"key":"qNxjXWdvAn"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.03592","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"ReFT: Representation Finetuning for Language Models","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"eGX92iRx4H"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.03592","identifier":"https://doi.org/10.48550/arXiv.2404.03592","enumerator":"3","key":"XpdCVeAAJg"}],"key":"nTkExnqnTE"},{"type":"tableCell","children":[{"type":"text","value":"Fine-tuning, Model representations","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"QDo7AT1GR5"}],"key":"NptGRX8v5G"},{"type":"tableCell","children":[],"key":"c4QaHduIFc"}],"key":"bfmQC0GQzN"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://doi.org/10.5555/2627435.2670313","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Dropout: A Simple Way to Prevent Neural Networks from Overfitting","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"RhGyqAQg3o"}],"urlSource":"https://dl.acm.org/doi/abs/10.5555/2627435.2670313","data":{"doi":"10.5555/2627435.2670313"},"internal":false,"protocol":"doi","key":"jUPqDUerqr"}],"key":"Fyamex27Kh"},{"type":"tableCell","children":[{"type":"text","value":"Model performance, Optimization, Model architecture","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"jKBlApH0gF"}],"key":"CQmFBGET2x"},{"type":"tableCell","children":[],"key":"LkgQfIhgJ9"}],"key":"fwZqT3GMZI"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.06111","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Observation-based unit test generation at Meta","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"HBSmwi2upR"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.06111","identifier":"https://doi.org/10.48550/arXiv.2402.06111","enumerator":"4","key":"muBgdcgoiQ"}],"key":"YRHnR3KIVu"},{"type":"tableCell","children":[{"type":"text","value":"Automated testing, Software engineering","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"zMPlR9lxRg"}],"key":"x8rZiWfVDa"},{"type":"tableCell","children":[],"key":"nygyC9cI7c"}],"key":"aqRDNGuKfY"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2403.20327","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"Gecko: Versatile Text Embeddings Distilled from Large Language Models","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"uT1qJWfg5a"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2403.20327","identifier":"https://doi.org/10.48550/arXiv.2403.20327","enumerator":"5","key":"pYJnrKV6qp"}],"key":"uArMy80DlZ"},{"type":"tableCell","children":[{"type":"text","value":"Embeddings, Model distillation","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"ptmKJwOZen"}],"key":"wT6126QgFm"},{"type":"tableCell","children":[],"key":"EmwcF7Tqnm"}],"key":"A3r8cHV7Lh"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2210.07128","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Language Models of Code are Few-Shot Commonsense Learners","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"aSArdTkSQm"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2210.07128","identifier":"https://doi.org/10.48550/arXiv.2210.07128","enumerator":"6","key":"lGUsh9DeF8"}],"key":"oW9j3xBpEd"},{"type":"tableCell","children":[{"type":"text","value":"Code models, Transfer learning","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"YNG4JvyFDm"}],"key":"QDZyXRsGK3"},{"type":"tableCell","children":[],"key":"KA5LvhZELB"}],"key":"a5waWt2WeC"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2407.10969","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Q-Sparse: All Large Language Models can be Fully Sparsely-Activated","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"nLswz631et"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2407.10969","identifier":"https://doi.org/10.48550/arXiv.2407.10969","enumerator":"7","key":"UD8CoQnszf"}],"key":"J1uJyHE2Kr"},{"type":"tableCell","children":[{"type":"text","value":"Efficiency, Model performance","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"R6TGL2f5Qs"}],"key":"vQx88daOJ4"},{"type":"tableCell","children":[],"key":"ylNKweoULf"}],"key":"T52E75mrWw"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2207.01780","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"HQDzqCMz9A"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2207.01780","identifier":"https://doi.org/10.48550/arXiv.2207.01780","enumerator":"8","key":"qRUGzsLxBF"}],"key":"HzmzXFzjd5"},{"type":"tableCell","children":[{"type":"text","value":"Code generation, Reinforcement learning","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"ttEWUBRYrF"}],"key":"pIc1AdIVF2"},{"type":"tableCell","children":[],"key":"kYLAMH3oza"}],"key":"LNVbA9BkxG"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2405.20541","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"PQT18RGIOT"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2405.20541","identifier":"https://doi.org/10.48550/arXiv.2405.20541","enumerator":"9","key":"ycuhuH91to"}],"key":"tMf880rFSJ"},{"type":"tableCell","children":[{"type":"text","value":"Data pruning, Perplexity","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"EofX4oWTFc"}],"key":"Q8VudPNhN5"},{"type":"tableCell","children":[{"type":"link","url":"/paper-notes/perplexity-based-data-pruning","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"Details","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"qvy9KERhDZ"}],"urlSource":"perplexity-based-data-pruning","dataUrl":"/paper-notes.perplexity-based-data-pruning.json","internal":true,"protocol":"file","key":"ZeEiAZsCHl"}],"key":"s0Aftv3rQW"}],"key":"tJKH6U4jua"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.17764","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"vHLD7HkUAR"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.17764","identifier":"https://doi.org/10.48550/arXiv.2402.17764","enumerator":"10","key":"cPXeKQHczx"}],"key":"qmcx3DCyMt"},{"type":"tableCell","children":[{"type":"text","value":"Hardware optimization, Model compression","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"zH2eL0xW5L"}],"key":"yvvmkRWUnl"},{"type":"tableCell","children":[],"key":"GVp3K5sFKm"}],"key":"tX3xiquH4e"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2305.17493","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"The Curse of Recursion: Training on Generated Data Makes Models Forget","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"tfqgumbN8H"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2305.17493","identifier":"https://doi.org/10.48550/arXiv.2305.17493","enumerator":"11","key":"WGRj84SKsh"}],"key":"f9Bgbphfu5"},{"type":"tableCell","children":[{"type":"text","value":"Model collapse, Training data","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"LWE9bG1tew"}],"key":"i4oZspCSxF"},{"type":"tableCell","children":[],"key":"sxQAcTLOLc"}],"key":"AmvPh6PzRO"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Chain of thought prompting","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"W3tPa0s3dT"}],"urlSource":"https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html","key":"t7g0rvlZJa"}],"key":"V78lJPKpMP"},{"type":"tableCell","children":[{"type":"text","value":"Prompting strategies","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"cAzS2TDcDQ"}],"key":"uaNKGo3vZ2"},{"type":"tableCell","children":[],"key":"dD7xK2o7dn"}],"key":"DjS909NYFN"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.07143","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"uX58rlq2fi"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.07143","identifier":"https://doi.org/10.48550/arXiv.2404.07143","enumerator":"12","key":"X3ZHFMO96D"}],"key":"K1MNCdYNxl"},{"type":"tableCell","children":[{"type":"text","value":"Attention mechanisms, Context window","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"IOUobjhWPr"}],"key":"MJJQxibB8P"},{"type":"tableCell","children":[],"key":"chl47mbJGe"}],"key":"HJBB1DDsG7"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.07496","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"TextGrad","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"LkdvvU9Yq5"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.07496","identifier":"https://doi.org/10.48550/arXiv.2406.07496","enumerator":"13","key":"m3fpIvE8x1"}],"key":"YGSynASzzH"},{"type":"tableCell","children":[{"type":"text","value":"Agent systems, Text optimization","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"mOav5viMBo"}],"key":"R0pbapGhVU"},{"type":"tableCell","children":[],"key":"h4kVn0w5KB"}],"key":"zhv6Ai5kMK"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.02528","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"Scalable MatMul-free Language Modeling","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"uddQ7fWhOu"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.02528","identifier":"https://doi.org/10.48550/arXiv.2406.02528","enumerator":"14","key":"jeeMY053jX"}],"key":"V6TW0b4rgM"},{"type":"tableCell","children":[{"type":"text","value":"Attention mechanisms, Model efficiency","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"ZHifpVGR2t"}],"key":"H9pPFz0KGF"},{"type":"tableCell","children":[],"key":"wagPHezVmn"}],"key":"Mqbx59e35O"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1712.00676","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"Will humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"AKpG24p62E"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1712.00676","identifier":"https://doi.org/10.48550/arXiv.1712.00676","enumerator":"15","key":"qa4O0wFpTS"}],"key":"HW4Tbq8Wn9"},{"type":"tableCell","children":[{"type":"text","value":"AI in software development, Future of coding","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"gAkPryDh6A"}],"key":"ZbS2i0PWhX"},{"type":"tableCell","children":[],"key":"cFN8Mh9uKX"}],"key":"a5E2uObaIO"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2311.17035","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"Scalable Extraction of Training Data from (Production) Language Models","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"BeNYjJRwEF"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2311.17035","identifier":"https://doi.org/10.48550/arXiv.2311.17035","enumerator":"16","key":"CUKVXYa44L"}],"key":"eYKqEO64Df"},{"type":"tableCell","children":[{"type":"text","value":"Data accumulation, Model performance, Curated datasets","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"hPWEg8YaT8"}],"key":"txv6PDbfDd"},{"type":"tableCell","children":[],"key":"jyaTfFh4YE"}],"key":"CONCHczNnd"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2305.07759","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"TinyStories: How Small Can Language Models Be and Still Speak Coherent English?","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"R95NvOLvbe"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2305.07759","identifier":"https://doi.org/10.48550/arXiv.2305.07759","enumerator":"17","key":"xK3MnpdJ2v"}],"key":"t7U7VUA391"},{"type":"tableCell","children":[{"type":"text","value":"Dataset creation, Small language models","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"F71Axw66cs"}],"key":"Sh6JiHmHSi"},{"type":"tableCell","children":[],"key":"s90bstOnPG"}],"key":"qauLmkQet5"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2311.12983","position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"text","value":"GAIA: A Benchmark for General AI Assistants","position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"key":"Inxap4BUND"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2311.12983","identifier":"https://doi.org/10.48550/arXiv.2311.12983","enumerator":"18","key":"wF4DHSjqu2"}],"key":"WQd4LzN86l"},{"type":"tableCell","children":[{"type":"text","value":"AI assistants, Benchmarking","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"ZuRRQuMzzo"}],"key":"gcOBJL3vHM"},{"type":"tableCell","children":[],"key":"EAoi3zUZUP"}],"key":"MIrvTfAEA4"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.anthropic.com/news/mapping-mind-language-model","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"text","value":"Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"IXEDuuukmH"}],"urlSource":"https://www.anthropic.com/news/mapping-mind-language-model","key":"HUFmdRCgut"}],"key":"jUo4apsa3R"},{"type":"tableCell","children":[{"type":"text","value":"Feature extraction, Interpretability","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"gFMCcr8abW"}],"key":"ePsPSaUmdH"},{"type":"tableCell","children":[],"key":"jaT3NHf7an"}],"key":"pMGxLmFt6V"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.04692","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"Mixture-of-Agents Enhances Large Language Model Capabilities","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"ebOOlDJxRr"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.04692","identifier":"https://doi.org/10.48550/arXiv.2406.04692","enumerator":"19","key":"pnQizaykuQ"}],"key":"WtbPTyEVzs"},{"type":"tableCell","children":[{"type":"text","value":"Model performance, Multi-agent systems","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"O76Pkib0rz"}],"key":"AI8Pq8Jyzj"},{"type":"tableCell","children":[],"key":"nLZiHU4q87"}],"key":"E3NKA2MRj7"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2311.05884","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"text","value":"Hiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"key":"Td894LP7Cd"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2311.05884","identifier":"https://doi.org/10.48550/arXiv.2311.05884","enumerator":"20","key":"EZYsFTIXFX"}],"key":"WBI9MYwtSZ"},{"type":"tableCell","children":[{"type":"text","value":"Transformers, Model architecture, Model performance","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"PYfxx0yzaS"}],"key":"RHvCct6DzL"},{"type":"tableCell","children":[],"key":"ODtKPvsvtD"}],"key":"FmP2cxFJss"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2307.11760","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"text","value":"Large Language Models Understand and Can Be Enhanced by Emotional Stimuli","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"key":"TMi2qQvTRA"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2307.11760","identifier":"https://doi.org/10.48550/arXiv.2307.11760","enumerator":"21","key":"ujpKHW9gU1"}],"key":"LFGENdZz7g"},{"type":"tableCell","children":[{"type":"text","value":"emotional stimuli, Model behavior","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"key":"d2ICBdNzPA"}],"key":"bEOjCnFDyV"},{"type":"tableCell","children":[],"key":"KwuHdAdi0X"}],"key":"AvU7DO6ZZY"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.09171","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"text","value":"Automated Unit Test Improvement using Large Language Models at Meta","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"key":"GCaLKvbnQB"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.09171","identifier":"https://doi.org/10.48550/arXiv.2402.09171","enumerator":"22","key":"lQ2jeXdNdT"}],"key":"Jo5ccJ9H6J"},{"type":"tableCell","children":[{"type":"text","value":"Automated testing, Software engineering","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"key":"X16jUGAh12"}],"key":"GKLrgoOf8t"},{"type":"tableCell","children":[],"key":"m9gJk19SiM"}],"key":"OtTATkG4Bx"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.01413","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"children":[{"type":"text","value":"Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"key":"UtpF2sUHUS"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.01413","identifier":"https://doi.org/10.48550/arXiv.2404.01413","enumerator":"23","key":"dPgiMpFGII"}],"key":"o92cwk1rc8"},{"type":"tableCell","children":[{"type":"text","value":"Data accumulation, Model collapse prevention","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"r3HqHwf33I"}],"key":"MiqgYFijvi"},{"type":"tableCell","children":[],"key":"yM5B67shDI"}],"key":"vw4DnS7VAO"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2102.04518","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"children":[{"type":"text","value":"A\\ Search Without Expansions: Learning Heuristic Functions With Deep Q-Networks","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"key":"Squw2u36C2"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2102.04518","identifier":"https://doi.org/10.48550/arXiv.2102.04518","enumerator":"24","key":"TjdnlKWYIi"}],"key":"P80WAWGt0y"},{"type":"tableCell","children":[{"type":"text","value":"Reinforcement learning, Search algorithms","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"F2repNvwRs"}],"key":"mPH5kqXsDo"},{"type":"tableCell","children":[],"key":"JGT49MfAtS"}],"key":"zb69fT3NQP"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.06196","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"children":[{"type":"text","value":"Large Language Models: A Survey","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"key":"vCmaXquylH"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.06196","identifier":"https://doi.org/10.48550/arXiv.2402.06196","enumerator":"25","key":"JCXGen8Bnn"}],"key":"AxNM2nqsJ3"},{"type":"tableCell","children":[{"type":"text","value":"LLM capabilities, Survey","position":{"start":{"line":95,"column":1},"end":{"line":95,"column":1}},"key":"sZDkenwHw7"}],"key":"h9XIgdh18S"},{"type":"tableCell","children":[],"key":"tfo9XTdwOn"}],"key":"HGbD2p31Yj"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.14433","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"children":[{"type":"text","value":"A Language Model’s Guide Through Latent Space","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"z40YS2l9e6"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.14433","identifier":"https://doi.org/10.48550/arXiv.2402.14433","enumerator":"26","key":"AcZx8HPT1S"}],"key":"DsVnEs4HdY"},{"type":"tableCell","children":[{"type":"text","value":"Interpretability, Latent space","position":{"start":{"line":98,"column":1},"end":{"line":98,"column":1}},"key":"Zb0uRtw7HD"}],"key":"Ow1mE6YLMc"},{"type":"tableCell","children":[],"key":"nyLyADo0GH"}],"key":"INrvWY4SxK"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2205.05124","position":{"start":{"line":100,"column":1},"end":{"line":100,"column":1}},"children":[{"type":"text","value":"Extracting Latent Steering Vectors from Pretrained Language Models","position":{"start":{"line":100,"column":1},"end":{"line":100,"column":1}},"key":"Ov9V5cbxLS"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2205.05124","identifier":"https://doi.org/10.48550/arXiv.2205.05124","enumerator":"27","key":"wMJGgjTvNI"}],"key":"k8IJrj8Zno"},{"type":"tableCell","children":[{"type":"text","value":"Interpretability, Latent space","position":{"start":{"line":101,"column":1},"end":{"line":101,"column":1}},"key":"eXF96G339C"}],"key":"GE6xZsmKd1"},{"type":"tableCell","children":[],"key":"gMwCdSHhJC"}],"key":"YoaJnZWHc7"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.anthropic.com/research/many-shot-jailbreaking","position":{"start":{"line":103,"column":1},"end":{"line":103,"column":1}},"children":[{"type":"text","value":"Many-shot jailbreaking","position":{"start":{"line":103,"column":1},"end":{"line":103,"column":1}},"key":"Upbzvn7IME"}],"urlSource":"https://www.anthropic.com/research/many-shot-jailbreaking","key":"Gbd1XB574a"}],"key":"W3TgT4UeWh"},{"type":"tableCell","children":[{"type":"text","value":"Jailbreaking, Model safety","position":{"start":{"line":104,"column":1},"end":{"line":104,"column":1}},"key":"nVVK798Y24"}],"key":"Puubzgpnka"},{"type":"tableCell","children":[],"key":"U9hl7xarKu"}],"key":"re2j3uAefn"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1910.10683","position":{"start":{"line":106,"column":1},"end":{"line":106,"column":1}},"children":[{"type":"text","value":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer","position":{"start":{"line":106,"column":1},"end":{"line":106,"column":1}},"key":"rVikCkSIF7"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1910.10683","identifier":"https://doi.org/10.48550/arXiv.1910.10683","enumerator":"28","key":"vkNvBEduSg"}],"key":"Md9xTGr17N"},{"type":"tableCell","children":[{"type":"text","value":"Transfer learning","position":{"start":{"line":107,"column":1},"end":{"line":107,"column":1}},"key":"mdOGMyZiPo"}],"key":"wN44NpFq7c"},{"type":"tableCell","children":[],"key":"zuPrVTwKKp"}],"key":"q28PZ1zK7s"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2308.10248","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"Activation Addition: Steering Language Models Without Optimization","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"oYP5Db676l"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2308.10248","identifier":"https://doi.org/10.48550/arXiv.2308.10248","enumerator":"29","key":"b6TI2EhBvB"}],"key":"dpgHhl69yl"},{"type":"tableCell","children":[{"type":"text","value":"Activation manipulation, Model steering","position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"key":"grsvCF9daQ"}],"key":"sSFVZtiIIW"},{"type":"tableCell","children":[],"key":"uj0qsiGf6G"}],"key":"yK0L7HQGVa"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2107.03374","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"children":[{"type":"text","value":"Evaluating Large Language Models Trained on Code","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"xQYL1jKj0T"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2107.03374","identifier":"https://doi.org/10.48550/arXiv.2107.03374","enumerator":"30","key":"sCD5YxOzoI"}],"key":"h5Go0QAuqV"},{"type":"tableCell","children":[{"type":"text","value":"Code generation, Model evaluation","position":{"start":{"line":113,"column":1},"end":{"line":113,"column":1}},"key":"JfWb2RcNhS"}],"key":"m2oYOUq1Ml"},{"type":"tableCell","children":[],"key":"APNfK4mTVl"}],"key":"OPFN02ITTA"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.02543","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"children":[{"type":"text","value":"To Believe or Not to Believe Your LLM","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"key":"cEX3MOvRLl"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.02543","identifier":"https://doi.org/10.48550/arXiv.2406.02543","enumerator":"31","key":"BTDuDuUPFJ"}],"key":"GKOwANntRi"},{"type":"tableCell","children":[{"type":"text","value":"Hallucination detection, Uncertainty quantification","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"OenMmLQRwi"}],"key":"Ggs2vKQszN"},{"type":"tableCell","children":[],"key":"ONGHCY6fQo"}],"key":"jAkDOBfKgE"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.04692","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"children":[{"type":"text","value":"Mixture of Agents","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"key":"kM64U1ONRu"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.04692","identifier":"https://doi.org/10.48550/arXiv.2406.04692","enumerator":"19","key":"IJ9HFnm1Kx"}],"key":"eJYj3yfest"},{"type":"tableCell","children":[{"type":"text","value":"Multi-agent systems, Prompting","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"key":"EQOcv4hU1C"}],"key":"b7setvguSY"},{"type":"tableCell","children":[],"key":"bRo6Kx0R4J"}],"key":"cp4fIzQ3wW"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.14619","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"children":[{"type":"text","value":"OpenELM: An Efficient Language Model Family with Open Training and Inference Framework","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"key":"MSYsw3ubkD"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.14619","identifier":"https://doi.org/10.48550/arXiv.2404.14619","enumerator":"32","key":"k3XJmEFEqu"}],"key":"JkYCZbWfSg"},{"type":"tableCell","children":[{"type":"text","value":"Efficiency, Model architecture","position":{"start":{"line":122,"column":1},"end":{"line":122,"column":1}},"key":"El35A4rRdI"}],"key":"dhmpY7TdQE"},{"type":"tableCell","children":[],"key":"uaRhGs1l6s"}],"key":"RTXObgPImt"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1706.03741","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"text","value":"Deep Reinforcement Learning from Human Preferences","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"rvTmlDLJd3"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1706.03741","identifier":"https://doi.org/10.48550/arXiv.1706.03741","enumerator":"33","key":"SlMCHETmA1"}],"key":"Y1wo4C8hHo"},{"type":"tableCell","children":[{"type":"text","value":"human feedback, Reinforcement learning","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":1}},"key":"W6QvNpNI45"}],"key":"vPXXjLjBlR"},{"type":"tableCell","children":[],"key":"qPK4RPRyO0"}],"key":"BnLsWGnAXo"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2307.08925","position":{"start":{"line":127,"column":1},"end":{"line":127,"column":1}},"children":[{"type":"text","value":"Federated Large Language Model: A Position Paper","position":{"start":{"line":127,"column":1},"end":{"line":127,"column":1}},"key":"jYHRFSGhgT"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2307.08925","identifier":"https://doi.org/10.48550/arXiv.2307.08925","enumerator":"34","key":"XVuMoz6zHH"}],"key":"fv6smEPzwq"},{"type":"tableCell","children":[{"type":"text","value":"Distributed training, Federated learning","position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"key":"DgJhGRcJz6"}],"key":"yRq6Mr6GYv"},{"type":"tableCell","children":[],"key":"HzSA6MRGRx"}],"key":"WY7WrDxEBW"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2212.02508","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"children":[{"type":"text","value":"MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"key":"T1jnNRllt5"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2212.02508","identifier":"https://doi.org/10.48550/arXiv.2212.02508","enumerator":"35","key":"jPGRPkMFcC"}],"key":"WClpdRP96l"},{"type":"tableCell","children":[{"type":"text","value":"Music representation, Self-supervised learning","position":{"start":{"line":131,"column":1},"end":{"line":131,"column":1}},"key":"hNS4YhbDlY"}],"key":"TDwy5PeFkR"},{"type":"tableCell","children":[],"key":"Mixf6Y4SUr"}],"key":"MTnLwp3QRe"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2302.13971","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"children":[{"type":"text","value":"LLaMA: Open and Efficient Foundation Language Models","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"key":"IAQNt5Wh1j"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2302.13971","identifier":"https://doi.org/10.48550/arXiv.2302.13971","enumerator":"36","key":"aA3TYtS3VB"}],"key":"CYSM0pkFL2"},{"type":"tableCell","children":[{"type":"text","value":"Model architecture, Open-source LLMs","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"KKUma7cGLY"}],"key":"f9ReUJpTMg"},{"type":"tableCell","children":[],"key":"CaX6oovJzN"}],"key":"oA5NglmRWT"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"text","value":"Phi1: Textbooks Are All You Need","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"RU7ffE6pB3"}],"urlSource":"https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/","key":"s2EjccsPUh"}],"key":"D1vqQefDWq"},{"type":"tableCell","children":[{"type":"text","value":"Curated datasets, Model efficiency","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"c6B7rHaAgf"}],"key":"hGv1CFYuRB"},{"type":"tableCell","children":[],"key":"KV6FaHJM1H"}],"key":"EPytYqOjdt"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1607.06450","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"children":[{"type":"text","value":"Layer Normalization","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"key":"cQYVxOn3mf"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1607.06450","identifier":"https://doi.org/10.48550/arXiv.1607.06450","enumerator":"37","key":"cEzWlEUKRu"}],"key":"WjIuVdEBFB"},{"type":"tableCell","children":[{"type":"text","value":"Model internals, Optimization","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"key":"J80cAaiwy7"}],"key":"zGIoKiWHH5"},{"type":"tableCell","children":[],"key":"v0sp5do42R"}],"key":"tHiL2ZfO3k"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1706.03762","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"children":[{"type":"text","value":"Attention Is All You Need","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"key":"QUenAGO6Ub"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1706.03762","identifier":"https://doi.org/10.48550/arXiv.1706.03762","enumerator":"38","key":"baB0L9XfEB"}],"key":"qTBBTAq6xK"},{"type":"tableCell","children":[{"type":"text","value":"OG papers, Transformers","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"DYbOdD0xc5"}],"key":"Xl07Z5ZjKY"},{"type":"tableCell","children":[],"key":"QrsszRIT4t"}],"key":"gebLGoKVeC"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.09412","position":{"start":{"line":145,"column":1},"end":{"line":145,"column":1}},"children":[{"type":"text","value":"Explore the Limits of Omni-modal Pretraining at Scale","position":{"start":{"line":145,"column":1},"end":{"line":145,"column":1}},"key":"Odfc7JihNl"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.09412","identifier":"https://doi.org/10.48550/arXiv.2406.09412","enumerator":"39","key":"vBInJtsrec"}],"key":"FyuYSl2M7q"},{"type":"tableCell","children":[{"type":"text","value":"Multi-modal models, Pretraining","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"ron8ewJRRS"}],"key":"LrrxLFL0EU"},{"type":"tableCell","children":[],"key":"wZ2UpoIGVN"}],"key":"tpsifwvP0f"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1606.08415","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"children":[{"type":"text","value":"Gaussian Error Linear Units (GELUs)","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"key":"AcMWH3ShhJ"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1606.08415","identifier":"https://doi.org/10.48550/arXiv.1606.08415","enumerator":"40","key":"gFCEUdzpvE"}],"key":"pUP7pu7APQ"},{"type":"tableCell","children":[{"type":"text","value":"Activation functions, Model internals","position":{"start":{"line":149,"column":1},"end":{"line":149,"column":1}},"key":"I3xnQKevm6"}],"key":"i7H5vr5sMf"},{"type":"tableCell","children":[],"key":"e993koPLCK"}],"key":"YcKAu7CoXd"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2401.09796","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"children":[{"type":"text","value":"A Fast, Performant, Secure Distributed Training Framework For Large Language Model","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"key":"LQVNulpXqB"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2401.09796","identifier":"https://doi.org/10.48550/arXiv.2401.09796","enumerator":"41","key":"lVry4zTbEu"}],"key":"SYfmofNvk2"},{"type":"tableCell","children":[{"type":"text","value":"Distributed training, Security","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"oML1Fvyxzy"}],"key":"WFg4nIHKnX"},{"type":"tableCell","children":[],"key":"jvTl1RJwSU"}],"key":"q65Skvk7BC"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1910.01108","position":{"start":{"line":154,"column":1},"end":{"line":154,"column":1}},"children":[{"type":"text","value":"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter","position":{"start":{"line":154,"column":1},"end":{"line":154,"column":1}},"key":"G4p6FFRlyj"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1910.01108","identifier":"https://doi.org/10.48550/arXiv.1910.01108","enumerator":"42","key":"ybdz3MgazD"}],"key":"jV10sY4cla"},{"type":"tableCell","children":[{"type":"text","value":"Efficiency, Model distillation","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"C6By0Ewf1y"}],"key":"Mqe78qGvGh"},{"type":"tableCell","children":[],"key":"HbACQixNbv"}],"key":"ssaA3Njpg4"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","position":{"start":{"line":157,"column":1},"end":{"line":157,"column":1}},"children":[{"type":"text","value":"Improving Language Understanding by Generative Pre-Training","position":{"start":{"line":157,"column":1},"end":{"line":157,"column":1}},"key":"vXpNCoNEvU"}],"urlSource":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","key":"dBHnn3qXql"}],"key":"HAVfFYzKfY"},{"type":"tableCell","children":[{"type":"text","value":"OG papers, Pre-training","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"key":"xX0ienFl7O"}],"key":"zluyu7K4Wn"},{"type":"tableCell","children":[],"key":"nK7dXSfxf7"}],"key":"tai04gkvKr"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2203.02155","position":{"start":{"line":160,"column":1},"end":{"line":160,"column":1}},"children":[{"type":"text","value":"Training language models to follow instructions with human feedback","position":{"start":{"line":160,"column":1},"end":{"line":160,"column":1}},"key":"OUSNkaRWBn"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2203.02155","identifier":"https://doi.org/10.48550/arXiv.2203.02155","enumerator":"43","key":"cdDy4BdDef"}],"key":"pQLivCadf2"},{"type":"tableCell","children":[{"type":"text","value":"Instruction following, Reinforcement learning","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"key":"cG6OAdYduW"}],"key":"wPcpAQ5zjB"},{"type":"tableCell","children":[],"key":"MMLrC61Mwv"}],"key":"HL2WdgWCY6"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2307.09288","position":{"start":{"line":163,"column":1},"end":{"line":163,"column":1}},"children":[{"type":"text","value":"Llama 2: Open Foundation and Fine-Tuned Chat Models","position":{"start":{"line":163,"column":1},"end":{"line":163,"column":1}},"key":"pjyxtXaEt4"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2307.09288","identifier":"https://doi.org/10.48550/arXiv.2307.09288","enumerator":"44","key":"bZIpShuyEB"}],"key":"pQhpi8HANH"},{"type":"tableCell","children":[{"type":"text","value":"Fine-tuning, Open-source LLMs","position":{"start":{"line":164,"column":1},"end":{"line":164,"column":1}},"key":"fR9hnaTaGu"}],"key":"qsRUEppmIM"},{"type":"tableCell","children":[],"key":"RcJp3YFf6A"}],"key":"dvaOOQ32Vf"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2104.09864","position":{"start":{"line":166,"column":1},"end":{"line":166,"column":1}},"children":[{"type":"text","value":"RoFormer: Enhanced Transformer with Rotary Position Embedding","position":{"start":{"line":166,"column":1},"end":{"line":166,"column":1}},"key":"T45UOhpJYn"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2104.09864","identifier":"https://doi.org/10.48550/arXiv.2104.09864","enumerator":"45","key":"uT9XJCGjJP"}],"key":"PWdTeStF1r"},{"type":"tableCell","children":[{"type":"text","value":"Embeddings, Model architecture","position":{"start":{"line":167,"column":1},"end":{"line":167,"column":1}},"key":"OnxFaMPN2f"}],"key":"XZZj2ipbqP"},{"type":"tableCell","children":[],"key":"I9mrdDXl4Y"}],"key":"X1dxv8GRnT"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.nature.com/articles/s42256-023-00748-9","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"children":[{"type":"text","value":"Spatially embedded recurrent neural networks reveal widespread links between structural and functional neuroscience findings | Nature Machine Intelligence","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"key":"j1kGomOENL"}],"urlSource":"https://www.nature.com/articles/s42256-023-00748-9","key":"yA0x7a3HZX"}],"key":"dczRMKeFGX"},{"type":"tableCell","children":[{"type":"text","value":"Biological Brains","position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"key":"qGSlZRTNbF"}],"key":"ceuOVsKa7T"},{"type":"tableCell","children":[],"key":"zqTB8c2YQo"}],"key":"NcPeGvrDkJ"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://onlinelibrary.wiley.com/doi/10.1111/tops.12737","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"children":[{"type":"text","value":"Understanding Human Cognition Through Computational Modeling - Hsiao - 2024 - Topics in Cognitive Science - Wiley Online Library","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"key":"prKO2Fq5li"}],"kind":"narrative","label":"Hsiao_2024","identifier":"https://onlinelibrary.wiley.com/doi/10.1111/tops.12737","enumerator":"46","key":"PC1a0ZTJbO"}],"key":"izGs0YmTCN"},{"type":"tableCell","children":[{"type":"text","value":"Biological Brains","position":{"start":{"line":173,"column":1},"end":{"line":173,"column":1}},"key":"dJQB741Tmq"}],"key":"FGEJ7QDNCM"},{"type":"tableCell","children":[],"key":"NEAb6KjJTw"}],"key":"du8D04EGTY"}],"key":"vgdhF1ZTLu"}],"enumerator":"1","key":"PHZTJD7NXN"}],"key":"SuEHMbeMBy"}],"key":"eDuiPGeUEP"},"references":{"cite":{"order":["https://doi.org/10.48550/arxiv.2411.07191","https://doi.org/10.48550/arxiv.2410.02725","https://doi.org/10.48550/arxiv.2404.03592","https://doi.org/10.48550/arxiv.2402.06111","https://doi.org/10.48550/arxiv.2403.20327","https://doi.org/10.48550/arxiv.2210.07128","https://doi.org/10.48550/arxiv.2407.10969","https://doi.org/10.48550/arxiv.2207.01780","https://doi.org/10.48550/arxiv.2405.20541","https://doi.org/10.48550/arxiv.2402.17764","https://doi.org/10.48550/arxiv.2305.17493","https://doi.org/10.48550/arxiv.2404.07143","https://doi.org/10.48550/arxiv.2406.07496","https://doi.org/10.48550/arxiv.2406.02528","https://doi.org/10.48550/arxiv.1712.00676","https://doi.org/10.48550/arxiv.2311.17035","https://doi.org/10.48550/arxiv.2305.07759","https://doi.org/10.48550/arxiv.2311.12983","https://doi.org/10.48550/arxiv.2406.04692","https://doi.org/10.48550/arxiv.2311.05884","https://doi.org/10.48550/arxiv.2307.11760","https://doi.org/10.48550/arxiv.2402.09171","https://doi.org/10.48550/arxiv.2404.01413","https://doi.org/10.48550/arxiv.2102.04518","https://doi.org/10.48550/arxiv.2402.06196","https://doi.org/10.48550/arxiv.2402.14433","https://doi.org/10.48550/arxiv.2205.05124","https://doi.org/10.48550/arxiv.1910.10683","https://doi.org/10.48550/arxiv.2308.10248","https://doi.org/10.48550/arxiv.2107.03374","https://doi.org/10.48550/arxiv.2406.02543","https://doi.org/10.48550/arxiv.2404.14619","https://doi.org/10.48550/arxiv.1706.03741","https://doi.org/10.48550/arxiv.2307.08925","https://doi.org/10.48550/arxiv.2212.02508","https://doi.org/10.48550/arxiv.2302.13971","https://doi.org/10.48550/arxiv.1607.06450","https://doi.org/10.48550/arxiv.1706.03762","https://doi.org/10.48550/arxiv.2406.09412","https://doi.org/10.48550/arxiv.1606.08415","https://doi.org/10.48550/arxiv.2401.09796","https://doi.org/10.48550/arxiv.1910.01108","https://doi.org/10.48550/arxiv.2203.02155","https://doi.org/10.48550/arxiv.2307.09288","https://doi.org/10.48550/arxiv.2104.09864","Hsiao_2024"],"data":{"https://doi.org/10.48550/arxiv.2411.07191":{"label":"https://doi.org/10.48550/arxiv.2411.07191","enumerator":"1","doi":"10.48550/ARXIV.2411.07191","html":"Yu, M., Wang, D., Shan, Q., Reed, C., \u0026 Wan, A. (2024). \u003ci\u003eThe Super Weight in Large Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2411.07191\"\u003e10.48550/ARXIV.2411.07191\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2411.07191"},"https://doi.org/10.48550/arxiv.2410.02725":{"label":"https://doi.org/10.48550/arxiv.2410.02725","enumerator":"2","doi":"10.48550/ARXIV.2410.02725","html":"Manvi, R., Singh, A., \u0026 Ermon, S. (2024). \u003ci\u003eAdaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2410.02725\"\u003e10.48550/ARXIV.2410.02725\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2410.02725"},"https://doi.org/10.48550/arxiv.2404.03592":{"label":"https://doi.org/10.48550/arxiv.2404.03592","enumerator":"3","doi":"10.48550/ARXIV.2404.03592","html":"Wu, Z., Arora, A., Wang, Z., Geiger, A., Jurafsky, D., Manning, C. D., \u0026 Potts, C. (2024). \u003ci\u003eReFT: Representation Finetuning for Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.03592\"\u003e10.48550/ARXIV.2404.03592\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.03592"},"https://doi.org/10.48550/arxiv.2402.06111":{"label":"https://doi.org/10.48550/arxiv.2402.06111","enumerator":"4","doi":"10.48550/ARXIV.2402.06111","html":"Alshahwan, N., Harman, M., Marginean, A., Tal, R., \u0026 Wang, E. (2024). \u003ci\u003eObservation-based unit test generation at Meta\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.06111\"\u003e10.48550/ARXIV.2402.06111\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.06111"},"https://doi.org/10.48550/arxiv.2403.20327":{"label":"https://doi.org/10.48550/arxiv.2403.20327","enumerator":"5","doi":"10.48550/ARXIV.2403.20327","html":"Lee, J., Dai, Z., Ren, X., Chen, B., Cer, D., Cole, J. R., Hui, K., Boratko, M., Kapadia, R., Ding, W., Luan, Y., Duddu, S. M. K., Abrego, G. H., Shi, W., Gupta, N., Kusupati, A., Jain, P., Jonnalagadda, S. R., Chang, M.-W., \u0026 Naim, I. (2024). \u003ci\u003eGecko: Versatile Text Embeddings Distilled from Large Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2403.20327\"\u003e10.48550/ARXIV.2403.20327\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2403.20327"},"https://doi.org/10.48550/arxiv.2210.07128":{"label":"https://doi.org/10.48550/arxiv.2210.07128","enumerator":"6","doi":"10.48550/ARXIV.2210.07128","html":"Madaan, A., Zhou, S., Alon, U., Yang, Y., \u0026 Neubig, G. (2022). \u003ci\u003eLanguage Models of Code are Few-Shot Commonsense Learners\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2210.07128\"\u003e10.48550/ARXIV.2210.07128\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2210.07128"},"https://doi.org/10.48550/arxiv.2407.10969":{"label":"https://doi.org/10.48550/arxiv.2407.10969","enumerator":"7","doi":"10.48550/ARXIV.2407.10969","html":"Wang, H., Ma, S., Wang, R., \u0026 Wei, F. (2024). \u003ci\u003eQ-Sparse: All Large Language Models can be Fully Sparsely-Activated\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2407.10969\"\u003e10.48550/ARXIV.2407.10969\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2407.10969"},"https://doi.org/10.48550/arxiv.2207.01780":{"label":"https://doi.org/10.48550/arxiv.2207.01780","enumerator":"8","doi":"10.48550/ARXIV.2207.01780","html":"Le, H., Wang, Y., Gotmare, A. D., Savarese, S., \u0026 Hoi, S. C. H. (2022). \u003ci\u003eCodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2207.01780\"\u003e10.48550/ARXIV.2207.01780\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2207.01780"},"https://doi.org/10.48550/arxiv.2405.20541":{"label":"https://doi.org/10.48550/arxiv.2405.20541","enumerator":"9","doi":"10.48550/ARXIV.2405.20541","html":"Ankner, Z., Blakeney, C., Sreenivasan, K., Marion, M., Leavitt, M. L., \u0026 Paul, M. (2024). \u003ci\u003ePerplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2405.20541\"\u003e10.48550/ARXIV.2405.20541\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2405.20541"},"https://doi.org/10.48550/arxiv.2402.17764":{"label":"https://doi.org/10.48550/arxiv.2402.17764","enumerator":"10","doi":"10.48550/ARXIV.2402.17764","html":"Ma, S., Wang, H., Ma, L., Wang, L., Wang, W., Huang, S., Dong, L., Wang, R., Xue, J., \u0026 Wei, F. (2024). \u003ci\u003eThe Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.17764\"\u003e10.48550/ARXIV.2402.17764\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.17764"},"https://doi.org/10.48550/arxiv.2305.17493":{"label":"https://doi.org/10.48550/arxiv.2305.17493","enumerator":"11","doi":"10.48550/ARXIV.2305.17493","html":"Shumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot, N., \u0026 Anderson, R. (2023). \u003ci\u003eThe Curse of Recursion: Training on Generated Data Makes Models Forget\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2305.17493\"\u003e10.48550/ARXIV.2305.17493\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2305.17493"},"https://doi.org/10.48550/arxiv.2404.07143":{"label":"https://doi.org/10.48550/arxiv.2404.07143","enumerator":"12","doi":"10.48550/ARXIV.2404.07143","html":"Munkhdalai, T., Faruqui, M., \u0026 Gopal, S. (2024). \u003ci\u003eLeave No Context Behind: Efficient Infinite Context Transformers with Infini-attention\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.07143\"\u003e10.48550/ARXIV.2404.07143\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.07143"},"https://doi.org/10.48550/arxiv.2406.07496":{"label":"https://doi.org/10.48550/arxiv.2406.07496","enumerator":"13","doi":"10.48550/ARXIV.2406.07496","html":"Yuksekgonul, M., Bianchi, F., Boen, J., Liu, S., Huang, Z., Guestrin, C., \u0026 Zou, J. (2024). \u003ci\u003eTextGrad: Automatic “Differentiation” via Text\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.07496\"\u003e10.48550/ARXIV.2406.07496\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.07496"},"https://doi.org/10.48550/arxiv.2406.02528":{"label":"https://doi.org/10.48550/arxiv.2406.02528","enumerator":"14","doi":"10.48550/ARXIV.2406.02528","html":"Zhu, R.-J., Zhang, Y., Sifferman, E., Sheaves, T., Wang, Y., Richmond, D., Zhou, P., \u0026 Eshraghian, J. K. (2024). \u003ci\u003eScalable MatMul-free Language Modeling\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.02528\"\u003e10.48550/ARXIV.2406.02528\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.02528"},"https://doi.org/10.48550/arxiv.1712.00676":{"label":"https://doi.org/10.48550/arxiv.1712.00676","enumerator":"15","doi":"10.48550/ARXIV.1712.00676","html":"Billings, J. J., McCaskey, A. J., Vallee, G., \u0026 Watson, G. (2017). \u003ci\u003eWill humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?\u003c/i\u003e arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1712.00676\"\u003e10.48550/ARXIV.1712.00676\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1712.00676"},"https://doi.org/10.48550/arxiv.2311.17035":{"label":"https://doi.org/10.48550/arxiv.2311.17035","enumerator":"16","doi":"10.48550/ARXIV.2311.17035","html":"Nasr, M., Carlini, N., Hayase, J., Jagielski, M., Cooper, A. F., Ippolito, D., Choquette-Choo, C. A., Wallace, E., Tramèr, F., \u0026 Lee, K. (2023). \u003ci\u003eScalable Extraction of Training Data from (Production) Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2311.17035\"\u003e10.48550/ARXIV.2311.17035\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2311.17035"},"https://doi.org/10.48550/arxiv.2305.07759":{"label":"https://doi.org/10.48550/arxiv.2305.07759","enumerator":"17","doi":"10.48550/ARXIV.2305.07759","html":"Eldan, R., \u0026 Li, Y. (2023). \u003ci\u003eTinyStories: How Small Can Language Models Be and Still Speak Coherent English?\u003c/i\u003e arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2305.07759\"\u003e10.48550/ARXIV.2305.07759\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2305.07759"},"https://doi.org/10.48550/arxiv.2311.12983":{"label":"https://doi.org/10.48550/arxiv.2311.12983","enumerator":"18","doi":"10.48550/ARXIV.2311.12983","html":"Mialon, G., Fourrier, C., Swift, C., Wolf, T., LeCun, Y., \u0026 Scialom, T. (2023). \u003ci\u003eGAIA: a benchmark for General AI Assistants\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2311.12983\"\u003e10.48550/ARXIV.2311.12983\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2311.12983"},"https://doi.org/10.48550/arxiv.2406.04692":{"label":"https://doi.org/10.48550/arxiv.2406.04692","enumerator":"19","doi":"10.48550/ARXIV.2406.04692","html":"Wang, J., Wang, J., Athiwaratkun, B., Zhang, C., \u0026 Zou, J. (2024). \u003ci\u003eMixture-of-Agents Enhances Large Language Model Capabilities\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.04692\"\u003e10.48550/ARXIV.2406.04692\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.04692"},"https://doi.org/10.48550/arxiv.2311.05884":{"label":"https://doi.org/10.48550/arxiv.2311.05884","enumerator":"20","doi":"10.48550/ARXIV.2311.05884","html":"Gui, H., Wang, R., Yin, K., Jin, L., Kula, M., Xu, T., Hong, L., \u0026 Chi, E. H. (2023). \u003ci\u003eHiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2311.05884\"\u003e10.48550/ARXIV.2311.05884\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2311.05884"},"https://doi.org/10.48550/arxiv.2307.11760":{"label":"https://doi.org/10.48550/arxiv.2307.11760","enumerator":"21","doi":"10.48550/ARXIV.2307.11760","html":"Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., \u0026 Xie, X. (2023). \u003ci\u003eLarge Language Models Understand and Can be Enhanced by Emotional Stimuli\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2307.11760\"\u003e10.48550/ARXIV.2307.11760\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2307.11760"},"https://doi.org/10.48550/arxiv.2402.09171":{"label":"https://doi.org/10.48550/arxiv.2402.09171","enumerator":"22","doi":"10.48550/ARXIV.2402.09171","html":"Alshahwan, N., Chheda, J., Finegenova, A., Gokkaya, B., Harman, M., Harper, I., Marginean, A., Sengupta, S., \u0026 Wang, E. (2024). \u003ci\u003eAutomated Unit Test Improvement using Large Language Models at Meta\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.09171\"\u003e10.48550/ARXIV.2402.09171\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.09171"},"https://doi.org/10.48550/arxiv.2404.01413":{"label":"https://doi.org/10.48550/arxiv.2404.01413","enumerator":"23","doi":"10.48550/ARXIV.2404.01413","html":"Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., \u0026 Koyejo, S. (2024). \u003ci\u003eIs Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.01413\"\u003e10.48550/ARXIV.2404.01413\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.01413"},"https://doi.org/10.48550/arxiv.2102.04518":{"label":"https://doi.org/10.48550/arxiv.2102.04518","enumerator":"24","doi":"10.48550/ARXIV.2102.04518","html":"Agostinelli, F., Shmakov, A., McAleer, S., Fox, R., \u0026 Baldi, P. (2021). \u003ci\u003eA* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2102.04518\"\u003e10.48550/ARXIV.2102.04518\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2102.04518"},"https://doi.org/10.48550/arxiv.2402.06196":{"label":"https://doi.org/10.48550/arxiv.2402.06196","enumerator":"25","doi":"10.48550/ARXIV.2402.06196","html":"Minaee, S., Mikolov, T., Nikzad, N., Chenaghlu, M., Socher, R., Amatriain, X., \u0026 Gao, J. (2024). \u003ci\u003eLarge Language Models: A Survey\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.06196\"\u003e10.48550/ARXIV.2402.06196\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.06196"},"https://doi.org/10.48550/arxiv.2402.14433":{"label":"https://doi.org/10.48550/arxiv.2402.14433","enumerator":"26","doi":"10.48550/ARXIV.2402.14433","html":"von Rütte, D., Anagnostidis, S., Bachmann, G., \u0026 Hofmann, T. (2024). \u003ci\u003eA Language Model’s Guide Through Latent Space\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.14433\"\u003e10.48550/ARXIV.2402.14433\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.14433"},"https://doi.org/10.48550/arxiv.2205.05124":{"label":"https://doi.org/10.48550/arxiv.2205.05124","enumerator":"27","doi":"10.48550/ARXIV.2205.05124","html":"Subramani, N., Suresh, N., \u0026 Peters, M. E. (2022). \u003ci\u003eExtracting Latent Steering Vectors from Pretrained Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2205.05124\"\u003e10.48550/ARXIV.2205.05124\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2205.05124"},"https://doi.org/10.48550/arxiv.1910.10683":{"label":"https://doi.org/10.48550/arxiv.1910.10683","enumerator":"28","doi":"10.48550/ARXIV.1910.10683","html":"Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., \u0026 Liu, P. J. (2019). \u003ci\u003eExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1910.10683\"\u003e10.48550/ARXIV.1910.10683\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1910.10683"},"https://doi.org/10.48550/arxiv.2308.10248":{"label":"https://doi.org/10.48550/arxiv.2308.10248","enumerator":"29","doi":"10.48550/ARXIV.2308.10248","html":"Turner, A. M., Thiergart, L., Leech, G., Udell, D., Vazquez, J. J., Mini, U., \u0026 MacDiarmid, M. (2023). \u003ci\u003eSteering Language Models With Activation Engineering\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2308.10248\"\u003e10.48550/ARXIV.2308.10248\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2308.10248"},"https://doi.org/10.48550/arxiv.2107.03374":{"label":"https://doi.org/10.48550/arxiv.2107.03374","enumerator":"30","doi":"10.48550/ARXIV.2107.03374","html":"Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., … Zaremba, W. (2021). \u003ci\u003eEvaluating Large Language Models Trained on Code\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2107.03374\"\u003e10.48550/ARXIV.2107.03374\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2107.03374"},"https://doi.org/10.48550/arxiv.2406.02543":{"label":"https://doi.org/10.48550/arxiv.2406.02543","enumerator":"31","doi":"10.48550/ARXIV.2406.02543","html":"Yadkori, Y. A., Kuzborskij, I., György, A., \u0026 Szepesvári, C. (2024). \u003ci\u003eTo Believe or Not to Believe Your LLM\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.02543\"\u003e10.48550/ARXIV.2406.02543\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.02543"},"https://doi.org/10.48550/arxiv.2404.14619":{"label":"https://doi.org/10.48550/arxiv.2404.14619","enumerator":"32","doi":"10.48550/ARXIV.2404.14619","html":"Mehta, S., Sekhavat, M. H., Cao, Q., Horton, M., Jin, Y., Sun, C., Mirzadeh, I., Najibi, M., Belenko, D., Zatloukal, P., \u0026 Rastegari, M. (2024). \u003ci\u003eOpenELM: An Efficient Language Model Family with Open Training and Inference Framework\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.14619\"\u003e10.48550/ARXIV.2404.14619\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.14619"},"https://doi.org/10.48550/arxiv.1706.03741":{"label":"https://doi.org/10.48550/arxiv.1706.03741","enumerator":"33","doi":"10.48550/ARXIV.1706.03741","html":"Christiano, P., Leike, J., Brown, T. B., Martic, M., Legg, S., \u0026 Amodei, D. (2017). \u003ci\u003eDeep reinforcement learning from human preferences\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1706.03741\"\u003e10.48550/ARXIV.1706.03741\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1706.03741"},"https://doi.org/10.48550/arxiv.2307.08925":{"label":"https://doi.org/10.48550/arxiv.2307.08925","enumerator":"34","doi":"10.48550/ARXIV.2307.08925","html":"Chen, C., Feng, X., Li, Y., Lyu, L., Zhou, J., Zheng, X., \u0026 Yin, J. (2023). \u003ci\u003eIntegration of Large Language Models and Federated Learning\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2307.08925\"\u003e10.48550/ARXIV.2307.08925\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2307.08925"},"https://doi.org/10.48550/arxiv.2212.02508":{"label":"https://doi.org/10.48550/arxiv.2212.02508","enumerator":"35","doi":"10.48550/ARXIV.2212.02508","html":"Li, Y., Yuan, R., Zhang, G., Ma, Y., Lin, C., Chen, X., Ragni, A., Yin, H., Hu, Z., He, H., Benetos, E., Gyenge, N., Liu, R., \u0026 Fu, J. (2022). \u003ci\u003eMAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2212.02508\"\u003e10.48550/ARXIV.2212.02508\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2212.02508"},"https://doi.org/10.48550/arxiv.2302.13971":{"label":"https://doi.org/10.48550/arxiv.2302.13971","enumerator":"36","doi":"10.48550/ARXIV.2302.13971","html":"Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., \u0026 Lample, G. (2023). \u003ci\u003eLLaMA: Open and Efficient Foundation Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2302.13971\"\u003e10.48550/ARXIV.2302.13971\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2302.13971"},"https://doi.org/10.48550/arxiv.1607.06450":{"label":"https://doi.org/10.48550/arxiv.1607.06450","enumerator":"37","doi":"10.48550/ARXIV.1607.06450","html":"Ba, J. L., Kiros, J. R., \u0026 Hinton, G. E. (2016). \u003ci\u003eLayer Normalization\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1607.06450\"\u003e10.48550/ARXIV.1607.06450\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1607.06450"},"https://doi.org/10.48550/arxiv.1706.03762":{"label":"https://doi.org/10.48550/arxiv.1706.03762","enumerator":"38","doi":"10.48550/ARXIV.1706.03762","html":"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., \u0026 Polosukhin, I. (2017). \u003ci\u003eAttention Is All You Need\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1706.03762\"\u003e10.48550/ARXIV.1706.03762\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1706.03762"},"https://doi.org/10.48550/arxiv.2406.09412":{"label":"https://doi.org/10.48550/arxiv.2406.09412","enumerator":"39","doi":"10.48550/ARXIV.2406.09412","html":"Zhang, Y., Li, H., Liu, J., \u0026 Yue, X. (2024). \u003ci\u003eExplore the Limits of Omni-modal Pretraining at Scale\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.09412\"\u003e10.48550/ARXIV.2406.09412\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.09412"},"https://doi.org/10.48550/arxiv.1606.08415":{"label":"https://doi.org/10.48550/arxiv.1606.08415","enumerator":"40","doi":"10.48550/ARXIV.1606.08415","html":"Hendrycks, D., \u0026 Gimpel, K. (2016). \u003ci\u003eGaussian Error Linear Units (GELUs)\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1606.08415\"\u003e10.48550/ARXIV.1606.08415\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1606.08415"},"https://doi.org/10.48550/arxiv.2401.09796":{"label":"https://doi.org/10.48550/arxiv.2401.09796","enumerator":"41","doi":"10.48550/ARXIV.2401.09796","html":"Huang, W., Wang, Y., Cheng, A., Zhou, A., Yu, C., \u0026 Wang, L. (2024). \u003ci\u003eA Fast, Performant, Secure Distributed Training Framework For Large Language Model\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2401.09796\"\u003e10.48550/ARXIV.2401.09796\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2401.09796"},"https://doi.org/10.48550/arxiv.1910.01108":{"label":"https://doi.org/10.48550/arxiv.1910.01108","enumerator":"42","doi":"10.48550/ARXIV.1910.01108","html":"Sanh, V., Debut, L., Chaumond, J., \u0026 Wolf, T. (2019). \u003ci\u003eDistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1910.01108\"\u003e10.48550/ARXIV.1910.01108\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1910.01108"},"https://doi.org/10.48550/arxiv.2203.02155":{"label":"https://doi.org/10.48550/arxiv.2203.02155","enumerator":"43","doi":"10.48550/ARXIV.2203.02155","html":"Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., \u0026 Lowe, R. (2022). \u003ci\u003eTraining language models to follow instructions with human feedback\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2203.02155\"\u003e10.48550/ARXIV.2203.02155\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2203.02155"},"https://doi.org/10.48550/arxiv.2307.09288":{"label":"https://doi.org/10.48550/arxiv.2307.09288","enumerator":"44","doi":"10.48550/ARXIV.2307.09288","html":"Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., … Scialom, T. (2023). \u003ci\u003eLlama 2: Open Foundation and Fine-Tuned Chat Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2307.09288\"\u003e10.48550/ARXIV.2307.09288\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2307.09288"},"https://doi.org/10.48550/arxiv.2104.09864":{"label":"https://doi.org/10.48550/arxiv.2104.09864","enumerator":"45","doi":"10.48550/ARXIV.2104.09864","html":"Su, J., Lu, Y., Pan, S., Murtadha, A., Wen, B., \u0026 Liu, Y. (2021). \u003ci\u003eRoFormer: Enhanced Transformer with Rotary Position Embedding\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2104.09864\"\u003e10.48550/ARXIV.2104.09864\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2104.09864"},"Hsiao_2024":{"label":"Hsiao_2024","enumerator":"46","doi":"10.1111/tops.12737","html":"Hsiao, J. H. (2024). Understanding Human Cognition Through Computational Modeling. \u003ci\u003eTopics in Cognitive Science\u003c/i\u003e, \u003ci\u003e16\u003c/i\u003e(3), 349–376. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1111/tops.12737\"\u003e10.1111/tops.12737\u003c/a\u003e","url":"https://doi.org/10.1111/tops.12737"}}}},"footer":{"navigation":{"prev":{"title":"The Transformer","url":"/glossary/transformer-1","group":"ML Notes"},"next":{"title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","url":"/paper-notes/perplexity-based-data-pruning","group":"ML Notes"}}},"domain":"http://localhost:3000"},"project":{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"},{"children":[{"file":"experiments/higher-abstract-reasoning.ipynb"}],"file":"experiments/index.md","title":"Experiments"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-96b2eadaf42874bf4f4baabaf5828596.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"experiments.index","title":"Experiments","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"experiments.higher-abstract-reasoning","title":"Transformers and Higher-Order Abstract Reasoning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-A92797E9.js";
import * as route0 from "/build/root-HROFNPGU.js";
import * as route1 from "/build/routes/$-WNZNXUO2.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>