<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Papers - ML Notes</title><meta property="og:title" content="Papers - ML Notes"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/build/_assets/app-H3NBUYVS.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="/myst-theme.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">ML Notes</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3iop:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="ML Notes" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">ML Notes</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Projects" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/projects">Projects</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rbd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rbd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Glossary" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/glossary">Glossary</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rfd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rfd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="open" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none bg-blue-300/30"><a title="Papers" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow font-semibold text-blue-800 dark:text-blue-200 active" href="/paper-notes">Papers</a><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rjd8p:" aria-expanded="true" data-state="open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="open" id="radix-:Rjd8p:" class="pl-3 pr-[2px] collapsible-content"><a title="Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/paper-notes/perplexity-based-data-pruning">Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</a></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/joshcarp/ml-notes" title="GitHub Repository: joshcarp/ml-notes" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Papers</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="WxxCO1TC2J" class="relative group/block article-grid subgrid-gap col-screen"><p>A collection of papers with summaries and quick access links.</p><h2 id="paper-notes" class="relative group"><span class="heading-text">Paper Notes</span><a class="no-underline text-inherit hover:text-inherit px-2 font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#paper-notes" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><figure id="drQ5XEeVhi" class="fig-table"><table><tbody><tr><th class="">Title</th><th class="">Tags</th><th class="">Full Notes</th></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2411.07191" target="_blank" rel="noreferrer" class="hover-link">The Super Weight in Large Language Models</a></cite></td><td class="">Model internals</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2410.02725" target="_blank" rel="noreferrer" class="hover-link">Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation</a></cite></td><td class=""></td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.03592" target="_blank" rel="noreferrer" class="hover-link">ReFT: Representation Finetuning for Language Models</a></cite></td><td class="">Fine-tuning, Model representations</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://doi.org/10.5555/2627435.2670313" rel="noreferrer">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></td><td class="">Model performance, Optimization, Model architecture</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.06111" target="_blank" rel="noreferrer" class="hover-link">Observation-based unit test generation at Meta</a></cite></td><td class="">Automated testing, Software engineering</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2403.20327" target="_blank" rel="noreferrer" class="hover-link">Gecko: Versatile Text Embeddings Distilled from Large Language Models</a></cite></td><td class="">Embeddings, Model distillation</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2210.07128" target="_blank" rel="noreferrer" class="hover-link">Language Models of Code are Few-Shot Commonsense Learners</a></cite></td><td class="">Code models, Transfer learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2407.10969" target="_blank" rel="noreferrer" class="hover-link">Q-Sparse: All Large Language Models can be Fully Sparsely-Activated</a></cite></td><td class="">Efficiency, Model performance</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2207.01780" target="_blank" rel="noreferrer" class="hover-link">CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning</a></cite></td><td class="">Code generation, Reinforcement learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2405.20541" target="_blank" rel="noreferrer" class="hover-link">Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</a></cite></td><td class="">Data pruning, Perplexity</td><td class=""><a href="/paper-notes/perplexity-based-data-pruning">Details</a></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.17764" target="_blank" rel="noreferrer" class="hover-link">The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits</a></cite></td><td class="">Hardware optimization, Model compression</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2305.17493" target="_blank" rel="noreferrer" class="hover-link">The Curse of Recursion: Training on Generated Data Makes Models Forget</a></cite></td><td class="">Model collapse, Training data</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html" rel="noreferrer">Chain of thought prompting</a></td><td class="">Prompting strategies</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.07143" target="_blank" rel="noreferrer" class="hover-link">Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</a></cite></td><td class="">Attention mechanisms, Context window</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.07496" target="_blank" rel="noreferrer" class="hover-link">TextGrad</a></cite></td><td class="">Agent systems, Text optimization</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.02528" target="_blank" rel="noreferrer" class="hover-link">Scalable MatMul-free Language Modeling</a></cite></td><td class="">Attention mechanisms, Model efficiency</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1712.00676" target="_blank" rel="noreferrer" class="hover-link">Will humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?</a></cite></td><td class="">AI in software development, Future of coding</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2311.17035" target="_blank" rel="noreferrer" class="hover-link">Scalable Extraction of Training Data from (Production) Language Models</a></cite></td><td class="">Data accumulation, Model performance, Curated datasets</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2305.07759" target="_blank" rel="noreferrer" class="hover-link">TinyStories: How Small Can Language Models Be and Still Speak Coherent English?</a></cite></td><td class="">Dataset creation, Small language models</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2311.12983" target="_blank" rel="noreferrer" class="hover-link">GAIA: A Benchmark for General AI Assistants</a></cite></td><td class="">AI assistants, Benchmarking</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.anthropic.com/news/mapping-mind-language-model" rel="noreferrer">Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet</a></td><td class="">Feature extraction, Interpretability</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.04692" target="_blank" rel="noreferrer" class="hover-link">Mixture-of-Agents Enhances Large Language Model Capabilities</a></cite></td><td class="">Model performance, Multi-agent systems</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2311.05884" target="_blank" rel="noreferrer" class="hover-link">Hiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems</a></cite></td><td class="">Transformers, Model architecture, Model performance</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2307.11760" target="_blank" rel="noreferrer" class="hover-link">Large Language Models Understand and Can Be Enhanced by Emotional Stimuli</a></cite></td><td class="">emotional stimuli, Model behavior</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.09171" target="_blank" rel="noreferrer" class="hover-link">Automated Unit Test Improvement using Large Language Models at Meta</a></cite></td><td class="">Automated testing, Software engineering</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.01413" target="_blank" rel="noreferrer" class="hover-link">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</a></cite></td><td class="">Data accumulation, Model collapse prevention</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2102.04518" target="_blank" rel="noreferrer" class="hover-link">A\ Search Without Expansions: Learning Heuristic Functions With Deep Q-Networks</a></cite></td><td class="">Reinforcement learning, Search algorithms</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.06196" target="_blank" rel="noreferrer" class="hover-link">Large Language Models: A Survey</a></cite></td><td class="">LLM capabilities, Survey</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2402.14433" target="_blank" rel="noreferrer" class="hover-link">A Language Model’s Guide Through Latent Space</a></cite></td><td class="">Interpretability, Latent space</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2205.05124" target="_blank" rel="noreferrer" class="hover-link">Extracting Latent Steering Vectors from Pretrained Language Models</a></cite></td><td class="">Interpretability, Latent space</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.anthropic.com/research/many-shot-jailbreaking" rel="noreferrer">Many-shot jailbreaking</a></td><td class="">Jailbreaking, Model safety</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1910.10683" target="_blank" rel="noreferrer" class="hover-link">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></cite></td><td class="">Transfer learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2308.10248" target="_blank" rel="noreferrer" class="hover-link">Activation Addition: Steering Language Models Without Optimization</a></cite></td><td class="">Activation manipulation, Model steering</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2107.03374" target="_blank" rel="noreferrer" class="hover-link">Evaluating Large Language Models Trained on Code</a></cite></td><td class="">Code generation, Model evaluation</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.02543" target="_blank" rel="noreferrer" class="hover-link">To Believe or Not to Believe Your LLM</a></cite></td><td class="">Hallucination detection, Uncertainty quantification</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.04692" target="_blank" rel="noreferrer" class="hover-link">Mixture of Agents</a></cite></td><td class="">Multi-agent systems, Prompting</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2404.14619" target="_blank" rel="noreferrer" class="hover-link">OpenELM: An Efficient Language Model Family with Open Training and Inference Framework</a></cite></td><td class="">Efficiency, Model architecture</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1706.03741" target="_blank" rel="noreferrer" class="hover-link">Deep Reinforcement Learning from Human Preferences</a></cite></td><td class="">human feedback, Reinforcement learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2307.08925" target="_blank" rel="noreferrer" class="hover-link">Federated Large Language Model: A Position Paper</a></cite></td><td class="">Distributed training, Federated learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2212.02508" target="_blank" rel="noreferrer" class="hover-link">MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning</a></cite></td><td class="">Music representation, Self-supervised learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2302.13971" target="_blank" rel="noreferrer" class="hover-link">LLaMA: Open and Efficient Foundation Language Models</a></cite></td><td class="">Model architecture, Open-source LLMs</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/" rel="noreferrer">Phi1: Textbooks Are All You Need</a></td><td class="">Curated datasets, Model efficiency</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1607.06450" target="_blank" rel="noreferrer" class="hover-link">Layer Normalization</a></cite></td><td class="">Model internals, Optimization</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1706.03762" target="_blank" rel="noreferrer" class="hover-link">Attention Is All You Need</a></cite></td><td class="">OG papers, Transformers</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2406.09412" target="_blank" rel="noreferrer" class="hover-link">Explore the Limits of Omni-modal Pretraining at Scale</a></cite></td><td class="">Multi-modal models, Pretraining</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1606.08415" target="_blank" rel="noreferrer" class="hover-link">Gaussian Error Linear Units (GELUs)</a></cite></td><td class="">Activation functions, Model internals</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2401.09796" target="_blank" rel="noreferrer" class="hover-link">A Fast, Performant, Secure Distributed Training Framework For Large Language Model</a></cite></td><td class="">Distributed training, Security</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.1910.01108" target="_blank" rel="noreferrer" class="hover-link">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</a></cite></td><td class="">Efficiency, Model distillation</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="noreferrer">Improving Language Understanding by Generative Pre-Training</a></td><td class="">OG papers, Pre-training</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2203.02155" target="_blank" rel="noreferrer" class="hover-link">Training language models to follow instructions with human feedback</a></cite></td><td class="">Instruction following, Reinforcement learning</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2307.09288" target="_blank" rel="noreferrer" class="hover-link">Llama 2: Open Foundation and Fine-Tuned Chat Models</a></cite></td><td class="">Fine-tuning, Open-source LLMs</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.48550/ARXIV.2104.09864" target="_blank" rel="noreferrer" class="hover-link">RoFormer: Enhanced Transformer with Rotary Position Embedding</a></cite></td><td class="">Embeddings, Model architecture</td><td class=""></td></tr><tr><td class=""><a target="_blank" href="https://www.nature.com/articles/s42256-023-00748-9" rel="noreferrer">Spatially embedded recurrent neural networks reveal widespread links between structural and functional neuroscience findings | Nature Machine Intelligence</a></td><td class="">Biological Brains</td><td class=""></td></tr><tr><td class=""><cite data-state="closed"><a href="https://doi.org/10.1111/tops.12737" target="_blank" rel="noreferrer" class="hover-link">Understanding Human Cognition Through Computational Modeling - Hsiao - 2024 - Topics in Cognitive Science - Wiley Online Library</a></cite></td><td class="">Biological Brains</td><td class=""></td></tr></tbody></table></figure></div><div></div><section id="references" class="article-grid subgrid-gap col-screen"><div><button class="float-right p-1 px-2 text-xs border rounded hover:border-blue-500 dark:hover:border-blue-400">Show All</button><header class="text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2411.07191">Yu, M., Wang, D., Shan, Q., Reed, C., & Wan, A. (2024). <i>The Super Weight in Large Language Models</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2411.07191">10.48550/ARXIV.2411.07191</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2410.02725">Manvi, R., Singh, A., & Ermon, S. (2024). <i>Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2410.02725">10.48550/ARXIV.2410.02725</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2404.03592">Wu, Z., Arora, A., Wang, Z., Geiger, A., Jurafsky, D., Manning, C. D., & Potts, C. (2024). <i>ReFT: Representation Finetuning for Language Models</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2404.03592">10.48550/ARXIV.2404.03592</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2402.06111">Alshahwan, N., Harman, M., Marginean, A., Tal, R., & Wang, E. (2024). <i>Observation-based unit test generation at Meta</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2402.06111">10.48550/ARXIV.2402.06111</a></li><li class="break-words" id="cite-https://doi.org/10.48550/arxiv.2403.20327">Lee, J., Dai, Z., Ren, X., Chen, B., Cer, D., Cole, J. R., Hui, K., Boratko, M., Kapadia, R., Ding, W., Luan, Y., Duddu, S. M. K., Abrego, G. H., Shi, W., Gupta, N., Kusupati, A., Jain, P., Jonnalagadda, S. R., Chang, M.-W., & Naim, I. (2024). <i>Gecko: Versatile Text Embeddings Distilled from Large Language Models</i>. arXiv. <a target="_blank" rel="noreferrer" href="https://doi.org/10.48550/ARXIV.2403.20327">10.48550/ARXIV.2403.20327</a></li><li class="text-center list-none"><button class="p-2 border rounded hover:border-blue-500 dark:hover:border-blue-400">Show all 46 references</button></li></ol></div></section><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/glossary/transformer-1"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>The Transformer</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/paper-notes/perplexity-based-data-pruning"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">ML Notes</div>Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-JLDGA2DL.js"/><link rel="modulepreload" href="/build/_shared/chunk-YAIQ7LUU.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-ZQWAZXET.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-IQBJE7PC.js"/><link rel="modulepreload" href="/build/_shared/chunk-5CFTM6YW.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-HROFNPGU.js"/><link rel="modulepreload" href="/build/_shared/chunk-N544LW6X.js"/><link rel="modulepreload" href="/build/routes/$-WNZNXUO2.js"/><script>window.__remixContext = {"url":"/paper-notes","state":{"loaderData":{"root":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-8dc5eb8c43306bad204a83ccf0fbf0ec.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3101","MODE":"static"},"routes/$":{"config":{"title":"ML Notes","options":{"logo_text":"ML Notes","folders":true},"myst":"1.3.18","nav":[],"actions":[],"projects":[{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-8dc5eb8c43306bad204a83ccf0fbf0ec.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"kind":"Article","sha256":"de6f13421b9e894a3495f69d13e261da2b558605fa45aba906e17ebef11a1aea","slug":"paper-notes.index","location":"/paper-notes/index.md","dependencies":[],"frontmatter":{"title":"Papers","content_includes_title":false,"github":"https://github.com/joshcarp/ml-notes","exports":[{"format":"md","filename":"index.md","url":"/build/index-ab00802d9242182da19d48d67abc124d.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"A collection of papers with summaries and quick access links.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"eoujsU2yyG"}],"key":"LOGcE74pDs"},{"type":"heading","depth":2,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Paper Notes","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"dOxVbeWBDY"}],"identifier":"paper-notes","label":"Paper Notes","html_id":"paper-notes","implicit":true,"key":"nRDYkKAxxz"},{"type":"container","kind":"table","children":[{"type":"table","children":[{"type":"tableRow","children":[{"type":"tableCell","header":true,"children":[{"type":"text","value":"Title","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"mCkUj6jGSQ"}],"key":"gYD8cdGCTi"},{"type":"tableCell","header":true,"children":[{"type":"text","value":"Tags","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"SPa3Retk97"}],"key":"v6lqkzqMIg"},{"type":"tableCell","header":true,"children":[{"type":"text","value":"Full Notes","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"xahcBUYta9"}],"key":"SZ4Nu19Ldo"}],"key":"c9Z3nHt3bR"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2411.07191","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"The Super Weight in Large Language Models","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"qIBxZQgHhw"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2411.07191","identifier":"https://doi.org/10.48550/arXiv.2411.07191","enumerator":"1","key":"Yanz7ZiH25"}],"key":"UqycOvs5qo"},{"type":"tableCell","children":[{"type":"text","value":"Model internals","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"FhoHLNFE6x"}],"key":"ywspRPYVJp"},{"type":"tableCell","children":[],"key":"vp6sb31cZw"}],"key":"exU4aK8LAU"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2410.02725","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"MIOlmNh4D2"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2410.02725","identifier":"https://doi.org/10.48550/arXiv.2410.02725","enumerator":"2","key":"Jwr8NDDOxO"}],"key":"gT6gtWKjCi"},{"type":"tableCell","children":[],"key":"GlQiUllPjq"},{"type":"tableCell","children":[],"key":"vMwX8aDdDU"}],"key":"l4UEneJy7e"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.03592","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"ReFT: Representation Finetuning for Language Models","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"q3gcMp2g4K"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.03592","identifier":"https://doi.org/10.48550/arXiv.2404.03592","enumerator":"3","key":"Vkh0k80Fui"}],"key":"kslVuI356W"},{"type":"tableCell","children":[{"type":"text","value":"Fine-tuning, Model representations","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"XuFhgpRbGp"}],"key":"DBvEF9YBts"},{"type":"tableCell","children":[],"key":"sO1BFF4nqj"}],"key":"EJ2xSsgjoR"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://doi.org/10.5555/2627435.2670313","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Dropout: A Simple Way to Prevent Neural Networks from Overfitting","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"uloOlypdb4"}],"urlSource":"https://dl.acm.org/doi/abs/10.5555/2627435.2670313","data":{"doi":"10.5555/2627435.2670313"},"internal":false,"protocol":"doi","key":"TCHT2sqTCE"}],"key":"zLK8bDzirg"},{"type":"tableCell","children":[{"type":"text","value":"Model performance, Optimization, Model architecture","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"M7uQuNFGlX"}],"key":"yxIAN32sho"},{"type":"tableCell","children":[],"key":"J1VaAXF0hl"}],"key":"W7Orm4Jhi1"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.06111","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Observation-based unit test generation at Meta","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"X45VJm7dCZ"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.06111","identifier":"https://doi.org/10.48550/arXiv.2402.06111","enumerator":"4","key":"mSPdbpehFJ"}],"key":"tEeQSgHho0"},{"type":"tableCell","children":[{"type":"text","value":"Automated testing, Software engineering","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"neoxHcpw5J"}],"key":"QlTjfX72nI"},{"type":"tableCell","children":[],"key":"fMNHIxmgRF"}],"key":"q41wsQetYh"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2403.20327","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"Gecko: Versatile Text Embeddings Distilled from Large Language Models","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"Pb0JBRc35Q"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2403.20327","identifier":"https://doi.org/10.48550/arXiv.2403.20327","enumerator":"5","key":"Lh3pPIJ1Al"}],"key":"TBLZrYTeoi"},{"type":"tableCell","children":[{"type":"text","value":"Embeddings, Model distillation","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"kwp7fM1P4X"}],"key":"pWavP6QGS9"},{"type":"tableCell","children":[],"key":"fSubfS2pBz"}],"key":"hGNXd5N5go"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2210.07128","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"Language Models of Code are Few-Shot Commonsense Learners","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"nw4S0xcPD9"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2210.07128","identifier":"https://doi.org/10.48550/arXiv.2210.07128","enumerator":"6","key":"AmdkuBz4IN"}],"key":"YZhI5KmlSo"},{"type":"tableCell","children":[{"type":"text","value":"Code models, Transfer learning","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"oOiMrUBrpB"}],"key":"UNPzT3qCK7"},{"type":"tableCell","children":[],"key":"vhNt8jKOh1"}],"key":"ccVMUVhfIh"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2407.10969","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Q-Sparse: All Large Language Models can be Fully Sparsely-Activated","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"UvutZ5xnmP"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2407.10969","identifier":"https://doi.org/10.48550/arXiv.2407.10969","enumerator":"7","key":"uv7kG7uiTG"}],"key":"muWQiTW8xw"},{"type":"tableCell","children":[{"type":"text","value":"Efficiency, Model performance","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"uzxSWa5sBf"}],"key":"FWoOTGWYwU"},{"type":"tableCell","children":[],"key":"IGoBjXvvqH"}],"key":"EP9YtahR1z"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2207.01780","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"MHICUUB2Xk"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2207.01780","identifier":"https://doi.org/10.48550/arXiv.2207.01780","enumerator":"8","key":"ocChfMzQwu"}],"key":"uLecfNG1Aq"},{"type":"tableCell","children":[{"type":"text","value":"Code generation, Reinforcement learning","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"irutjeb6kh"}],"key":"pxMr8y57vV"},{"type":"tableCell","children":[],"key":"W8MRF2pPB7"}],"key":"dNRMeYnGHK"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2405.20541","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"xYINRUvIOF"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2405.20541","identifier":"https://doi.org/10.48550/arXiv.2405.20541","enumerator":"9","key":"rhUKS1fqRr"}],"key":"mvvDeS7ohh"},{"type":"tableCell","children":[{"type":"text","value":"Data pruning, Perplexity","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"Cp8EHewKoz"}],"key":"C7dRvMjx7s"},{"type":"tableCell","children":[{"type":"link","url":"/paper-notes/perplexity-based-data-pruning","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"Details","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"cPdEwEcGPB"}],"urlSource":"perplexity-based-data-pruning","dataUrl":"/paper-notes.perplexity-based-data-pruning.json","internal":true,"protocol":"file","key":"trFscWlggU"}],"key":"yX8rEgxs6z"}],"key":"MReAeFj2ja"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.17764","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"bAgnURhE4K"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.17764","identifier":"https://doi.org/10.48550/arXiv.2402.17764","enumerator":"10","key":"NJxf858Lzm"}],"key":"k7WejaNyHI"},{"type":"tableCell","children":[{"type":"text","value":"Hardware optimization, Model compression","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"KuOw2ic1yp"}],"key":"MNXHEvkd0m"},{"type":"tableCell","children":[],"key":"gYTOVoi7X2"}],"key":"wz7Ic84pIc"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2305.17493","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"The Curse of Recursion: Training on Generated Data Makes Models Forget","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"s0MrBAd4C2"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2305.17493","identifier":"https://doi.org/10.48550/arXiv.2305.17493","enumerator":"11","key":"HLQRuUk3Ef"}],"key":"pt7CAows6M"},{"type":"tableCell","children":[{"type":"text","value":"Model collapse, Training data","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"tviTYwZ21J"}],"key":"ImgfBd6mKl"},{"type":"tableCell","children":[],"key":"lWkWuLrdWN"}],"key":"YvzL6WIw71"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Chain of thought prompting","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"y9WLTAMLWC"}],"urlSource":"https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html","key":"KMwfmy1MGo"}],"key":"MG4OWLZ2H1"},{"type":"tableCell","children":[{"type":"text","value":"Prompting strategies","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"gyam2t28p9"}],"key":"nnXYNo9mXg"},{"type":"tableCell","children":[],"key":"BrOwoIVk9s"}],"key":"w1uRYItC8h"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.07143","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"GISxMB6bdL"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.07143","identifier":"https://doi.org/10.48550/arXiv.2404.07143","enumerator":"12","key":"COblQiDHar"}],"key":"W4xN4fKQvG"},{"type":"tableCell","children":[{"type":"text","value":"Attention mechanisms, Context window","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"B9wonck2sC"}],"key":"b0GlaPQInu"},{"type":"tableCell","children":[],"key":"c5J3GF2gKy"}],"key":"M9r6rYWS9L"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.07496","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"TextGrad","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"SYEj4Eur5h"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.07496","identifier":"https://doi.org/10.48550/arXiv.2406.07496","enumerator":"13","key":"oku2J6YqFx"}],"key":"jnuclzj3nv"},{"type":"tableCell","children":[{"type":"text","value":"Agent systems, Text optimization","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"sF99i433rO"}],"key":"YnUMIvdDCn"},{"type":"tableCell","children":[],"key":"iaPAjgRDnb"}],"key":"jX8fwMfVnh"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.02528","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"Scalable MatMul-free Language Modeling","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"lq2vLsJsX7"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.02528","identifier":"https://doi.org/10.48550/arXiv.2406.02528","enumerator":"14","key":"vmEG4IuKzT"}],"key":"GQp8M2k40Q"},{"type":"tableCell","children":[{"type":"text","value":"Attention mechanisms, Model efficiency","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"qxN6CVxX0p"}],"key":"DkVda4XNGN"},{"type":"tableCell","children":[],"key":"eraDEYslvw"}],"key":"hxst3WSY2W"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1712.00676","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"Will humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"y4t7dEVpfD"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1712.00676","identifier":"https://doi.org/10.48550/arXiv.1712.00676","enumerator":"15","key":"VgasBL4FMZ"}],"key":"gkN3HxuCrq"},{"type":"tableCell","children":[{"type":"text","value":"AI in software development, Future of coding","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"aX6Urx4wMG"}],"key":"buEAkzB3gT"},{"type":"tableCell","children":[],"key":"xq1BT98a76"}],"key":"w70b0uV5kY"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2311.17035","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"Scalable Extraction of Training Data from (Production) Language Models","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"gCd0JDIW8n"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2311.17035","identifier":"https://doi.org/10.48550/arXiv.2311.17035","enumerator":"16","key":"VneQNH6scA"}],"key":"IdXqNSQPs5"},{"type":"tableCell","children":[{"type":"text","value":"Data accumulation, Model performance, Curated datasets","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"Uu5uqxbzeW"}],"key":"KuSIgbnflD"},{"type":"tableCell","children":[],"key":"hnxZum5tbi"}],"key":"F1hl4fGxVy"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2305.07759","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"TinyStories: How Small Can Language Models Be and Still Speak Coherent English?","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"jcLmpCDmNB"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2305.07759","identifier":"https://doi.org/10.48550/arXiv.2305.07759","enumerator":"17","key":"Jheqqb37Xa"}],"key":"wTeFSrGdNd"},{"type":"tableCell","children":[{"type":"text","value":"Dataset creation, Small language models","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"Qn9kAjAvy3"}],"key":"U2mc2ImQtM"},{"type":"tableCell","children":[],"key":"T5tT2HUOGI"}],"key":"N2tpCpEPvW"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2311.12983","position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"text","value":"GAIA: A Benchmark for General AI Assistants","position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"key":"eNck0aTdCr"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2311.12983","identifier":"https://doi.org/10.48550/arXiv.2311.12983","enumerator":"18","key":"RhbUKotIbA"}],"key":"ExyRR7JrST"},{"type":"tableCell","children":[{"type":"text","value":"AI assistants, Benchmarking","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"LJXiRpLySp"}],"key":"IruGSyNOBj"},{"type":"tableCell","children":[],"key":"tZ4pFVFY5S"}],"key":"Sb223qZQOg"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.anthropic.com/news/mapping-mind-language-model","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"text","value":"Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"hr5ZYmGVxB"}],"urlSource":"https://www.anthropic.com/news/mapping-mind-language-model","key":"NieKKPmltG"}],"key":"IyBXcs4MRb"},{"type":"tableCell","children":[{"type":"text","value":"Feature extraction, Interpretability","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"XW2G5bn33n"}],"key":"hUv7iXhuF0"},{"type":"tableCell","children":[],"key":"SF9wwTsj8P"}],"key":"NFk2WEpPpZ"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.04692","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"Mixture-of-Agents Enhances Large Language Model Capabilities","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"Sp5rjwhtwJ"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.04692","identifier":"https://doi.org/10.48550/arXiv.2406.04692","enumerator":"19","key":"apAr1pIDKh"}],"key":"Ipf7ePu6U6"},{"type":"tableCell","children":[{"type":"text","value":"Model performance, Multi-agent systems","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"jmOMzqRKuJ"}],"key":"zbeI59OFwg"},{"type":"tableCell","children":[],"key":"GUCfyW0NcJ"}],"key":"HWimNoTpHt"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2311.05884","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"text","value":"Hiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems","position":{"start":{"line":79,"column":1},"end":{"line":79,"column":1}},"key":"I2xAcoNlXP"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2311.05884","identifier":"https://doi.org/10.48550/arXiv.2311.05884","enumerator":"20","key":"ekGQYrksiI"}],"key":"pfIJ6iuZZz"},{"type":"tableCell","children":[{"type":"text","value":"Transformers, Model architecture, Model performance","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"vp2dFQqZoF"}],"key":"Ly80ECAgkl"},{"type":"tableCell","children":[],"key":"MEFT5OHpp1"}],"key":"MlxNVEo5iW"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2307.11760","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"text","value":"Large Language Models Understand and Can Be Enhanced by Emotional Stimuli","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"key":"EDXvpbw7qo"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2307.11760","identifier":"https://doi.org/10.48550/arXiv.2307.11760","enumerator":"21","key":"JsO03PiO54"}],"key":"Jg4xL2cbGC"},{"type":"tableCell","children":[{"type":"text","value":"emotional stimuli, Model behavior","position":{"start":{"line":83,"column":1},"end":{"line":83,"column":1}},"key":"oNm1G0SpQs"}],"key":"MXBZqqcbO0"},{"type":"tableCell","children":[],"key":"WRqJry8qoH"}],"key":"mIT5MH5iqp"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.09171","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"text","value":"Automated Unit Test Improvement using Large Language Models at Meta","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"key":"tv4MH3G7W9"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.09171","identifier":"https://doi.org/10.48550/arXiv.2402.09171","enumerator":"22","key":"XVPRmnkZJo"}],"key":"xAkZoX8L7s"},{"type":"tableCell","children":[{"type":"text","value":"Automated testing, Software engineering","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"key":"RNvd4lHkr0"}],"key":"tqajvJu6zL"},{"type":"tableCell","children":[],"key":"RTCJlQb8dx"}],"key":"tKuEZ48jKK"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.01413","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"children":[{"type":"text","value":"Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"key":"NRDFB4VAky"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.01413","identifier":"https://doi.org/10.48550/arXiv.2404.01413","enumerator":"23","key":"Q4qBNPTJxM"}],"key":"db2cAe6F2M"},{"type":"tableCell","children":[{"type":"text","value":"Data accumulation, Model collapse prevention","position":{"start":{"line":89,"column":1},"end":{"line":89,"column":1}},"key":"EuNJJ6TaTC"}],"key":"Rb961uHquc"},{"type":"tableCell","children":[],"key":"ElBroTT2Lt"}],"key":"Uk9K748wgj"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2102.04518","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"children":[{"type":"text","value":"A\\ Search Without Expansions: Learning Heuristic Functions With Deep Q-Networks","position":{"start":{"line":91,"column":1},"end":{"line":91,"column":1}},"key":"a11M1oJVkV"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2102.04518","identifier":"https://doi.org/10.48550/arXiv.2102.04518","enumerator":"24","key":"GtJmqP9ln9"}],"key":"MXNKG4eepv"},{"type":"tableCell","children":[{"type":"text","value":"Reinforcement learning, Search algorithms","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"IPkgf9Y9JI"}],"key":"n8rl4nJOn5"},{"type":"tableCell","children":[],"key":"vpRhKN74H9"}],"key":"l2bkjN2beZ"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.06196","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"children":[{"type":"text","value":"Large Language Models: A Survey","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"key":"J4mpA7Crx3"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.06196","identifier":"https://doi.org/10.48550/arXiv.2402.06196","enumerator":"25","key":"P1VOQeRb12"}],"key":"Hqrw4lNVqg"},{"type":"tableCell","children":[{"type":"text","value":"LLM capabilities, Survey","position":{"start":{"line":95,"column":1},"end":{"line":95,"column":1}},"key":"EU7s8SPvx3"}],"key":"eaF82NvSZe"},{"type":"tableCell","children":[],"key":"TM1Ih6iGP8"}],"key":"Zg4jg02hkW"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2402.14433","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"children":[{"type":"text","value":"A Language Model’s Guide Through Latent Space","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"U23XcY1C9Z"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2402.14433","identifier":"https://doi.org/10.48550/arXiv.2402.14433","enumerator":"26","key":"gqYttBFekz"}],"key":"PAfz48fhk1"},{"type":"tableCell","children":[{"type":"text","value":"Interpretability, Latent space","position":{"start":{"line":98,"column":1},"end":{"line":98,"column":1}},"key":"pLCXQMGLer"}],"key":"KTDndiIED9"},{"type":"tableCell","children":[],"key":"g43Q4xjm1P"}],"key":"z85KPbRCCP"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2205.05124","position":{"start":{"line":100,"column":1},"end":{"line":100,"column":1}},"children":[{"type":"text","value":"Extracting Latent Steering Vectors from Pretrained Language Models","position":{"start":{"line":100,"column":1},"end":{"line":100,"column":1}},"key":"E7oGadPGfC"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2205.05124","identifier":"https://doi.org/10.48550/arXiv.2205.05124","enumerator":"27","key":"OQ8fndVd2i"}],"key":"ORyJRU1rz2"},{"type":"tableCell","children":[{"type":"text","value":"Interpretability, Latent space","position":{"start":{"line":101,"column":1},"end":{"line":101,"column":1}},"key":"iyKHTECgoi"}],"key":"WJ2wcDDKRf"},{"type":"tableCell","children":[],"key":"mfVihklOxn"}],"key":"DYFmM8J9sw"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.anthropic.com/research/many-shot-jailbreaking","position":{"start":{"line":103,"column":1},"end":{"line":103,"column":1}},"children":[{"type":"text","value":"Many-shot jailbreaking","position":{"start":{"line":103,"column":1},"end":{"line":103,"column":1}},"key":"CtQJrpEEK7"}],"urlSource":"https://www.anthropic.com/research/many-shot-jailbreaking","key":"qnlp6drrHG"}],"key":"qKJ0sqiu3O"},{"type":"tableCell","children":[{"type":"text","value":"Jailbreaking, Model safety","position":{"start":{"line":104,"column":1},"end":{"line":104,"column":1}},"key":"izjEtT4LeE"}],"key":"hUrvCRUkDS"},{"type":"tableCell","children":[],"key":"r7SQQdV1IG"}],"key":"klrUJWu2W0"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1910.10683","position":{"start":{"line":106,"column":1},"end":{"line":106,"column":1}},"children":[{"type":"text","value":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer","position":{"start":{"line":106,"column":1},"end":{"line":106,"column":1}},"key":"BnUazwJ3U0"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1910.10683","identifier":"https://doi.org/10.48550/arXiv.1910.10683","enumerator":"28","key":"xSo9purOoe"}],"key":"JCdkACE0QR"},{"type":"tableCell","children":[{"type":"text","value":"Transfer learning","position":{"start":{"line":107,"column":1},"end":{"line":107,"column":1}},"key":"SSMQY7L8fY"}],"key":"iJjWfX8o82"},{"type":"tableCell","children":[],"key":"VztTOnOV7d"}],"key":"rdxfagemme"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2308.10248","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"children":[{"type":"text","value":"Activation Addition: Steering Language Models Without Optimization","position":{"start":{"line":109,"column":1},"end":{"line":109,"column":1}},"key":"fWIV9dNOe2"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2308.10248","identifier":"https://doi.org/10.48550/arXiv.2308.10248","enumerator":"29","key":"C4BAA4Cd2P"}],"key":"zsU3l3vSFW"},{"type":"tableCell","children":[{"type":"text","value":"Activation manipulation, Model steering","position":{"start":{"line":110,"column":1},"end":{"line":110,"column":1}},"key":"q1if1hjkDB"}],"key":"gmd1BlL3Yy"},{"type":"tableCell","children":[],"key":"QkXKf5ZjYV"}],"key":"p6MvhEIpHT"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2107.03374","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"children":[{"type":"text","value":"Evaluating Large Language Models Trained on Code","position":{"start":{"line":112,"column":1},"end":{"line":112,"column":1}},"key":"R1tjpD37gP"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2107.03374","identifier":"https://doi.org/10.48550/arXiv.2107.03374","enumerator":"30","key":"WANxfyeDSZ"}],"key":"lj1T66j4tG"},{"type":"tableCell","children":[{"type":"text","value":"Code generation, Model evaluation","position":{"start":{"line":113,"column":1},"end":{"line":113,"column":1}},"key":"OU4lEWVhoK"}],"key":"i2qySAfR89"},{"type":"tableCell","children":[],"key":"Ni2B21q2EG"}],"key":"X6diysZoHK"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.02543","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"children":[{"type":"text","value":"To Believe or Not to Believe Your LLM","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"key":"c1q0t9c8HB"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.02543","identifier":"https://doi.org/10.48550/arXiv.2406.02543","enumerator":"31","key":"MQCcBAcPhN"}],"key":"b5n0IBDkxS"},{"type":"tableCell","children":[{"type":"text","value":"Hallucination detection, Uncertainty quantification","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"amml2eW5ss"}],"key":"EmHVxt6pRK"},{"type":"tableCell","children":[],"key":"pGkujVE46E"}],"key":"VcfHfTqnB6"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.04692","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"children":[{"type":"text","value":"Mixture of Agents","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"key":"bzdTIqqry5"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.04692","identifier":"https://doi.org/10.48550/arXiv.2406.04692","enumerator":"19","key":"ddHlzRRJED"}],"key":"Y0eUrCtErZ"},{"type":"tableCell","children":[{"type":"text","value":"Multi-agent systems, Prompting","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"key":"kEO0srMx6F"}],"key":"rZdXe1mPyl"},{"type":"tableCell","children":[],"key":"AnfiTzZ3x2"}],"key":"skeUGDX7ln"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2404.14619","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"children":[{"type":"text","value":"OpenELM: An Efficient Language Model Family with Open Training and Inference Framework","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"key":"PFIukBkBH4"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2404.14619","identifier":"https://doi.org/10.48550/arXiv.2404.14619","enumerator":"32","key":"RqKIeGcOIv"}],"key":"r9aXkhf5TJ"},{"type":"tableCell","children":[{"type":"text","value":"Efficiency, Model architecture","position":{"start":{"line":122,"column":1},"end":{"line":122,"column":1}},"key":"xbQ513jnyc"}],"key":"vUZeMyp6MM"},{"type":"tableCell","children":[],"key":"WBBNYo811z"}],"key":"DQWGOWFFC9"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1706.03741","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"children":[{"type":"text","value":"Deep Reinforcement Learning from Human Preferences","position":{"start":{"line":124,"column":1},"end":{"line":124,"column":1}},"key":"gdwWUiv3TD"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1706.03741","identifier":"https://doi.org/10.48550/arXiv.1706.03741","enumerator":"33","key":"l6Y4j9axBu"}],"key":"yFJK5572ix"},{"type":"tableCell","children":[{"type":"text","value":"human feedback, Reinforcement learning","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":1}},"key":"nR4MUwC54G"}],"key":"mU4DNRcJQu"},{"type":"tableCell","children":[],"key":"Vf8y3nFv3k"}],"key":"WRsgZcHasw"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2307.08925","position":{"start":{"line":127,"column":1},"end":{"line":127,"column":1}},"children":[{"type":"text","value":"Federated Large Language Model: A Position Paper","position":{"start":{"line":127,"column":1},"end":{"line":127,"column":1}},"key":"mFPfTYXfiq"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2307.08925","identifier":"https://doi.org/10.48550/arXiv.2307.08925","enumerator":"34","key":"PDRbGJprnf"}],"key":"d9ddsM4jCV"},{"type":"tableCell","children":[{"type":"text","value":"Distributed training, Federated learning","position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"key":"f4s8RIFGJk"}],"key":"GXUYENqzFX"},{"type":"tableCell","children":[],"key":"SnznTAdAva"}],"key":"NKL911XYSP"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2212.02508","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"children":[{"type":"text","value":"MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"key":"LIe7w5tM43"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2212.02508","identifier":"https://doi.org/10.48550/arXiv.2212.02508","enumerator":"35","key":"Zc3gQpOFaG"}],"key":"D9Qbce2jI0"},{"type":"tableCell","children":[{"type":"text","value":"Music representation, Self-supervised learning","position":{"start":{"line":131,"column":1},"end":{"line":131,"column":1}},"key":"K7fkCIWBC2"}],"key":"ZlyoF58Nwx"},{"type":"tableCell","children":[],"key":"cpNR2TFq95"}],"key":"fmxsccOfI2"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2302.13971","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"children":[{"type":"text","value":"LLaMA: Open and Efficient Foundation Language Models","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"key":"NY8qT6fgVB"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2302.13971","identifier":"https://doi.org/10.48550/arXiv.2302.13971","enumerator":"36","key":"zcSf4BDKGG"}],"key":"h6iKjZUIsc"},{"type":"tableCell","children":[{"type":"text","value":"Model architecture, Open-source LLMs","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"NIk4Ektoqt"}],"key":"G0HMbspTtK"},{"type":"tableCell","children":[],"key":"jYz7p03kMl"}],"key":"zkxSrWGIgF"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"text","value":"Phi1: Textbooks Are All You Need","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"sB88F5mOtv"}],"urlSource":"https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/","key":"L0w8G5rUdi"}],"key":"ZdjLgvObid"},{"type":"tableCell","children":[{"type":"text","value":"Curated datasets, Model efficiency","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"ZCIpdvcwz9"}],"key":"FFsuk5GQiM"},{"type":"tableCell","children":[],"key":"TrwDZTVzgI"}],"key":"fg6hEzH6r2"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1607.06450","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"children":[{"type":"text","value":"Layer Normalization","position":{"start":{"line":139,"column":1},"end":{"line":139,"column":1}},"key":"GK8dxiaTb9"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1607.06450","identifier":"https://doi.org/10.48550/arXiv.1607.06450","enumerator":"37","key":"nmznaWh1jF"}],"key":"HrC7XymYHv"},{"type":"tableCell","children":[{"type":"text","value":"Model internals, Optimization","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"key":"AbZPyUAOME"}],"key":"SSeBi79UqS"},{"type":"tableCell","children":[],"key":"D93uedK0PS"}],"key":"pUsEDjxGHY"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1706.03762","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"children":[{"type":"text","value":"Attention Is All You Need","position":{"start":{"line":142,"column":1},"end":{"line":142,"column":1}},"key":"iDu0IWA4yB"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1706.03762","identifier":"https://doi.org/10.48550/arXiv.1706.03762","enumerator":"38","key":"DHDooexRii"}],"key":"qfEuzhdygw"},{"type":"tableCell","children":[{"type":"text","value":"OG papers, Transformers","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"nGlp7aOPNG"}],"key":"k29gytKVJi"},{"type":"tableCell","children":[],"key":"emmQ2FmKKS"}],"key":"QgaSgxkZDT"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2406.09412","position":{"start":{"line":145,"column":1},"end":{"line":145,"column":1}},"children":[{"type":"text","value":"Explore the Limits of Omni-modal Pretraining at Scale","position":{"start":{"line":145,"column":1},"end":{"line":145,"column":1}},"key":"fTZYx21GlY"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2406.09412","identifier":"https://doi.org/10.48550/arXiv.2406.09412","enumerator":"39","key":"NuHdbkz1rb"}],"key":"Fp4ZnqPiFf"},{"type":"tableCell","children":[{"type":"text","value":"Multi-modal models, Pretraining","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"uPBC18YKdj"}],"key":"U39JOfbCQg"},{"type":"tableCell","children":[],"key":"vDlrPyzCm7"}],"key":"EQL6NKg9zR"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1606.08415","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"children":[{"type":"text","value":"Gaussian Error Linear Units (GELUs)","position":{"start":{"line":148,"column":1},"end":{"line":148,"column":1}},"key":"Ryl4Zp4gkH"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1606.08415","identifier":"https://doi.org/10.48550/arXiv.1606.08415","enumerator":"40","key":"bNbbNUpVVr"}],"key":"HQRJQPgU9I"},{"type":"tableCell","children":[{"type":"text","value":"Activation functions, Model internals","position":{"start":{"line":149,"column":1},"end":{"line":149,"column":1}},"key":"xx1lr9ZJvJ"}],"key":"GhpzbZmlfe"},{"type":"tableCell","children":[],"key":"TTwJdzV1KQ"}],"key":"P9WVt1aDQ1"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2401.09796","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"children":[{"type":"text","value":"A Fast, Performant, Secure Distributed Training Framework For Large Language Model","position":{"start":{"line":151,"column":1},"end":{"line":151,"column":1}},"key":"V2u69X7sXn"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2401.09796","identifier":"https://doi.org/10.48550/arXiv.2401.09796","enumerator":"41","key":"NarZxZeu04"}],"key":"w9Ykp3vPp0"},{"type":"tableCell","children":[{"type":"text","value":"Distributed training, Security","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"uulXrVSSlb"}],"key":"K4NDTojVXV"},{"type":"tableCell","children":[],"key":"otrnHJJdO5"}],"key":"kNgZtgmUHU"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.1910.01108","position":{"start":{"line":154,"column":1},"end":{"line":154,"column":1}},"children":[{"type":"text","value":"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter","position":{"start":{"line":154,"column":1},"end":{"line":154,"column":1}},"key":"OdvJ8Cxay9"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.1910.01108","identifier":"https://doi.org/10.48550/arXiv.1910.01108","enumerator":"42","key":"qGHwpA584X"}],"key":"P8HG7toJLu"},{"type":"tableCell","children":[{"type":"text","value":"Efficiency, Model distillation","position":{"start":{"line":155,"column":1},"end":{"line":155,"column":1}},"key":"wqmvAhtlgE"}],"key":"ZhRXXbPmXm"},{"type":"tableCell","children":[],"key":"rygkLIMyZJ"}],"key":"Cd0lexkIfg"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","position":{"start":{"line":157,"column":1},"end":{"line":157,"column":1}},"children":[{"type":"text","value":"Improving Language Understanding by Generative Pre-Training","position":{"start":{"line":157,"column":1},"end":{"line":157,"column":1}},"key":"MePPfpBNPx"}],"urlSource":"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf","key":"XUFCbZUzfH"}],"key":"lj0ag2hon0"},{"type":"tableCell","children":[{"type":"text","value":"OG papers, Pre-training","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"key":"wJgdHNwdra"}],"key":"YVVV1SbHIO"},{"type":"tableCell","children":[],"key":"uvKZ1Ue3tz"}],"key":"N1paMPtYWV"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2203.02155","position":{"start":{"line":160,"column":1},"end":{"line":160,"column":1}},"children":[{"type":"text","value":"Training language models to follow instructions with human feedback","position":{"start":{"line":160,"column":1},"end":{"line":160,"column":1}},"key":"iQ2YILpNnL"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2203.02155","identifier":"https://doi.org/10.48550/arXiv.2203.02155","enumerator":"43","key":"RBrz2niQuU"}],"key":"fkog8zBhPp"},{"type":"tableCell","children":[{"type":"text","value":"Instruction following, Reinforcement learning","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"key":"al1UsJEmDi"}],"key":"KJAHkRFEoo"},{"type":"tableCell","children":[],"key":"ikEs7KMk60"}],"key":"aphgRjVibp"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2307.09288","position":{"start":{"line":163,"column":1},"end":{"line":163,"column":1}},"children":[{"type":"text","value":"Llama 2: Open Foundation and Fine-Tuned Chat Models","position":{"start":{"line":163,"column":1},"end":{"line":163,"column":1}},"key":"zcds3Y2iD1"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2307.09288","identifier":"https://doi.org/10.48550/arXiv.2307.09288","enumerator":"44","key":"XmDTuSZUw9"}],"key":"CamryJcwGc"},{"type":"tableCell","children":[{"type":"text","value":"Fine-tuning, Open-source LLMs","position":{"start":{"line":164,"column":1},"end":{"line":164,"column":1}},"key":"DCo0W5YAmg"}],"key":"TIxoghlB0c"},{"type":"tableCell","children":[],"key":"XbQh47ZtcT"}],"key":"Mi7yPDDZpe"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://doi.org/10.48550/arXiv.2104.09864","position":{"start":{"line":166,"column":1},"end":{"line":166,"column":1}},"children":[{"type":"text","value":"RoFormer: Enhanced Transformer with Rotary Position Embedding","position":{"start":{"line":166,"column":1},"end":{"line":166,"column":1}},"key":"iV2VblxyJ2"}],"kind":"narrative","label":"https://doi.org/10.48550/arxiv.2104.09864","identifier":"https://doi.org/10.48550/arXiv.2104.09864","enumerator":"45","key":"Gv8WyJFDXB"}],"key":"VOuJjOPw9H"},{"type":"tableCell","children":[{"type":"text","value":"Embeddings, Model architecture","position":{"start":{"line":167,"column":1},"end":{"line":167,"column":1}},"key":"CIljtpKhTR"}],"key":"JoFhRMYkdz"},{"type":"tableCell","children":[],"key":"q0U9yEDoyh"}],"key":"SFYyaTutwq"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"link","url":"https://www.nature.com/articles/s42256-023-00748-9","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"children":[{"type":"text","value":"Spatially embedded recurrent neural networks reveal widespread links between structural and functional neuroscience findings | Nature Machine Intelligence","position":{"start":{"line":169,"column":1},"end":{"line":169,"column":1}},"key":"l26qvCChLc"}],"urlSource":"https://www.nature.com/articles/s42256-023-00748-9","key":"NTNzuEq9V1"}],"key":"eLX3zOc73H"},{"type":"tableCell","children":[{"type":"text","value":"Biological Brains","position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"key":"GbMoRIXNEl"}],"key":"pRSU9heiMh"},{"type":"tableCell","children":[],"key":"egksresPtV"}],"key":"bNS4bK621k"},{"type":"tableRow","children":[{"type":"tableCell","children":[{"type":"cite","url":"https://onlinelibrary.wiley.com/doi/10.1111/tops.12737","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"children":[{"type":"text","value":"Understanding Human Cognition Through Computational Modeling - Hsiao - 2024 - Topics in Cognitive Science - Wiley Online Library","position":{"start":{"line":172,"column":1},"end":{"line":172,"column":1}},"key":"d7pAjNF3OQ"}],"kind":"narrative","label":"Hsiao_2024","identifier":"https://onlinelibrary.wiley.com/doi/10.1111/tops.12737","enumerator":"46","key":"OlVsCRoXTL"}],"key":"EksRetR812"},{"type":"tableCell","children":[{"type":"text","value":"Biological Brains","position":{"start":{"line":173,"column":1},"end":{"line":173,"column":1}},"key":"tBYqMGw9I8"}],"key":"fyvxAa2BQq"},{"type":"tableCell","children":[],"key":"ItorC2XSUm"}],"key":"Oll8TKPgsk"}],"key":"Qzd1yFKrq1"}],"enumerator":"1","key":"drQ5XEeVhi"}],"key":"WxxCO1TC2J"}],"key":"dVR9QF2KCt"},"references":{"cite":{"order":["https://doi.org/10.48550/arxiv.2411.07191","https://doi.org/10.48550/arxiv.2410.02725","https://doi.org/10.48550/arxiv.2404.03592","https://doi.org/10.48550/arxiv.2402.06111","https://doi.org/10.48550/arxiv.2403.20327","https://doi.org/10.48550/arxiv.2210.07128","https://doi.org/10.48550/arxiv.2407.10969","https://doi.org/10.48550/arxiv.2207.01780","https://doi.org/10.48550/arxiv.2405.20541","https://doi.org/10.48550/arxiv.2402.17764","https://doi.org/10.48550/arxiv.2305.17493","https://doi.org/10.48550/arxiv.2404.07143","https://doi.org/10.48550/arxiv.2406.07496","https://doi.org/10.48550/arxiv.2406.02528","https://doi.org/10.48550/arxiv.1712.00676","https://doi.org/10.48550/arxiv.2311.17035","https://doi.org/10.48550/arxiv.2305.07759","https://doi.org/10.48550/arxiv.2311.12983","https://doi.org/10.48550/arxiv.2406.04692","https://doi.org/10.48550/arxiv.2311.05884","https://doi.org/10.48550/arxiv.2307.11760","https://doi.org/10.48550/arxiv.2402.09171","https://doi.org/10.48550/arxiv.2404.01413","https://doi.org/10.48550/arxiv.2102.04518","https://doi.org/10.48550/arxiv.2402.06196","https://doi.org/10.48550/arxiv.2402.14433","https://doi.org/10.48550/arxiv.2205.05124","https://doi.org/10.48550/arxiv.1910.10683","https://doi.org/10.48550/arxiv.2308.10248","https://doi.org/10.48550/arxiv.2107.03374","https://doi.org/10.48550/arxiv.2406.02543","https://doi.org/10.48550/arxiv.2404.14619","https://doi.org/10.48550/arxiv.1706.03741","https://doi.org/10.48550/arxiv.2307.08925","https://doi.org/10.48550/arxiv.2212.02508","https://doi.org/10.48550/arxiv.2302.13971","https://doi.org/10.48550/arxiv.1607.06450","https://doi.org/10.48550/arxiv.1706.03762","https://doi.org/10.48550/arxiv.2406.09412","https://doi.org/10.48550/arxiv.1606.08415","https://doi.org/10.48550/arxiv.2401.09796","https://doi.org/10.48550/arxiv.1910.01108","https://doi.org/10.48550/arxiv.2203.02155","https://doi.org/10.48550/arxiv.2307.09288","https://doi.org/10.48550/arxiv.2104.09864","Hsiao_2024"],"data":{"https://doi.org/10.48550/arxiv.2411.07191":{"label":"https://doi.org/10.48550/arxiv.2411.07191","enumerator":"1","doi":"10.48550/ARXIV.2411.07191","html":"Yu, M., Wang, D., Shan, Q., Reed, C., \u0026 Wan, A. (2024). \u003ci\u003eThe Super Weight in Large Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2411.07191\"\u003e10.48550/ARXIV.2411.07191\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2411.07191"},"https://doi.org/10.48550/arxiv.2410.02725":{"label":"https://doi.org/10.48550/arxiv.2410.02725","enumerator":"2","doi":"10.48550/ARXIV.2410.02725","html":"Manvi, R., Singh, A., \u0026 Ermon, S. (2024). \u003ci\u003eAdaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better, Even Mid-Generation\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2410.02725\"\u003e10.48550/ARXIV.2410.02725\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2410.02725"},"https://doi.org/10.48550/arxiv.2404.03592":{"label":"https://doi.org/10.48550/arxiv.2404.03592","enumerator":"3","doi":"10.48550/ARXIV.2404.03592","html":"Wu, Z., Arora, A., Wang, Z., Geiger, A., Jurafsky, D., Manning, C. D., \u0026 Potts, C. (2024). \u003ci\u003eReFT: Representation Finetuning for Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.03592\"\u003e10.48550/ARXIV.2404.03592\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.03592"},"https://doi.org/10.48550/arxiv.2402.06111":{"label":"https://doi.org/10.48550/arxiv.2402.06111","enumerator":"4","doi":"10.48550/ARXIV.2402.06111","html":"Alshahwan, N., Harman, M., Marginean, A., Tal, R., \u0026 Wang, E. (2024). \u003ci\u003eObservation-based unit test generation at Meta\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.06111\"\u003e10.48550/ARXIV.2402.06111\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.06111"},"https://doi.org/10.48550/arxiv.2403.20327":{"label":"https://doi.org/10.48550/arxiv.2403.20327","enumerator":"5","doi":"10.48550/ARXIV.2403.20327","html":"Lee, J., Dai, Z., Ren, X., Chen, B., Cer, D., Cole, J. R., Hui, K., Boratko, M., Kapadia, R., Ding, W., Luan, Y., Duddu, S. M. K., Abrego, G. H., Shi, W., Gupta, N., Kusupati, A., Jain, P., Jonnalagadda, S. R., Chang, M.-W., \u0026 Naim, I. (2024). \u003ci\u003eGecko: Versatile Text Embeddings Distilled from Large Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2403.20327\"\u003e10.48550/ARXIV.2403.20327\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2403.20327"},"https://doi.org/10.48550/arxiv.2210.07128":{"label":"https://doi.org/10.48550/arxiv.2210.07128","enumerator":"6","doi":"10.48550/ARXIV.2210.07128","html":"Madaan, A., Zhou, S., Alon, U., Yang, Y., \u0026 Neubig, G. (2022). \u003ci\u003eLanguage Models of Code are Few-Shot Commonsense Learners\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2210.07128\"\u003e10.48550/ARXIV.2210.07128\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2210.07128"},"https://doi.org/10.48550/arxiv.2407.10969":{"label":"https://doi.org/10.48550/arxiv.2407.10969","enumerator":"7","doi":"10.48550/ARXIV.2407.10969","html":"Wang, H., Ma, S., Wang, R., \u0026 Wei, F. (2024). \u003ci\u003eQ-Sparse: All Large Language Models can be Fully Sparsely-Activated\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2407.10969\"\u003e10.48550/ARXIV.2407.10969\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2407.10969"},"https://doi.org/10.48550/arxiv.2207.01780":{"label":"https://doi.org/10.48550/arxiv.2207.01780","enumerator":"8","doi":"10.48550/ARXIV.2207.01780","html":"Le, H., Wang, Y., Gotmare, A. D., Savarese, S., \u0026 Hoi, S. C. H. (2022). \u003ci\u003eCodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2207.01780\"\u003e10.48550/ARXIV.2207.01780\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2207.01780"},"https://doi.org/10.48550/arxiv.2405.20541":{"label":"https://doi.org/10.48550/arxiv.2405.20541","enumerator":"9","doi":"10.48550/ARXIV.2405.20541","html":"Ankner, Z., Blakeney, C., Sreenivasan, K., Marion, M., Leavitt, M. L., \u0026 Paul, M. (2024). \u003ci\u003ePerplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2405.20541\"\u003e10.48550/ARXIV.2405.20541\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2405.20541"},"https://doi.org/10.48550/arxiv.2402.17764":{"label":"https://doi.org/10.48550/arxiv.2402.17764","enumerator":"10","doi":"10.48550/ARXIV.2402.17764","html":"Ma, S., Wang, H., Ma, L., Wang, L., Wang, W., Huang, S., Dong, L., Wang, R., Xue, J., \u0026 Wei, F. (2024). \u003ci\u003eThe Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.17764\"\u003e10.48550/ARXIV.2402.17764\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.17764"},"https://doi.org/10.48550/arxiv.2305.17493":{"label":"https://doi.org/10.48550/arxiv.2305.17493","enumerator":"11","doi":"10.48550/ARXIV.2305.17493","html":"Shumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot, N., \u0026 Anderson, R. (2023). \u003ci\u003eThe Curse of Recursion: Training on Generated Data Makes Models Forget\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2305.17493\"\u003e10.48550/ARXIV.2305.17493\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2305.17493"},"https://doi.org/10.48550/arxiv.2404.07143":{"label":"https://doi.org/10.48550/arxiv.2404.07143","enumerator":"12","doi":"10.48550/ARXIV.2404.07143","html":"Munkhdalai, T., Faruqui, M., \u0026 Gopal, S. (2024). \u003ci\u003eLeave No Context Behind: Efficient Infinite Context Transformers with Infini-attention\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.07143\"\u003e10.48550/ARXIV.2404.07143\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.07143"},"https://doi.org/10.48550/arxiv.2406.07496":{"label":"https://doi.org/10.48550/arxiv.2406.07496","enumerator":"13","doi":"10.48550/ARXIV.2406.07496","html":"Yuksekgonul, M., Bianchi, F., Boen, J., Liu, S., Huang, Z., Guestrin, C., \u0026 Zou, J. (2024). \u003ci\u003eTextGrad: Automatic “Differentiation” via Text\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.07496\"\u003e10.48550/ARXIV.2406.07496\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.07496"},"https://doi.org/10.48550/arxiv.2406.02528":{"label":"https://doi.org/10.48550/arxiv.2406.02528","enumerator":"14","doi":"10.48550/ARXIV.2406.02528","html":"Zhu, R.-J., Zhang, Y., Sifferman, E., Sheaves, T., Wang, Y., Richmond, D., Zhou, P., \u0026 Eshraghian, J. K. (2024). \u003ci\u003eScalable MatMul-free Language Modeling\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.02528\"\u003e10.48550/ARXIV.2406.02528\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.02528"},"https://doi.org/10.48550/arxiv.1712.00676":{"label":"https://doi.org/10.48550/arxiv.1712.00676","enumerator":"15","doi":"10.48550/ARXIV.1712.00676","html":"Billings, J. J., McCaskey, A. J., Vallee, G., \u0026 Watson, G. (2017). \u003ci\u003eWill humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?\u003c/i\u003e arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1712.00676\"\u003e10.48550/ARXIV.1712.00676\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1712.00676"},"https://doi.org/10.48550/arxiv.2311.17035":{"label":"https://doi.org/10.48550/arxiv.2311.17035","enumerator":"16","doi":"10.48550/ARXIV.2311.17035","html":"Nasr, M., Carlini, N., Hayase, J., Jagielski, M., Cooper, A. F., Ippolito, D., Choquette-Choo, C. A., Wallace, E., Tramèr, F., \u0026 Lee, K. (2023). \u003ci\u003eScalable Extraction of Training Data from (Production) Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2311.17035\"\u003e10.48550/ARXIV.2311.17035\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2311.17035"},"https://doi.org/10.48550/arxiv.2305.07759":{"label":"https://doi.org/10.48550/arxiv.2305.07759","enumerator":"17","doi":"10.48550/ARXIV.2305.07759","html":"Eldan, R., \u0026 Li, Y. (2023). \u003ci\u003eTinyStories: How Small Can Language Models Be and Still Speak Coherent English?\u003c/i\u003e arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2305.07759\"\u003e10.48550/ARXIV.2305.07759\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2305.07759"},"https://doi.org/10.48550/arxiv.2311.12983":{"label":"https://doi.org/10.48550/arxiv.2311.12983","enumerator":"18","doi":"10.48550/ARXIV.2311.12983","html":"Mialon, G., Fourrier, C., Swift, C., Wolf, T., LeCun, Y., \u0026 Scialom, T. (2023). \u003ci\u003eGAIA: a benchmark for General AI Assistants\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2311.12983\"\u003e10.48550/ARXIV.2311.12983\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2311.12983"},"https://doi.org/10.48550/arxiv.2406.04692":{"label":"https://doi.org/10.48550/arxiv.2406.04692","enumerator":"19","doi":"10.48550/ARXIV.2406.04692","html":"Wang, J., Wang, J., Athiwaratkun, B., Zhang, C., \u0026 Zou, J. (2024). \u003ci\u003eMixture-of-Agents Enhances Large Language Model Capabilities\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.04692\"\u003e10.48550/ARXIV.2406.04692\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.04692"},"https://doi.org/10.48550/arxiv.2311.05884":{"label":"https://doi.org/10.48550/arxiv.2311.05884","enumerator":"20","doi":"10.48550/ARXIV.2311.05884","html":"Gui, H., Wang, R., Yin, K., Jin, L., Kula, M., Xu, T., Hong, L., \u0026 Chi, E. H. (2023). \u003ci\u003eHiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2311.05884\"\u003e10.48550/ARXIV.2311.05884\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2311.05884"},"https://doi.org/10.48550/arxiv.2307.11760":{"label":"https://doi.org/10.48550/arxiv.2307.11760","enumerator":"21","doi":"10.48550/ARXIV.2307.11760","html":"Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., \u0026 Xie, X. (2023). \u003ci\u003eLarge Language Models Understand and Can be Enhanced by Emotional Stimuli\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2307.11760\"\u003e10.48550/ARXIV.2307.11760\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2307.11760"},"https://doi.org/10.48550/arxiv.2402.09171":{"label":"https://doi.org/10.48550/arxiv.2402.09171","enumerator":"22","doi":"10.48550/ARXIV.2402.09171","html":"Alshahwan, N., Chheda, J., Finegenova, A., Gokkaya, B., Harman, M., Harper, I., Marginean, A., Sengupta, S., \u0026 Wang, E. (2024). \u003ci\u003eAutomated Unit Test Improvement using Large Language Models at Meta\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.09171\"\u003e10.48550/ARXIV.2402.09171\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.09171"},"https://doi.org/10.48550/arxiv.2404.01413":{"label":"https://doi.org/10.48550/arxiv.2404.01413","enumerator":"23","doi":"10.48550/ARXIV.2404.01413","html":"Gerstgrasser, M., Schaeffer, R., Dey, A., Rafailov, R., Sleight, H., Hughes, J., Korbak, T., Agrawal, R., Pai, D., Gromov, A., Roberts, D. A., Yang, D., Donoho, D. L., \u0026 Koyejo, S. (2024). \u003ci\u003eIs Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.01413\"\u003e10.48550/ARXIV.2404.01413\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.01413"},"https://doi.org/10.48550/arxiv.2102.04518":{"label":"https://doi.org/10.48550/arxiv.2102.04518","enumerator":"24","doi":"10.48550/ARXIV.2102.04518","html":"Agostinelli, F., Shmakov, A., McAleer, S., Fox, R., \u0026 Baldi, P. (2021). \u003ci\u003eA* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2102.04518\"\u003e10.48550/ARXIV.2102.04518\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2102.04518"},"https://doi.org/10.48550/arxiv.2402.06196":{"label":"https://doi.org/10.48550/arxiv.2402.06196","enumerator":"25","doi":"10.48550/ARXIV.2402.06196","html":"Minaee, S., Mikolov, T., Nikzad, N., Chenaghlu, M., Socher, R., Amatriain, X., \u0026 Gao, J. (2024). \u003ci\u003eLarge Language Models: A Survey\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.06196\"\u003e10.48550/ARXIV.2402.06196\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.06196"},"https://doi.org/10.48550/arxiv.2402.14433":{"label":"https://doi.org/10.48550/arxiv.2402.14433","enumerator":"26","doi":"10.48550/ARXIV.2402.14433","html":"von Rütte, D., Anagnostidis, S., Bachmann, G., \u0026 Hofmann, T. (2024). \u003ci\u003eA Language Model’s Guide Through Latent Space\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2402.14433\"\u003e10.48550/ARXIV.2402.14433\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2402.14433"},"https://doi.org/10.48550/arxiv.2205.05124":{"label":"https://doi.org/10.48550/arxiv.2205.05124","enumerator":"27","doi":"10.48550/ARXIV.2205.05124","html":"Subramani, N., Suresh, N., \u0026 Peters, M. E. (2022). \u003ci\u003eExtracting Latent Steering Vectors from Pretrained Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2205.05124\"\u003e10.48550/ARXIV.2205.05124\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2205.05124"},"https://doi.org/10.48550/arxiv.1910.10683":{"label":"https://doi.org/10.48550/arxiv.1910.10683","enumerator":"28","doi":"10.48550/ARXIV.1910.10683","html":"Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., \u0026 Liu, P. J. (2019). \u003ci\u003eExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1910.10683\"\u003e10.48550/ARXIV.1910.10683\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1910.10683"},"https://doi.org/10.48550/arxiv.2308.10248":{"label":"https://doi.org/10.48550/arxiv.2308.10248","enumerator":"29","doi":"10.48550/ARXIV.2308.10248","html":"Turner, A. M., Thiergart, L., Leech, G., Udell, D., Vazquez, J. J., Mini, U., \u0026 MacDiarmid, M. (2023). \u003ci\u003eSteering Language Models With Activation Engineering\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2308.10248\"\u003e10.48550/ARXIV.2308.10248\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2308.10248"},"https://doi.org/10.48550/arxiv.2107.03374":{"label":"https://doi.org/10.48550/arxiv.2107.03374","enumerator":"30","doi":"10.48550/ARXIV.2107.03374","html":"Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., … Zaremba, W. (2021). \u003ci\u003eEvaluating Large Language Models Trained on Code\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2107.03374\"\u003e10.48550/ARXIV.2107.03374\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2107.03374"},"https://doi.org/10.48550/arxiv.2406.02543":{"label":"https://doi.org/10.48550/arxiv.2406.02543","enumerator":"31","doi":"10.48550/ARXIV.2406.02543","html":"Yadkori, Y. A., Kuzborskij, I., György, A., \u0026 Szepesvári, C. (2024). \u003ci\u003eTo Believe or Not to Believe Your LLM\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.02543\"\u003e10.48550/ARXIV.2406.02543\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.02543"},"https://doi.org/10.48550/arxiv.2404.14619":{"label":"https://doi.org/10.48550/arxiv.2404.14619","enumerator":"32","doi":"10.48550/ARXIV.2404.14619","html":"Mehta, S., Sekhavat, M. H., Cao, Q., Horton, M., Jin, Y., Sun, C., Mirzadeh, I., Najibi, M., Belenko, D., Zatloukal, P., \u0026 Rastegari, M. (2024). \u003ci\u003eOpenELM: An Efficient Language Model Family with Open Training and Inference Framework\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2404.14619\"\u003e10.48550/ARXIV.2404.14619\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2404.14619"},"https://doi.org/10.48550/arxiv.1706.03741":{"label":"https://doi.org/10.48550/arxiv.1706.03741","enumerator":"33","doi":"10.48550/ARXIV.1706.03741","html":"Christiano, P., Leike, J., Brown, T. B., Martic, M., Legg, S., \u0026 Amodei, D. (2017). \u003ci\u003eDeep reinforcement learning from human preferences\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1706.03741\"\u003e10.48550/ARXIV.1706.03741\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1706.03741"},"https://doi.org/10.48550/arxiv.2307.08925":{"label":"https://doi.org/10.48550/arxiv.2307.08925","enumerator":"34","doi":"10.48550/ARXIV.2307.08925","html":"Chen, C., Feng, X., Li, Y., Lyu, L., Zhou, J., Zheng, X., \u0026 Yin, J. (2023). \u003ci\u003eIntegration of Large Language Models and Federated Learning\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2307.08925\"\u003e10.48550/ARXIV.2307.08925\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2307.08925"},"https://doi.org/10.48550/arxiv.2212.02508":{"label":"https://doi.org/10.48550/arxiv.2212.02508","enumerator":"35","doi":"10.48550/ARXIV.2212.02508","html":"Li, Y., Yuan, R., Zhang, G., Ma, Y., Lin, C., Chen, X., Ragni, A., Yin, H., Hu, Z., He, H., Benetos, E., Gyenge, N., Liu, R., \u0026 Fu, J. (2022). \u003ci\u003eMAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2212.02508\"\u003e10.48550/ARXIV.2212.02508\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2212.02508"},"https://doi.org/10.48550/arxiv.2302.13971":{"label":"https://doi.org/10.48550/arxiv.2302.13971","enumerator":"36","doi":"10.48550/ARXIV.2302.13971","html":"Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., \u0026 Lample, G. (2023). \u003ci\u003eLLaMA: Open and Efficient Foundation Language Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2302.13971\"\u003e10.48550/ARXIV.2302.13971\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2302.13971"},"https://doi.org/10.48550/arxiv.1607.06450":{"label":"https://doi.org/10.48550/arxiv.1607.06450","enumerator":"37","doi":"10.48550/ARXIV.1607.06450","html":"Ba, J. L., Kiros, J. R., \u0026 Hinton, G. E. (2016). \u003ci\u003eLayer Normalization\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1607.06450\"\u003e10.48550/ARXIV.1607.06450\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1607.06450"},"https://doi.org/10.48550/arxiv.1706.03762":{"label":"https://doi.org/10.48550/arxiv.1706.03762","enumerator":"38","doi":"10.48550/ARXIV.1706.03762","html":"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., \u0026 Polosukhin, I. (2017). \u003ci\u003eAttention Is All You Need\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1706.03762\"\u003e10.48550/ARXIV.1706.03762\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1706.03762"},"https://doi.org/10.48550/arxiv.2406.09412":{"label":"https://doi.org/10.48550/arxiv.2406.09412","enumerator":"39","doi":"10.48550/ARXIV.2406.09412","html":"Zhang, Y., Li, H., Liu, J., \u0026 Yue, X. (2024). \u003ci\u003eExplore the Limits of Omni-modal Pretraining at Scale\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2406.09412\"\u003e10.48550/ARXIV.2406.09412\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2406.09412"},"https://doi.org/10.48550/arxiv.1606.08415":{"label":"https://doi.org/10.48550/arxiv.1606.08415","enumerator":"40","doi":"10.48550/ARXIV.1606.08415","html":"Hendrycks, D., \u0026 Gimpel, K. (2016). \u003ci\u003eGaussian Error Linear Units (GELUs)\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1606.08415\"\u003e10.48550/ARXIV.1606.08415\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1606.08415"},"https://doi.org/10.48550/arxiv.2401.09796":{"label":"https://doi.org/10.48550/arxiv.2401.09796","enumerator":"41","doi":"10.48550/ARXIV.2401.09796","html":"Huang, W., Wang, Y., Cheng, A., Zhou, A., Yu, C., \u0026 Wang, L. (2024). \u003ci\u003eA Fast, Performant, Secure Distributed Training Framework For Large Language Model\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2401.09796\"\u003e10.48550/ARXIV.2401.09796\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2401.09796"},"https://doi.org/10.48550/arxiv.1910.01108":{"label":"https://doi.org/10.48550/arxiv.1910.01108","enumerator":"42","doi":"10.48550/ARXIV.1910.01108","html":"Sanh, V., Debut, L., Chaumond, J., \u0026 Wolf, T. (2019). \u003ci\u003eDistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.1910.01108\"\u003e10.48550/ARXIV.1910.01108\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.1910.01108"},"https://doi.org/10.48550/arxiv.2203.02155":{"label":"https://doi.org/10.48550/arxiv.2203.02155","enumerator":"43","doi":"10.48550/ARXIV.2203.02155","html":"Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., \u0026 Lowe, R. (2022). \u003ci\u003eTraining language models to follow instructions with human feedback\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2203.02155\"\u003e10.48550/ARXIV.2203.02155\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2203.02155"},"https://doi.org/10.48550/arxiv.2307.09288":{"label":"https://doi.org/10.48550/arxiv.2307.09288","enumerator":"44","doi":"10.48550/ARXIV.2307.09288","html":"Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., … Scialom, T. (2023). \u003ci\u003eLlama 2: Open Foundation and Fine-Tuned Chat Models\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2307.09288\"\u003e10.48550/ARXIV.2307.09288\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2307.09288"},"https://doi.org/10.48550/arxiv.2104.09864":{"label":"https://doi.org/10.48550/arxiv.2104.09864","enumerator":"45","doi":"10.48550/ARXIV.2104.09864","html":"Su, J., Lu, Y., Pan, S., Murtadha, A., Wen, B., \u0026 Liu, Y. (2021). \u003ci\u003eRoFormer: Enhanced Transformer with Rotary Position Embedding\u003c/i\u003e. arXiv. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.48550/ARXIV.2104.09864\"\u003e10.48550/ARXIV.2104.09864\u003c/a\u003e","url":"https://doi.org/10.48550/ARXIV.2104.09864"},"Hsiao_2024":{"label":"Hsiao_2024","enumerator":"46","doi":"10.1111/tops.12737","html":"Hsiao, J. H. (2024). Understanding Human Cognition Through Computational Modeling. \u003ci\u003eTopics in Cognitive Science\u003c/i\u003e, \u003ci\u003e16\u003c/i\u003e(3), 349–376. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1111/tops.12737\"\u003e10.1111/tops.12737\u003c/a\u003e","url":"https://doi.org/10.1111/tops.12737"}}}},"footer":{"navigation":{"prev":{"title":"The Transformer","url":"/glossary/transformer-1","group":"ML Notes"},"next":{"title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","url":"/paper-notes/perplexity-based-data-pruning","group":"ML Notes"}}},"domain":"http://localhost:3002"},"project":{"title":"ML Notes","github":"https://github.com/joshcarp/ml-notes","id":"af717f67-a8e5-4337-ac20-caf05da70397","thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"https://github.com/joshcarp/ml-notes","ref":"HEAD"}},"toc":[{"file":"intro.md"},{"children":[{"file":"projects/cognition.to.md"},{"file":"projects/the-interactive-transformer/interactive-transformer.ipynb","title":"The Interactive Transformer"}],"file":"projects/index.md"},{"children":[{"file":"glossary/dropout.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"},{"file":"glossary/dropout.md"},{"file":"glossary/feed_forward_network.md"},{"file":"glossary/fine-tuning.md"},{"file":"glossary/lora.md"},{"file":"glossary/model_collapse.md"},{"file":"glossary/poly_semanticity.md"},{"file":"glossary/pre-training.md"},{"file":"glossary/rag.md"},{"file":"glossary/reinforcement-learning.md"},{"file":"glossary/residual_stream.md"},{"file":"glossary/sparsedense-reward.md"},{"file":"glossary/transformer.md"}],"file":"glossary/index.md"},{"children":[{"file":"paper-notes/perplexity-based-data-pruning.md"}],"file":"paper-notes/index.md","title":"Paper Notes"}],"exports":[],"bibliography":[],"index":"intro","pages":[{"slug":"projects.index","title":"Projects","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"projects.cognition-to","title":"CognitionTO Community","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projects.the-interactive-transformer.interactive-transformer","title":"The Interactive Transformer","description":"","date":"","thumbnail":"/build/decoder-only-8dc5eb8c43306bad204a83ccf0fbf0ec.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.index","title":"Glossary","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"glossary.dropout","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.dropout-1","title":"Dropout","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.feed-forward-network","title":"Feed-Forward Network","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.fine-tuning-1","title":"Fine-Tuning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.lora","title":"LoRA (Low-Rank Adaptation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.model-collapse","title":"Model Collapse","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.poly-semanticity","title":"Poly-semanticity","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.pre-training-1","title":"Pre-Training","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.rag","title":"RAG (Retrieval-Augmented Generation)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.reinforcement-learning-1","title":"Reinforcement Learning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.residual-stream","title":"Residual Stream","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.sparsedense-reward-1","title":"Sparse/Dense Reward","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"glossary.transformer-1","title":"The Transformer","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"paper-notes.index","title":"Papers","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"paper-notes.perplexity-based-data-pruning","title":"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-A92797E9.js";
import * as route0 from "/build/root-HROFNPGU.js";
import * as route1 from "/build/routes/$-WNZNXUO2.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>